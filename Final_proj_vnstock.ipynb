{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing library\n",
        "Required library: OS, glob, pandas, datetime, numpy, seaborn, matplotlib, tensorflow, sklearn"
      ],
      "metadata": {
        "id": "ZArFsH_rwi4O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7mcJwp0OOg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad4c20f-8f14-465b-a942-a5a636e61a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZStMRUxPF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3d660c-5cba-4da3-cb72-bc8ee8bc9e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandas_ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pandas_ta) (1.16.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218908 sha256=eeebf457809f45f25594d545c2d1414202089fb8868cf4ceec132bd0f9bf4071\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from datetime import date,timedelta\n",
        "from datetime import datetime as dt\n",
        "from dateutil.relativedelta import *\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow and Keras imports.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, regularizers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, Dropout, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "import sklearn\n",
        "\n",
        "\n",
        "# Scikit-learn imports.\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import r2_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#Import library for calculating indicators\n",
        "!pip install pandas_ta\n",
        "import pandas_ta as ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring some constants\n",
        "goodmse = 0.1\n",
        "\n",
        "#Making the filepath to the dataset a global directory\n",
        "path = '/content/gdrive/My Drive/data-vn-20230228/'\n",
        "os.chdir(path)\n",
        "\n",
        "#Setting up a folder for storing best models\n",
        "bestModelDir = \"./best_models/\"\n",
        "if not os.path.exists(bestModelDir):\n",
        "  print(\"True\")\n",
        "  os.makedirs(bestModelDir)"
      ],
      "metadata": {
        "id": "Sl7b2lo8cWRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing"
      ],
      "metadata": {
        "id": "BK3AXyjgwz9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Company filtering\n",
        "Choose banks only"
      ],
      "metadata": {
        "id": "kxwEUmOawv-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xdGdFKSC-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8752ea80-853f-4898-9a2c-92719eeeea5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36      ABB\n",
              "41      ACB\n",
              "129     BID\n",
              "287     CTG\n",
              "423     EIB\n",
              "472     BVB\n",
              "545     HDB\n",
              "697     KLB\n",
              "773     LPB\n",
              "777     MBB\n",
              "812     MSB\n",
              "824     NAB\n",
              "833     BAB\n",
              "890     NVB\n",
              "894     OCB\n",
              "929     PGB\n",
              "1149    SSB\n",
              "1159    SGB\n",
              "1174    SHB\n",
              "1234    STB\n",
              "1268    TCB\n",
              "1357    TPB\n",
              "1420    VAB\n",
              "1435    VCB\n",
              "1477    VIB\n",
              "1564    VPB\n",
              "1599    VBB\n",
              "Name: ticker, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "temp = pd.read_csv(\"ticker-overview.csv\")\n",
        "temp[temp[\"industryEn\"] == \"Banks\"][\"ticker\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYLCS_K_UNb0"
      },
      "outputs": [],
      "source": [
        "#Preparing the list of names of bank.\n",
        "finName = []\n",
        "for file in temp[temp[\"industryEn\"] == \"Banks\"][\"ticker\"]:\n",
        "  tempPath = \"stock-historical-data/\" + file +\"-*\"\n",
        "  for i in glob.glob(tempPath.format(\"csv\")):\n",
        "    finName.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sxJHmvfAwa8"
      },
      "outputs": [],
      "source": [
        "#Preparing the list of names of bank.\n",
        "finRatio = []\n",
        "for file in temp[temp[\"industryEn\"] == \"Banks\"][\"ticker\"]:\n",
        "  tempPath = \"financial-ratio/\" + file +\"-*\"\n",
        "  for i in glob.glob(tempPath.format(\"csv\")):\n",
        "    finRatio.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jh_r_zyA6cH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb158df-6908-4344-b0a6-31aafe23fab8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(finRatio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmwL74yvA71v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ee239c-4416-46c9-c25d-7579ed0a62ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "#combine all files in the list\n",
        "ratio = pd.DataFrame()\n",
        "count = 0\n",
        "for file in finRatio:\n",
        " data = pd.read_csv(file)\n",
        " ratio = pd.concat([ratio, data], axis=0)\n",
        " count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko_bKoATBvX_"
      },
      "outputs": [],
      "source": [
        "ratio = ratio[(ratio[\"year\"]==2022) & (ratio[\"quarter\"] == 4)]\n",
        "ratio = ratio.sort_values(\"ticker\", ignore_index=True)\n",
        "# ratio.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "ratio.dropna(axis=1, inplace=True)\n",
        "companyAna = ratio[[\"ticker\", \"priceToBook\"]]\n",
        "companyAna = companyAna[companyAna[\"priceToBook\"]>0]\n",
        "companyAna.sort_values([\"priceToBook\"], ascending=False, ignore_index=True, inplace=True)\n",
        "# companyAna = companyAna.drop(labels = 25, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "companyAna.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "M-GP-C9qtSpw",
        "outputId": "7f0bda3a-425d-48f0-f7c9-9b8185ec1550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ticker  priceToBook\n",
              "0    VCB          3.2\n",
              "1    SSB          2.5\n",
              "2    BID          2.2\n",
              "3    NVB          1.6\n",
              "4    ACB          1.5\n",
              "5    BAB          1.4\n",
              "6    VIB          1.4\n",
              "7    CTG          1.3\n",
              "8    EIB          1.3\n",
              "9    TPB          1.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26ae294f-d3c0-4c67-abbb-69a9f46f3f99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>priceToBook</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VCB</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SSB</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BID</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NVB</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACB</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BAB</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>VIB</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CTG</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>EIB</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TPB</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26ae294f-d3c0-4c67-abbb-69a9f46f3f99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26ae294f-d3c0-4c67-abbb-69a9f46f3f99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26ae294f-d3c0-4c67-abbb-69a9f46f3f99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the company which has more than 730 days (2 years) of stock price records"
      ],
      "metadata": {
        "id": "IVFUS1TfJvMi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBK8nVfsOw0Z"
      },
      "outputs": [],
      "source": [
        "#Preparing the list of names of bank.\n",
        "finName = []\n",
        "tickerName = []\n",
        "for file in companyAna[\"ticker\"]:\n",
        "  tempPath = \"stock-historical-data/\" + file +\"-*\"\n",
        "  for i in glob.glob(tempPath.format(\"csv\")):\n",
        "    temp = pd.read_csv(i, parse_dates = [\"TradingDate\"])\n",
        "    first = pd.to_datetime(temp[\"TradingDate\"][0], dayfirst= True)\n",
        "    last = pd.to_datetime(temp[\"TradingDate\"][len(temp)-1], dayfirst= True)\n",
        "    if (last-first > timedelta(days = 365)):\n",
        "      finName.append(i)\n",
        "      tickerName.append(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finName"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLpgf1Ko4Cfd",
        "outputId": "8ce11d73-ef9d-4051-c094-2494340b0140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stock-historical-data/VCB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/SSB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/BID-VNINDEX-History.csv',\n",
              " 'stock-historical-data/NVB-HNXIndex-History.csv',\n",
              " 'stock-historical-data/ACB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/BAB-HNXIndex-History.csv',\n",
              " 'stock-historical-data/VIB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/CTG-VNINDEX-History.csv',\n",
              " 'stock-historical-data/EIB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/TPB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/STB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/PGB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/VPB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/HDB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/MBB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/SGB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/LPB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/MSB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/OCB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/KLB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/TCB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/KLB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/VBB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/BVB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/SHB-VNINDEX-History.csv',\n",
              " 'stock-historical-data/NAB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/ABB-UpcomIndex-History.csv',\n",
              " 'stock-historical-data/VAB-UpcomIndex-History.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(finName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY0czizFJmcS",
        "outputId": "b5718a89-7161-4f30-cfe4-1227c49d28ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function define\n"
      ],
      "metadata": {
        "id": "3UAlHzs7w47w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Window sliding\n",
        "Split the data by using window sliding, with a window_size and prediction day - Using window_size data to predict (prediction day) stocks ahead"
      ],
      "metadata": {
        "id": "teykZ7rpxBDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ETmL6tzsqpM"
      },
      "outputs": [],
      "source": [
        "def window_sliding(data, window, prediction_day):\n",
        "  \"\"\"Load and split data into training features and labels\"\"\"\n",
        "  X_data, y_data = [], []\n",
        "  for i in range(len(data) - window- prediction_day):\n",
        "      X_data.append(data.iloc[i:i + window].to_numpy())\n",
        "      y_data.append(data.iloc[i + window:i + window + prediction_day].to_numpy())\n",
        "  return X_data, y_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Min max scaling normalization - denormalization\n",
        "LSTM model works best with data in rage [0,1], therefore data must be normalized using min-max scaling"
      ],
      "metadata": {
        "id": "hTuqz7A_xND4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atkNHbKZv46J"
      },
      "outputs": [],
      "source": [
        "# MinMax normalize the training data: x=(x-min(x)/(max(x)-min(x))\n",
        "# This works for the data after applying window sliding\n",
        "def minMaxScaling(X, y):\n",
        "  X_norm = X.copy()\n",
        "  y_norm = y.copy()\n",
        "  for i in range(0, len(X)):\n",
        "      min_feature = np.min(X[i])\n",
        "      max_feature = np.max(X[i])\n",
        "      X_norm[i] = (X[i] - min_feature) / (max_feature - min_feature)\n",
        "      y_norm[i] = (y[i] - min_feature) / (max_feature - min_feature)\n",
        "  return X_norm, y_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This works for the data after applying window sliding\n",
        "def denormMinMax(X, y):\n",
        "  # MinMax normalize the test data: norm_x = (x-min(x) / (max(x) - min(x))\n",
        "  X_denorm = X.copy()\n",
        "  y_denorm = y.copy()\n",
        "  for i in range(0, len(y)): # denorm_x = norm_x * (max(x) - min(x)) + min(x)\n",
        "    min_feature = np.min(X[i])\n",
        "    max_feature = np.max(X[i])\n",
        "    y_denorm[i] = y[i] * (max_feature - min_feature) + min_feature\n",
        "  return X_denorm, y_denorm"
      ],
      "metadata": {
        "id": "M6TJ98xm65YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This works for the data without being through window sliding\n",
        "def denorm_training(y, X):\n",
        "  min_feature = np.min(X)\n",
        "  max_feature = np.max(X)\n",
        "  return y * (max_feature - min_feature) + min_feature"
      ],
      "metadata": {
        "id": "xHwMBHF7wW1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This works for the data without being through window sliding\n",
        "def normalize_training(X):\n",
        "    min_feature = np.min(X)\n",
        "    max_feature = np.max(X)\n",
        "    X_norm = (X - min_feature) / (max_feature - min_feature)\n",
        "    return X_norm"
      ],
      "metadata": {
        "id": "EN35t9NpwKEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model creation using LSTM model"
      ],
      "metadata": {
        "id": "AYuXw4jexYXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRewgN70v7T6"
      },
      "outputs": [],
      "source": [
        "### Create and train the model\n",
        "\n",
        "def modelLSTM(X_train_norm, y_train_norm, X_test_norm, y_test_norm, feature, pDay):\n",
        "  ### Create the model\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Input(shape=(X_train_norm.shape[1:])))\n",
        "  model.add(keras.layers.LSTM(units=128, return_sequences=True))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(keras.layers.Dense((feature))) #Number of columns in original datas used for training\n",
        "  model.add(keras.layers.Cropping1D(cropping=(X_train_norm.shape[1] - pDay, 0))) #Getting the output shape as (None, prediction_day, feature)\n",
        "  model.summary()\n",
        "\n",
        "  #Training the model with callbacks for saving the best models, learning_rate reduction, and early stopping\n",
        "  from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "  mc = ModelCheckpoint(filepath=\"epoch-{epoch:02d}.hdf5\", # Path to save the model\n",
        "                                        monitor='val_mse', # Metric to evaluate the model performance when looking for a better model.\n",
        "                                        mode='min', # mode='auto'/'max'/'min': the monitor should be max/min to be better.\n",
        "                                                    # In auto mode, the mode is set to max if the quantities monitored are 'acc' or start with 'fmeasure' (f-score) and are set to min for the rest of the quantities.\n",
        "                                        verbose=0, # Inform every time a better model is found and saved.\n",
        "                                        save_best_only=True) # Only save the model if the current training epoch is the best. 'False' means save models of all training epochs\n",
        "  r_reduced = ReduceLROnPlateau(monitor='val_mse', mode='min', verbose = 0,\n",
        "                                  factor = 0.2, patience = 5, min_lr = 0.000001)\n",
        "  es = EarlyStopping(monitor='val_mse', mode='min', verbose=1, patience=10)\n",
        "  model.compile(optimizer=keras.optimizers.AdamW(learning_rate=0.0001), loss='mse', metrics=['mse'], run_eagerly=True)\n",
        "  model.fit(X_train_norm, y_train_norm, validation_data=(X_test_norm, y_test_norm), epochs=10,\n",
        "            batch_size=4096, callbacks = [mc, r_reduced, es], verbose=1)\n",
        "  # model.summary()\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Class for cross-validation\n",
        "This class works similarly to the function TimeSeriessplit(), except that it allows you to specify how much data for each training and validation set you want"
      ],
      "metadata": {
        "id": "o9vIwJ7exbks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Parameters\n",
        "----------\n",
        "train_period: int\n",
        "    number of days to include in the training set\n",
        "test_period: int\n",
        "    number of days to include in the validation set\n",
        "    default is 7\n",
        "freq: string\n",
        "    This parameter is useful when we pass the data with a column corresponding to the time of records. However, our data during the training process do not include the TradingDate column,\n",
        "    hence this parameter remains unused\n",
        "'''\n",
        "class TimeSeriesCV(object):\n",
        "\n",
        "\n",
        "    def __init__(self, train_period, test_period, freq='days'):\n",
        "        self.train_period = train_period\n",
        "        self.test_period = test_period\n",
        "        self.freq = freq\n",
        "\n",
        "\n",
        "    '''\n",
        "    Generate indices to split data into training and validation set\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: Original data.\n",
        "    gap: int, default=0\n",
        "        In case one wants to have a gap between training set and validation set\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    listTrain, listTest:\n",
        "        list of tuples (train index, test index) similar to sklearn model selection\n",
        "    '''\n",
        "    def split(self, data, gap=0):\n",
        "\n",
        "        listTrain = []\n",
        "        listTest = []\n",
        "\n",
        "        start_train = 0\n",
        "        end_train = start_train + self.train_period\n",
        "        start_test = end_train + gap\n",
        "        end_test = start_test + self.test_period\n",
        "\n",
        "        while end_test < data.shape[0]:\n",
        "            # train indices:\n",
        "            trainIndex = []\n",
        "            testIndex = []\n",
        "            for i in range(start_train, end_train):\n",
        "              trainIndex.append(i)\n",
        "            for i in range (start_test, end_test):\n",
        "              testIndex.append(i)\n",
        "\n",
        "            print(\"Train period:\",start_train,\"-\" , end_train, \", Test period\", start_test, \"-\", end_test,\n",
        "                  \"# train records\", len(trainIndex), \", # test records\", len(testIndex))\n",
        "\n",
        "            listTrain.append(trainIndex)\n",
        "            listTest.append(testIndex)\n",
        "\n",
        "            # update dates:\n",
        "            start_train = start_train\n",
        "            end_train += self.train_period\n",
        "            start_test = end_train + gap\n",
        "            end_test = start_test + self.test_period\n",
        "\n",
        "        # In case the end_test > data.shape[0], but there are still some remaining dates. In this case, the codes below cover the remaining index\n",
        "        end_test = data.shape[0]\n",
        "        start_test = end_test - self.test_period\n",
        "        end_train = start_test\n",
        "        trainIndex = []\n",
        "        testIndex = []\n",
        "        for i in range(start_train, end_train):\n",
        "          trainIndex.append(i)\n",
        "        for i in range (start_test, end_test):\n",
        "          testIndex.append(i)\n",
        "        listTrain.append(trainIndex)\n",
        "        listTest.append(testIndex)\n",
        "        print(\"Train period:\",start_train,\"-\" , end_train, \", Test period\", start_test, \"-\", end_test,\n",
        "                  \"# train records\", len(trainIndex), \", # test records\", len(testIndex))\n",
        "\n",
        "        index_output = [(train,test) for train,test in zip(listTrain, listTest)]\n",
        "        self.n_splits = len(index_output)\n",
        "\n",
        "        return index_output\n",
        "\n",
        "\n",
        "    def get_n_splits(self):\n",
        "        \"\"\"Returns the number of splitting iterations in the cross-validator\n",
        "        Returns\n",
        "        -------\n",
        "        n_splits : int\n",
        "            Returns the number of splitting iterations in the cross-validator.\n",
        "        \"\"\"\n",
        "        return self.n_splits"
      ],
      "metadata": {
        "id": "2VuZCg3YEwbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model training"
      ],
      "metadata": {
        "id": "-PXRKPfpxobB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the models using cross-validation technique to choose the best models"
      ],
      "metadata": {
        "id": "Q9xFYK7xSTpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose the features for the models\n",
        "columns = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "#Choose the window_size and prediction day\n",
        "window_size = 90\n",
        "prediction_day = 7\n",
        "#Array to save the best companies with best models\n",
        "goodCom = []\n",
        "goodComPath = []\n",
        "allMse = []\n",
        "#Cross-validation for each company to pick the best ones with the best models\n",
        "for name in finName:\n",
        "  #Pre-processing the data\n",
        "  data_for_modeling=pd.read_csv(name)[columns]\n",
        "  X_data, y_data = window_sliding(data_for_modeling, window_size, prediction_day)\n",
        "  X_data, y_data = np.array(X_data), np.array(y_data)\n",
        "  X_train, X_test, y_train, y_test= train_test_split(X_data, y_data, test_size=0.2, shuffle=False, random_state=0)\n",
        "  # y_train, y_test= train_test_split(y_data, test_size=0.2, shuffle=False, random_state=0)\n",
        "  X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
        "  X_test_norm, y_test_norm = minMaxScaling(X_test, y_test)\n",
        "  print(X_train.shape, y_train.shape)\n",
        "  print(\"Shape of test set: \", X_test.shape, y_test.shape)\n",
        "  #Array to save the models and mse values\n",
        "  ensemble = []\n",
        "  mses = []\n",
        "  #Create TimeBasedCV object with specifeid train and test periods. Frequency = 'day', although the parameters is useless for this case\n",
        "  tscv = TimeSeriesCV(train_period=365,\n",
        "                    test_period=180,\n",
        "                    freq='days')\n",
        "  #Cross-validation for the folds by TimeSeriesCV object\n",
        "  for train_index, test_index in tscv.split(X_train):\n",
        "    #Picking up the data\n",
        "      X_train_VC   = X_train[train_index]\n",
        "      y_train_VC = y_train[train_index]\n",
        "\n",
        "      X_val_VC    = X_train[test_index]\n",
        "      y_val_VC  = y_train[test_index]\n",
        "\n",
        "      #Normalize the data features and labels\n",
        "      X_train_norm, y_train_norm = minMaxScaling(X_train_VC, y_train_VC)\n",
        "      X_val_norm, y_val_norm = minMaxScaling(X_val_VC, y_val_VC)\n",
        "\n",
        "      #Call the model to train on the data\n",
        "      model1 = modelLSTM(X_train_norm, y_train_norm, X_val_norm, y_val_norm, len(columns), prediction_day)\n",
        "      #Append the model for later evaluation\n",
        "      ensemble.append(model1)\n",
        "      loss, mse = model1.evaluate(X_test_norm, y_test_norm, verbose=0)\n",
        "      mses.append(mse)\n",
        "\n",
        "  overall_mse = np.average(mses)\n",
        "  allMse.append(overall_mse)\n",
        "  print(\"Overall MSE: \", overall_mse)\n",
        "# Pick the models with mse lower than the threshold\n",
        "  if overall_mse < goodmse:\n",
        "     goodCom.append(tickerName[finName.index(name)])\n",
        "     goodComPath.append(name)\n",
        "     ensemble[np.argmin(mses)].save(filepath=bestModelDir + tickerName[finName.index(name)], include_optimizer=False)\n",
        "     data_for_modeling[\"ticker\"] = tickerName[finName.index(name)]"
      ],
      "metadata": {
        "id": "ZMIc5n7YGmNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bbb16e-b76e-44f5-d503-13c2b79d3a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2652, 90, 4) (2652, 7, 4)\n",
            "Shape of test set:  (664, 90, 4) (664, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2472 , Test period 2472 - 2652 # train records 2472 , # test records 180\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d (Cropping1D)     (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe6ce935870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step - loss: 0.1911 - mse: 0.1911 - val_loss: 0.2101 - val_mse: 0.2101 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1878 - mse: 0.1878 - val_loss: 0.2054 - val_mse: 0.2054 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.1828 - mse: 0.1828 - val_loss: 0.2007 - val_mse: 0.2007 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 0.1962 - val_mse: 0.1962 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 0.1916 - val_mse: 0.1916 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1720 - mse: 0.1720 - val_loss: 0.1871 - val_mse: 0.1871 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1696 - mse: 0.1696 - val_loss: 0.1827 - val_mse: 0.1827 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.1659 - mse: 0.1659 - val_loss: 0.1783 - val_mse: 0.1783 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.1623 - mse: 0.1623 - val_loss: 0.1739 - val_mse: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1588 - mse: 0.1588 - val_loss: 0.1696 - val_mse: 0.1696 - lr: 1.0000e-04\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_1 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 50 calls to <function _BaseOptimizer._update_step_xla at 0x7fe6c02783a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2493 - mse: 0.2493 - val_loss: 0.4617 - val_mse: 0.4617 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.4502 - val_mse: 0.4502 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2374 - mse: 0.2374 - val_loss: 0.4390 - val_mse: 0.4390 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2308 - mse: 0.2308 - val_loss: 0.4279 - val_mse: 0.4279 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.4170 - val_mse: 0.4170 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.4063 - val_mse: 0.4063 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2124 - mse: 0.2124 - val_loss: 0.3958 - val_mse: 0.3958 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2086 - mse: 0.2086 - val_loss: 0.3854 - val_mse: 0.3854 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2028 - mse: 0.2028 - val_loss: 0.3751 - val_mse: 0.3751 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.1967 - mse: 0.1967 - val_loss: 0.3650 - val_mse: 0.3650 - lr: 1.0000e-04\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_2 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2705 - mse: 0.2705 - val_loss: 0.4573 - val_mse: 0.4573 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2643 - mse: 0.2643 - val_loss: 0.4450 - val_mse: 0.4450 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2571 - mse: 0.2571 - val_loss: 0.4329 - val_mse: 0.4329 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2510 - mse: 0.2510 - val_loss: 0.4210 - val_mse: 0.4210 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.4092 - val_mse: 0.4092 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2388 - mse: 0.2388 - val_loss: 0.3976 - val_mse: 0.3976 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 0.3861 - val_mse: 0.3861 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.3748 - val_mse: 0.3748 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.2125 - mse: 0.2125 - val_loss: 0.3526 - val_mse: 0.3526 - lr: 1.0000e-04\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_3 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.3727 - mse: 0.3727 - val_loss: 0.2740 - val_mse: 0.2740 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3630 - mse: 0.3630 - val_loss: 0.2670 - val_mse: 0.2670 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3540 - mse: 0.3540 - val_loss: 0.2602 - val_mse: 0.2602 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3452 - mse: 0.3452 - val_loss: 0.2534 - val_mse: 0.2534 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3366 - mse: 0.3366 - val_loss: 0.2467 - val_mse: 0.2467 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3280 - mse: 0.3280 - val_loss: 0.2401 - val_mse: 0.2401 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3197 - mse: 0.3197 - val_loss: 0.2336 - val_mse: 0.2336 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3118 - mse: 0.3118 - val_loss: 0.2271 - val_mse: 0.2271 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3035 - mse: 0.3035 - val_loss: 0.2206 - val_mse: 0.2206 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2947 - mse: 0.2947 - val_loss: 0.2143 - val_mse: 0.2143 - lr: 1.0000e-04\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_4 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.4050 - mse: 0.4050 - val_loss: 0.4637 - val_mse: 0.4637 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3954 - mse: 0.3954 - val_loss: 0.4537 - val_mse: 0.4537 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3861 - mse: 0.3861 - val_loss: 0.4438 - val_mse: 0.4438 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.3779 - mse: 0.3779 - val_loss: 0.4340 - val_mse: 0.4340 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3695 - mse: 0.3695 - val_loss: 0.4243 - val_mse: 0.4243 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3605 - mse: 0.3605 - val_loss: 0.4147 - val_mse: 0.4147 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3514 - mse: 0.3514 - val_loss: 0.4053 - val_mse: 0.4053 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.3426 - mse: 0.3426 - val_loss: 0.3959 - val_mse: 0.3959 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3350 - mse: 0.3350 - val_loss: 0.3866 - val_mse: 0.3866 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3284 - mse: 0.3284 - val_loss: 0.3774 - val_mse: 0.3774 - lr: 1.0000e-04\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_5 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4952 - mse: 0.4952 - val_loss: 0.5991 - val_mse: 0.5991 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.4841 - mse: 0.4841 - val_loss: 0.5837 - val_mse: 0.5837 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.4707 - mse: 0.4707 - val_loss: 0.5686 - val_mse: 0.5686 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4594 - mse: 0.4594 - val_loss: 0.5540 - val_mse: 0.5540 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.4500 - mse: 0.4500 - val_loss: 0.5396 - val_mse: 0.5396 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.4384 - mse: 0.4384 - val_loss: 0.5256 - val_mse: 0.5256 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.4276 - mse: 0.4276 - val_loss: 0.5119 - val_mse: 0.5119 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4182 - mse: 0.4182 - val_loss: 0.4986 - val_mse: 0.4986 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4093 - mse: 0.4093 - val_loss: 0.4855 - val_mse: 0.4855 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3986 - mse: 0.3986 - val_loss: 0.4727 - val_mse: 0.4727 - lr: 1.0000e-04\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_6 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.4933 - mse: 0.4933 - val_loss: 0.5522 - val_mse: 0.5522 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4811 - mse: 0.4811 - val_loss: 0.5378 - val_mse: 0.5378 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4683 - mse: 0.4683 - val_loss: 0.5237 - val_mse: 0.5237 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.5098 - val_mse: 0.5098 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4460 - mse: 0.4460 - val_loss: 0.4962 - val_mse: 0.4962 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4345 - mse: 0.4345 - val_loss: 0.4828 - val_mse: 0.4828 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4247 - mse: 0.4247 - val_loss: 0.4697 - val_mse: 0.4697 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4137 - mse: 0.4137 - val_loss: 0.4567 - val_mse: 0.4567 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4003 - mse: 0.4003 - val_loss: 0.4441 - val_mse: 0.4441 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3921 - mse: 0.3921 - val_loss: 0.4316 - val_mse: 0.4316 - lr: 1.0000e-04\n",
            "Overall MSE:  0.32936919586999075\n",
            "(308, 90, 4) (308, 7, 4)\n",
            "Shape of test set:  (78, 90, 4) (78, 7, 4)\n",
            "Train period: 0 - 128 , Test period 128 - 308 # train records 128 , # test records 180\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_7 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.7253 - mse: 0.7253 - val_loss: 0.4558 - val_mse: 0.4558 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.7133 - mse: 0.7133 - val_loss: 0.4452 - val_mse: 0.4452 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.6943 - mse: 0.6943 - val_loss: 0.4347 - val_mse: 0.4347 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.6792 - mse: 0.6792 - val_loss: 0.4245 - val_mse: 0.4245 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6661 - mse: 0.6661 - val_loss: 0.4144 - val_mse: 0.4144 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.6514 - mse: 0.6514 - val_loss: 0.4045 - val_mse: 0.4045 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.3947 - val_mse: 0.3947 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.6234 - mse: 0.6234 - val_loss: 0.3851 - val_mse: 0.3851 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6137 - mse: 0.6137 - val_loss: 0.3757 - val_mse: 0.3757 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.5997 - mse: 0.5997 - val_loss: 0.3663 - val_mse: 0.3663 - lr: 1.0000e-04\n",
            "Overall MSE:  0.5039544701576233\n",
            "(1736, 90, 4) (1736, 7, 4)\n",
            "Shape of test set:  (434, 90, 4) (434, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1556 , Test period 1556 - 1736 # train records 1556 , # test records 180\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_8 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.4652 - mse: 0.4652 - val_loss: 0.1727 - val_mse: 0.1727 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.4549 - mse: 0.4549 - val_loss: 0.1672 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.4416 - mse: 0.4416 - val_loss: 0.1617 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.4292 - mse: 0.4292 - val_loss: 0.1564 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.4202 - mse: 0.4202 - val_loss: 0.1511 - val_mse: 0.1511 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.4116 - mse: 0.4116 - val_loss: 0.1458 - val_mse: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.4017 - mse: 0.4017 - val_loss: 0.1406 - val_mse: 0.1406 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.3885 - mse: 0.3885 - val_loss: 0.1355 - val_mse: 0.1355 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.1304 - val_mse: 0.1304 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3717 - mse: 0.3717 - val_loss: 0.1254 - val_mse: 0.1254 - lr: 1.0000e-04\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_9 (Cropping1D)   (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.7370 - val_mse: 0.7370 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.3578 - mse: 0.3578 - val_loss: 0.7241 - val_mse: 0.7241 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.3505 - mse: 0.3505 - val_loss: 0.7113 - val_mse: 0.7113 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3429 - mse: 0.3429 - val_loss: 0.6986 - val_mse: 0.6986 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.3367 - mse: 0.3367 - val_loss: 0.6860 - val_mse: 0.6860 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.3297 - mse: 0.3297 - val_loss: 0.6736 - val_mse: 0.6736 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3255 - mse: 0.3255 - val_loss: 0.6612 - val_mse: 0.6612 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3184 - mse: 0.3184 - val_loss: 0.6489 - val_mse: 0.6489 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3098 - mse: 0.3098 - val_loss: 0.6367 - val_mse: 0.6367 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3049 - mse: 0.3049 - val_loss: 0.6247 - val_mse: 0.6247 - lr: 1.0000e-04\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_10 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.4882 - mse: 0.4882 - val_loss: 0.3686 - val_mse: 0.3686 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4799 - mse: 0.4799 - val_loss: 0.3606 - val_mse: 0.3606 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4708 - mse: 0.4708 - val_loss: 0.3528 - val_mse: 0.3528 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.4618 - mse: 0.4618 - val_loss: 0.3450 - val_mse: 0.3450 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.4525 - mse: 0.4525 - val_loss: 0.3374 - val_mse: 0.3374 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4448 - mse: 0.4448 - val_loss: 0.3298 - val_mse: 0.3298 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.4354 - mse: 0.4354 - val_loss: 0.3224 - val_mse: 0.3224 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4270 - mse: 0.4270 - val_loss: 0.3151 - val_mse: 0.3151 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4178 - mse: 0.4178 - val_loss: 0.3079 - val_mse: 0.3079 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4091 - mse: 0.4091 - val_loss: 0.3007 - val_mse: 0.3007 - lr: 1.0000e-04\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_11 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_11 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4496 - mse: 0.4496 - val_loss: 0.3820 - val_mse: 0.3820 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.4390 - mse: 0.4390 - val_loss: 0.3718 - val_mse: 0.3718 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.4273 - mse: 0.4273 - val_loss: 0.3618 - val_mse: 0.3618 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.4161 - mse: 0.4161 - val_loss: 0.3519 - val_mse: 0.3519 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.4061 - mse: 0.4061 - val_loss: 0.3422 - val_mse: 0.3422 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3948 - mse: 0.3948 - val_loss: 0.3326 - val_mse: 0.3326 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3846 - mse: 0.3846 - val_loss: 0.3231 - val_mse: 0.3231 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.3138 - val_mse: 0.3138 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3633 - mse: 0.3633 - val_loss: 0.3046 - val_mse: 0.3046 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3535 - mse: 0.3535 - val_loss: 0.2955 - val_mse: 0.2955 - lr: 1.0000e-04\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_12 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.4231 - mse: 0.4231 - val_loss: 0.3905 - val_mse: 0.3905 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.4117 - mse: 0.4117 - val_loss: 0.3810 - val_mse: 0.3810 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.4028 - mse: 0.4028 - val_loss: 0.3717 - val_mse: 0.3717 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3916 - mse: 0.3916 - val_loss: 0.3625 - val_mse: 0.3625 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3829 - mse: 0.3829 - val_loss: 0.3535 - val_mse: 0.3535 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3729 - mse: 0.3729 - val_loss: 0.3445 - val_mse: 0.3445 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3631 - mse: 0.3631 - val_loss: 0.3358 - val_mse: 0.3358 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3552 - mse: 0.3552 - val_loss: 0.3271 - val_mse: 0.3271 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3472 - mse: 0.3472 - val_loss: 0.3185 - val_mse: 0.3185 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3372 - mse: 0.3372 - val_loss: 0.3100 - val_mse: 0.3100 - lr: 1.0000e-04\n",
            "Overall MSE:  0.29909762740135193\n",
            "(2411, 90, 4) (2411, 7, 4)\n",
            "Shape of test set:  (603, 90, 4) (603, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2231 , Test period 2231 - 2411 # train records 2231 , # test records 180\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_13 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2038 - mse: 0.2038 - val_loss: 0.1887 - val_mse: 0.1887 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 0.1833 - val_mse: 0.1833 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1912 - mse: 0.1912 - val_loss: 0.1781 - val_mse: 0.1781 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1846 - mse: 0.1846 - val_loss: 0.1730 - val_mse: 0.1730 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.1680 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.1746 - mse: 0.1746 - val_loss: 0.1632 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.1705 - mse: 0.1705 - val_loss: 0.1585 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1664 - mse: 0.1664 - val_loss: 0.1539 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.1611 - mse: 0.1611 - val_loss: 0.1494 - val_mse: 0.1494 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1551 - mse: 0.1551 - val_loss: 0.1451 - val_mse: 0.1451 - lr: 1.0000e-04\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_14 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_14 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2087 - mse: 0.2087 - val_loss: 0.2488 - val_mse: 0.2488 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.2020 - mse: 0.2020 - val_loss: 0.2409 - val_mse: 0.2409 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1968 - mse: 0.1968 - val_loss: 0.2332 - val_mse: 0.2332 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1916 - mse: 0.1916 - val_loss: 0.2256 - val_mse: 0.2256 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.1846 - mse: 0.1846 - val_loss: 0.2182 - val_mse: 0.2182 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.1802 - mse: 0.1802 - val_loss: 0.2109 - val_mse: 0.2109 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.1743 - mse: 0.1743 - val_loss: 0.2038 - val_mse: 0.2038 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1700 - mse: 0.1700 - val_loss: 0.1968 - val_mse: 0.1968 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1648 - mse: 0.1648 - val_loss: 0.1900 - val_mse: 0.1900 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1595 - mse: 0.1595 - val_loss: 0.1833 - val_mse: 0.1833 - lr: 1.0000e-04\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_15 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_15 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2660 - mse: 0.2660 - val_loss: 0.2524 - val_mse: 0.2524 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2595 - mse: 0.2595 - val_loss: 0.2464 - val_mse: 0.2464 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2404 - val_mse: 0.2404 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 0.2345 - val_mse: 0.2345 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2422 - mse: 0.2422 - val_loss: 0.2286 - val_mse: 0.2286 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2228 - val_mse: 0.2228 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2310 - mse: 0.2310 - val_loss: 0.2170 - val_mse: 0.2170 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.2113 - val_mse: 0.2113 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2201 - mse: 0.2201 - val_loss: 0.2056 - val_mse: 0.2056 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2000 - val_mse: 0.2000 - lr: 1.0000e-04\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_16 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1878 - mse: 0.1878 - val_loss: 0.3150 - val_mse: 0.3150 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1828 - mse: 0.1828 - val_loss: 0.3094 - val_mse: 0.3094 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1765 - mse: 0.1765 - val_loss: 0.3040 - val_mse: 0.3040 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.1710 - mse: 0.1710 - val_loss: 0.2987 - val_mse: 0.2987 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1660 - mse: 0.1660 - val_loss: 0.2935 - val_mse: 0.2935 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 0.2884 - val_mse: 0.2884 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.1550 - mse: 0.1550 - val_loss: 0.2834 - val_mse: 0.2834 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 0.2785 - val_mse: 0.2785 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.1452 - mse: 0.1452 - val_loss: 0.2736 - val_mse: 0.2736 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1400 - mse: 0.1400 - val_loss: 0.2689 - val_mse: 0.2689 - lr: 1.0000e-04\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_17 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_17 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.2017 - mse: 0.2017 - val_loss: 0.3226 - val_mse: 0.3226 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1970 - mse: 0.1970 - val_loss: 0.3150 - val_mse: 0.3150 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.1925 - mse: 0.1925 - val_loss: 0.3075 - val_mse: 0.3075 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1891 - mse: 0.1891 - val_loss: 0.3001 - val_mse: 0.3001 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 0.2928 - val_mse: 0.2928 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1799 - mse: 0.1799 - val_loss: 0.2856 - val_mse: 0.2856 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 0.2785 - val_mse: 0.2785 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.1724 - mse: 0.1724 - val_loss: 0.2715 - val_mse: 0.2715 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.1679 - mse: 0.1679 - val_loss: 0.2645 - val_mse: 0.2645 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.1642 - mse: 0.1642 - val_loss: 0.2576 - val_mse: 0.2576 - lr: 1.0000e-04\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_18 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_18 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2544 - mse: 0.2544 - val_loss: 0.3796 - val_mse: 0.3796 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2477 - mse: 0.2477 - val_loss: 0.3692 - val_mse: 0.3692 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.2414 - mse: 0.2414 - val_loss: 0.3590 - val_mse: 0.3590 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.3489 - val_mse: 0.3489 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 0.3389 - val_mse: 0.3389 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.3290 - val_mse: 0.3290 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2182 - mse: 0.2182 - val_loss: 0.3193 - val_mse: 0.3193 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2116 - mse: 0.2116 - val_loss: 0.3096 - val_mse: 0.3096 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.3000 - val_mse: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 0.2905 - val_mse: 0.2905 - lr: 1.0000e-04\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_19 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_19 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3133 - mse: 0.3133 - val_loss: 0.3201 - val_mse: 0.3201 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.3075 - mse: 0.3075 - val_loss: 0.3117 - val_mse: 0.3117 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.3002 - mse: 0.3002 - val_loss: 0.3035 - val_mse: 0.3035 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.2918 - mse: 0.2918 - val_loss: 0.2954 - val_mse: 0.2954 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.2853 - mse: 0.2853 - val_loss: 0.2875 - val_mse: 0.2875 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.2788 - mse: 0.2788 - val_loss: 0.2796 - val_mse: 0.2796 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.2718 - mse: 0.2718 - val_loss: 0.2718 - val_mse: 0.2718 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2653 - mse: 0.2653 - val_loss: 0.2642 - val_mse: 0.2642 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2594 - mse: 0.2594 - val_loss: 0.2566 - val_mse: 0.2566 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.2529 - mse: 0.2529 - val_loss: 0.2491 - val_mse: 0.2491 - lr: 1.0000e-04\n",
            "Overall MSE:  0.3899608254432678\n",
            "(3164, 90, 4) (3164, 7, 4)\n",
            "Shape of test set:  (791, 90, 4) (791, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2555 , Test period 2555 - 2735 # train records 2555 , # test records 180\n",
            "Train period: 0 - 2920 , Test period 2920 - 3100 # train records 2920 , # test records 180\n",
            "Train period: 0 - 2984 , Test period 2984 - 3164 # train records 2984 , # test records 180\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_20 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2076 - mse: 0.2076 - val_loss: 0.3529 - val_mse: 0.3529 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2017 - mse: 0.2017 - val_loss: 0.3450 - val_mse: 0.3450 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1964 - mse: 0.1964 - val_loss: 0.3373 - val_mse: 0.3373 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1910 - mse: 0.1910 - val_loss: 0.3296 - val_mse: 0.3296 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1862 - mse: 0.1862 - val_loss: 0.3219 - val_mse: 0.3219 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.1804 - mse: 0.1804 - val_loss: 0.3144 - val_mse: 0.3144 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1781 - mse: 0.1781 - val_loss: 0.3069 - val_mse: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.2995 - val_mse: 0.2995 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1676 - mse: 0.1676 - val_loss: 0.2921 - val_mse: 0.2921 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1613 - mse: 0.1613 - val_loss: 0.2849 - val_mse: 0.2849 - lr: 1.0000e-04\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_21 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_21 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.3109 - mse: 0.3109 - val_loss: 0.0479 - val_mse: 0.0479 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3052 - mse: 0.3052 - val_loss: 0.0465 - val_mse: 0.0465 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.2984 - mse: 0.2984 - val_loss: 0.0450 - val_mse: 0.0450 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2925 - mse: 0.2925 - val_loss: 0.0437 - val_mse: 0.0437 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2859 - mse: 0.2859 - val_loss: 0.0423 - val_mse: 0.0423 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2795 - mse: 0.2795 - val_loss: 0.0410 - val_mse: 0.0410 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2721 - mse: 0.2721 - val_loss: 0.0397 - val_mse: 0.0397 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2656 - mse: 0.2656 - val_loss: 0.0385 - val_mse: 0.0385 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.2604 - mse: 0.2604 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2538 - mse: 0.2538 - val_loss: 0.0361 - val_mse: 0.0361 - lr: 1.0000e-04\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_22 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_22 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2588 - mse: 0.2588 - val_loss: 0.4761 - val_mse: 0.4761 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.2535 - mse: 0.2535 - val_loss: 0.4665 - val_mse: 0.4665 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2478 - mse: 0.2478 - val_loss: 0.4571 - val_mse: 0.4571 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2410 - mse: 0.2410 - val_loss: 0.4478 - val_mse: 0.4478 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2351 - mse: 0.2351 - val_loss: 0.4386 - val_mse: 0.4386 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 0.4295 - val_mse: 0.4295 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.4206 - val_mse: 0.4206 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2192 - mse: 0.2192 - val_loss: 0.4118 - val_mse: 0.4118 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2154 - mse: 0.2154 - val_loss: 0.4030 - val_mse: 0.4030 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.2104 - mse: 0.2104 - val_loss: 0.3944 - val_mse: 0.3944 - lr: 1.0000e-04\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_23 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_23 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 0.1987 - val_mse: 0.1987 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 0.1912 - val_mse: 0.1912 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.2162 - mse: 0.2162 - val_loss: 0.1838 - val_mse: 0.1838 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2109 - mse: 0.2109 - val_loss: 0.1766 - val_mse: 0.1766 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2046 - mse: 0.2046 - val_loss: 0.1695 - val_mse: 0.1695 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1989 - mse: 0.1989 - val_loss: 0.1626 - val_mse: 0.1626 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1934 - mse: 0.1934 - val_loss: 0.1558 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1884 - mse: 0.1884 - val_loss: 0.1491 - val_mse: 0.1491 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 0.1425 - val_mse: 0.1425 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.1774 - mse: 0.1774 - val_loss: 0.1361 - val_mse: 0.1361 - lr: 1.0000e-04\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_24 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_24 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2619 - mse: 0.2619 - val_loss: 0.2639 - val_mse: 0.2639 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 0.2573 - val_mse: 0.2573 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2474 - mse: 0.2474 - val_loss: 0.2507 - val_mse: 0.2507 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2417 - mse: 0.2417 - val_loss: 0.2443 - val_mse: 0.2443 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.2334 - mse: 0.2334 - val_loss: 0.2379 - val_mse: 0.2379 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.2317 - val_mse: 0.2317 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.2256 - val_mse: 0.2256 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2196 - val_mse: 0.2196 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 0.2136 - val_mse: 0.2136 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.2016 - mse: 0.2016 - val_loss: 0.2078 - val_mse: 0.2078 - lr: 1.0000e-04\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_25 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_25 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.1182 - val_mse: 0.1182 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.1150 - val_mse: 0.1150 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2161 - mse: 0.2161 - val_loss: 0.1119 - val_mse: 0.1119 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2104 - mse: 0.2104 - val_loss: 0.1088 - val_mse: 0.1088 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 0.1058 - val_mse: 0.1058 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1995 - mse: 0.1995 - val_loss: 0.1029 - val_mse: 0.1029 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.1931 - mse: 0.1931 - val_loss: 0.1000 - val_mse: 0.1000 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.1887 - mse: 0.1887 - val_loss: 0.0971 - val_mse: 0.0971 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1829 - mse: 0.1829 - val_loss: 0.0943 - val_mse: 0.0943 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1782 - mse: 0.1782 - val_loss: 0.0916 - val_mse: 0.0916 - lr: 1.0000e-04\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_26 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_26 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.3398 - mse: 0.3398 - val_loss: 0.9488 - val_mse: 0.9488 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.3323 - mse: 0.3323 - val_loss: 0.9280 - val_mse: 0.9280 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3250 - mse: 0.3250 - val_loss: 0.9075 - val_mse: 0.9075 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3178 - mse: 0.3178 - val_loss: 0.8874 - val_mse: 0.8874 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3112 - mse: 0.3112 - val_loss: 0.8677 - val_mse: 0.8677 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.3038 - mse: 0.3038 - val_loss: 0.8483 - val_mse: 0.8483 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2969 - mse: 0.2969 - val_loss: 0.8292 - val_mse: 0.8292 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2908 - mse: 0.2908 - val_loss: 0.8104 - val_mse: 0.8104 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2839 - mse: 0.2839 - val_loss: 0.7919 - val_mse: 0.7919 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2769 - mse: 0.2769 - val_loss: 0.7735 - val_mse: 0.7735 - lr: 1.0000e-04\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_27 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_27 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3221 - mse: 0.3221 - val_loss: 0.2412 - val_mse: 0.2412 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.3133 - mse: 0.3133 - val_loss: 0.2338 - val_mse: 0.2338 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.3058 - mse: 0.3058 - val_loss: 0.2266 - val_mse: 0.2266 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 0.2195 - val_mse: 0.2195 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.2909 - mse: 0.2909 - val_loss: 0.2125 - val_mse: 0.2125 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.2833 - mse: 0.2833 - val_loss: 0.2057 - val_mse: 0.2057 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.2754 - mse: 0.2754 - val_loss: 0.1990 - val_mse: 0.1990 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.2688 - mse: 0.2688 - val_loss: 0.1924 - val_mse: 0.1924 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.2614 - mse: 0.2614 - val_loss: 0.1859 - val_mse: 0.1859 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.2536 - mse: 0.2536 - val_loss: 0.1796 - val_mse: 0.1796 - lr: 1.0000e-04\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_28 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_28 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2317 - mse: 0.2317 - val_loss: 0.1784 - val_mse: 0.1784 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.1722 - val_mse: 0.1722 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.1661 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2126 - mse: 0.2126 - val_loss: 0.1601 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2068 - mse: 0.2068 - val_loss: 0.1542 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.2002 - mse: 0.2002 - val_loss: 0.1485 - val_mse: 0.1485 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1952 - mse: 0.1952 - val_loss: 0.1428 - val_mse: 0.1428 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.1888 - mse: 0.1888 - val_loss: 0.1373 - val_mse: 0.1373 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1840 - mse: 0.1840 - val_loss: 0.1318 - val_mse: 0.1318 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1784 - mse: 0.1784 - val_loss: 0.1265 - val_mse: 0.1265 - lr: 1.0000e-04\n",
            "Overall MSE:  0.36142922937870026\n",
            "(950, 90, 4) (950, 7, 4)\n",
            "Shape of test set:  (238, 90, 4) (238, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 770 , Test period 770 - 950 # train records 770 , # test records 180\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_29 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_29 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 0.4339 - val_mse: 0.4339 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 0.4221 - val_mse: 0.4221 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.4105 - val_mse: 0.4105 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.3989 - val_mse: 0.3989 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2315 - mse: 0.2315 - val_loss: 0.3875 - val_mse: 0.3875 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.3761 - val_mse: 0.3761 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.2217 - mse: 0.2217 - val_loss: 0.3649 - val_mse: 0.3649 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2175 - mse: 0.2175 - val_loss: 0.3537 - val_mse: 0.3537 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2143 - mse: 0.2143 - val_loss: 0.3427 - val_mse: 0.3427 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2095 - mse: 0.2095 - val_loss: 0.3317 - val_mse: 0.3317 - lr: 1.0000e-04\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_30 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_30 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4303 - mse: 0.4303 - val_loss: 0.1657 - val_mse: 0.1657 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4183 - mse: 0.4183 - val_loss: 0.1607 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.4095 - mse: 0.4095 - val_loss: 0.1558 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.4029 - mse: 0.4029 - val_loss: 0.1511 - val_mse: 0.1511 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3924 - mse: 0.3924 - val_loss: 0.1464 - val_mse: 0.1464 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.1419 - val_mse: 0.1419 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 0.1375 - val_mse: 0.1375 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3661 - mse: 0.3661 - val_loss: 0.1332 - val_mse: 0.1332 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3563 - mse: 0.3563 - val_loss: 0.1289 - val_mse: 0.1289 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3489 - mse: 0.3489 - val_loss: 0.1248 - val_mse: 0.1248 - lr: 1.0000e-04\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_31 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_31 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4074 - mse: 0.4074 - val_loss: 0.1340 - val_mse: 0.1340 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3978 - mse: 0.3978 - val_loss: 0.1300 - val_mse: 0.1300 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3910 - mse: 0.3910 - val_loss: 0.1260 - val_mse: 0.1260 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3811 - mse: 0.3811 - val_loss: 0.1221 - val_mse: 0.1221 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3716 - mse: 0.3716 - val_loss: 0.1182 - val_mse: 0.1182 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.3631 - mse: 0.3631 - val_loss: 0.1145 - val_mse: 0.1145 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.1108 - val_mse: 0.1108 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.3472 - mse: 0.3472 - val_loss: 0.1072 - val_mse: 0.1072 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3362 - mse: 0.3362 - val_loss: 0.1036 - val_mse: 0.1036 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3290 - mse: 0.3290 - val_loss: 0.1002 - val_mse: 0.1002 - lr: 1.0000e-04\n",
            "Overall MSE:  0.056449200958013535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1143, 90, 4) (1143, 7, 4)\n",
            "Shape of test set:  (286, 90, 4) (286, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 963 , Test period 963 - 1143 # train records 963 , # test records 180\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_32 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_32 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4165 - mse: 0.4165 - val_loss: 0.2464 - val_mse: 0.2464 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.4070 - mse: 0.4070 - val_loss: 0.2407 - val_mse: 0.2407 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.3970 - mse: 0.3970 - val_loss: 0.2351 - val_mse: 0.2351 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.3902 - mse: 0.3902 - val_loss: 0.2296 - val_mse: 0.2296 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.3814 - mse: 0.3814 - val_loss: 0.2242 - val_mse: 0.2242 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.3729 - mse: 0.3729 - val_loss: 0.2188 - val_mse: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.3633 - mse: 0.3633 - val_loss: 0.2136 - val_mse: 0.2136 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.3562 - mse: 0.3562 - val_loss: 0.2084 - val_mse: 0.2084 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.3477 - mse: 0.3477 - val_loss: 0.2033 - val_mse: 0.2033 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.3370 - mse: 0.3370 - val_loss: 0.1983 - val_mse: 0.1983 - lr: 1.0000e-04\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_33 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_33 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3386 - mse: 0.3386 - val_loss: 0.7388 - val_mse: 0.7388 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3308 - mse: 0.3308 - val_loss: 0.7217 - val_mse: 0.7217 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3232 - mse: 0.3232 - val_loss: 0.7047 - val_mse: 0.7047 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3145 - mse: 0.3145 - val_loss: 0.6879 - val_mse: 0.6879 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.3078 - mse: 0.3078 - val_loss: 0.6712 - val_mse: 0.6712 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2977 - mse: 0.2977 - val_loss: 0.6547 - val_mse: 0.6547 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.2929 - mse: 0.2929 - val_loss: 0.6383 - val_mse: 0.6383 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2841 - mse: 0.2841 - val_loss: 0.6221 - val_mse: 0.6221 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2759 - mse: 0.2759 - val_loss: 0.6060 - val_mse: 0.6060 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 0.5900 - val_mse: 0.5900 - lr: 1.0000e-04\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_34 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_34 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.4253 - mse: 0.4253 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4147 - mse: 0.4147 - val_loss: 0.3741 - val_mse: 0.3741 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.4065 - mse: 0.4065 - val_loss: 0.3644 - val_mse: 0.3644 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3952 - mse: 0.3952 - val_loss: 0.3548 - val_mse: 0.3548 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3858 - mse: 0.3858 - val_loss: 0.3453 - val_mse: 0.3453 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3773 - mse: 0.3773 - val_loss: 0.3358 - val_mse: 0.3358 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3658 - mse: 0.3658 - val_loss: 0.3264 - val_mse: 0.3264 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3587 - mse: 0.3587 - val_loss: 0.3171 - val_mse: 0.3171 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3482 - mse: 0.3482 - val_loss: 0.3078 - val_mse: 0.3078 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3410 - mse: 0.3410 - val_loss: 0.2986 - val_mse: 0.2986 - lr: 1.0000e-04\n",
            "Overall MSE:  0.21154641608397165\n",
            "(2643, 90, 4) (2643, 7, 4)\n",
            "Shape of test set:  (661, 90, 4) (661, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2463 , Test period 2463 - 2643 # train records 2463 , # test records 180\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_35 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_35 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.3042 - mse: 0.3042 - val_loss: 0.1499 - val_mse: 0.1499 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2989 - mse: 0.2989 - val_loss: 0.1462 - val_mse: 0.1462 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2919 - mse: 0.2919 - val_loss: 0.1426 - val_mse: 0.1426 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2872 - mse: 0.2872 - val_loss: 0.1391 - val_mse: 0.1391 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2797 - mse: 0.2797 - val_loss: 0.1356 - val_mse: 0.1356 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2741 - mse: 0.2741 - val_loss: 0.1322 - val_mse: 0.1322 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2678 - mse: 0.2678 - val_loss: 0.1288 - val_mse: 0.1288 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2623 - mse: 0.2623 - val_loss: 0.1255 - val_mse: 0.1255 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 0.1223 - val_mse: 0.1223 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2492 - mse: 0.2492 - val_loss: 0.1191 - val_mse: 0.1191 - lr: 1.0000e-04\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_36 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_36 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.4289 - mse: 0.4289 - val_loss: 0.4056 - val_mse: 0.4056 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4179 - mse: 0.4179 - val_loss: 0.3976 - val_mse: 0.3976 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4105 - mse: 0.4105 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4037 - mse: 0.4037 - val_loss: 0.3824 - val_mse: 0.3824 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3935 - mse: 0.3935 - val_loss: 0.3750 - val_mse: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3897 - mse: 0.3897 - val_loss: 0.3678 - val_mse: 0.3678 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.3608 - val_mse: 0.3608 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.3539 - val_mse: 0.3539 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3658 - mse: 0.3658 - val_loss: 0.3471 - val_mse: 0.3471 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3593 - mse: 0.3593 - val_loss: 0.3405 - val_mse: 0.3405 - lr: 1.0000e-04\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_37 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_37 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3290 - mse: 0.3290 - val_loss: 0.1253 - val_mse: 0.1253 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3194 - mse: 0.3194 - val_loss: 0.1213 - val_mse: 0.1213 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3105 - mse: 0.3105 - val_loss: 0.1175 - val_mse: 0.1175 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3036 - mse: 0.3036 - val_loss: 0.1137 - val_mse: 0.1137 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2973 - mse: 0.2973 - val_loss: 0.1101 - val_mse: 0.1101 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2873 - mse: 0.2873 - val_loss: 0.1066 - val_mse: 0.1066 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.2809 - mse: 0.2809 - val_loss: 0.1031 - val_mse: 0.1031 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2722 - mse: 0.2722 - val_loss: 0.0998 - val_mse: 0.0998 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2652 - mse: 0.2652 - val_loss: 0.0966 - val_mse: 0.0966 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2591 - mse: 0.2591 - val_loss: 0.0934 - val_mse: 0.0934 - lr: 1.0000e-04\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_38 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_38 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.3401 - mse: 0.3401 - val_loss: 0.1706 - val_mse: 0.1706 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3307 - mse: 0.3307 - val_loss: 0.1659 - val_mse: 0.1659 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3238 - mse: 0.3238 - val_loss: 0.1613 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3167 - mse: 0.3167 - val_loss: 0.1568 - val_mse: 0.1568 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3094 - mse: 0.3094 - val_loss: 0.1524 - val_mse: 0.1524 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3016 - mse: 0.3016 - val_loss: 0.1480 - val_mse: 0.1480 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.2956 - mse: 0.2956 - val_loss: 0.1438 - val_mse: 0.1438 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.2883 - mse: 0.2883 - val_loss: 0.1395 - val_mse: 0.1395 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.2819 - mse: 0.2819 - val_loss: 0.1354 - val_mse: 0.1354 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2744 - mse: 0.2744 - val_loss: 0.1313 - val_mse: 0.1313 - lr: 1.0000e-04\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_39 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_39 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.4079 - mse: 0.4079 - val_loss: 0.7131 - val_mse: 0.7131 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4001 - mse: 0.4001 - val_loss: 0.6985 - val_mse: 0.6985 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.6841 - val_mse: 0.6841 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 0.6699 - val_mse: 0.6699 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3734 - mse: 0.3734 - val_loss: 0.6559 - val_mse: 0.6559 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3656 - mse: 0.3656 - val_loss: 0.6421 - val_mse: 0.6421 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3580 - mse: 0.3580 - val_loss: 0.6285 - val_mse: 0.6285 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3504 - mse: 0.3504 - val_loss: 0.6151 - val_mse: 0.6151 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3413 - mse: 0.3413 - val_loss: 0.6018 - val_mse: 0.6018 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3331 - mse: 0.3331 - val_loss: 0.5887 - val_mse: 0.5887 - lr: 1.0000e-04\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_40 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_40 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3256 - mse: 0.3256 - val_loss: 0.2193 - val_mse: 0.2193 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.3186 - mse: 0.3186 - val_loss: 0.2132 - val_mse: 0.2132 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.3116 - mse: 0.3116 - val_loss: 0.2072 - val_mse: 0.2072 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.3047 - mse: 0.3047 - val_loss: 0.2013 - val_mse: 0.2013 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2978 - mse: 0.2978 - val_loss: 0.1955 - val_mse: 0.1955 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2912 - mse: 0.2912 - val_loss: 0.1898 - val_mse: 0.1898 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2843 - mse: 0.2843 - val_loss: 0.1842 - val_mse: 0.1842 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2778 - mse: 0.2778 - val_loss: 0.1786 - val_mse: 0.1786 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2728 - mse: 0.2728 - val_loss: 0.1732 - val_mse: 0.1732 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.2655 - mse: 0.2655 - val_loss: 0.1678 - val_mse: 0.1678 - lr: 1.0000e-04\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_41 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_41 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.2626 - mse: 0.2626 - val_loss: 0.3255 - val_mse: 0.3255 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2569 - mse: 0.2569 - val_loss: 0.3190 - val_mse: 0.3190 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2511 - mse: 0.2511 - val_loss: 0.3126 - val_mse: 0.3126 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2460 - mse: 0.2460 - val_loss: 0.3064 - val_mse: 0.3064 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 0.3002 - val_mse: 0.3002 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2357 - mse: 0.2357 - val_loss: 0.2941 - val_mse: 0.2941 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2295 - mse: 0.2295 - val_loss: 0.2882 - val_mse: 0.2882 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.2823 - val_mse: 0.2823 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.2766 - val_mse: 0.2766 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2709 - val_mse: 0.2709 - lr: 1.0000e-04\n",
            "Overall MSE:  0.4286357079233442\n",
            "(2585, 90, 4) (2585, 7, 4)\n",
            "Shape of test set:  (647, 90, 4) (647, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2405 , Test period 2405 - 2585 # train records 2405 , # test records 180\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_42 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_42 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.5340 - val_mse: 0.5340 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2294 - mse: 0.2294 - val_loss: 0.5210 - val_mse: 0.5210 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.5082 - val_mse: 0.5082 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.2179 - mse: 0.2179 - val_loss: 0.4955 - val_mse: 0.4955 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.4830 - val_mse: 0.4830 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.2072 - mse: 0.2072 - val_loss: 0.4706 - val_mse: 0.4706 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2003 - mse: 0.2003 - val_loss: 0.4584 - val_mse: 0.4584 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1962 - mse: 0.1962 - val_loss: 0.4463 - val_mse: 0.4463 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1906 - mse: 0.1906 - val_loss: 0.4344 - val_mse: 0.4344 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1851 - mse: 0.1851 - val_loss: 0.4226 - val_mse: 0.4226 - lr: 1.0000e-04\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_43 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_43 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3086 - mse: 0.3086 - val_loss: 0.1002 - val_mse: 0.1002 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3017 - mse: 0.3017 - val_loss: 0.0964 - val_mse: 0.0964 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2939 - mse: 0.2939 - val_loss: 0.0927 - val_mse: 0.0927 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.2863 - mse: 0.2863 - val_loss: 0.0891 - val_mse: 0.0891 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.2780 - mse: 0.2780 - val_loss: 0.0855 - val_mse: 0.0855 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.2731 - mse: 0.2731 - val_loss: 0.0821 - val_mse: 0.0821 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.2669 - mse: 0.2669 - val_loss: 0.0787 - val_mse: 0.0787 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2584 - mse: 0.2584 - val_loss: 0.0754 - val_mse: 0.0754 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.2537 - mse: 0.2537 - val_loss: 0.0722 - val_mse: 0.0722 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.2477 - mse: 0.2477 - val_loss: 0.0691 - val_mse: 0.0691 - lr: 1.0000e-04\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_44 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_44 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.2758 - mse: 0.2758 - val_loss: 0.2214 - val_mse: 0.2214 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.2684 - mse: 0.2684 - val_loss: 0.2143 - val_mse: 0.2143 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.2609 - mse: 0.2609 - val_loss: 0.2074 - val_mse: 0.2074 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.2523 - mse: 0.2523 - val_loss: 0.2006 - val_mse: 0.2006 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 0.1939 - val_mse: 0.1939 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2379 - mse: 0.2379 - val_loss: 0.1874 - val_mse: 0.1874 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2306 - mse: 0.2306 - val_loss: 0.1810 - val_mse: 0.1810 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.1747 - val_mse: 0.1747 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2175 - mse: 0.2175 - val_loss: 0.1685 - val_mse: 0.1685 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2111 - mse: 0.2111 - val_loss: 0.1625 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_45 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_45 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.3479 - mse: 0.3479 - val_loss: 0.2331 - val_mse: 0.2331 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3372 - mse: 0.3372 - val_loss: 0.2266 - val_mse: 0.2266 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3279 - mse: 0.3279 - val_loss: 0.2204 - val_mse: 0.2204 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3190 - mse: 0.3190 - val_loss: 0.2143 - val_mse: 0.2143 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3116 - mse: 0.3116 - val_loss: 0.2084 - val_mse: 0.2084 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3048 - mse: 0.3048 - val_loss: 0.2026 - val_mse: 0.2026 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.2946 - mse: 0.2946 - val_loss: 0.1969 - val_mse: 0.1969 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2872 - mse: 0.2872 - val_loss: 0.1914 - val_mse: 0.1914 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.2799 - mse: 0.2799 - val_loss: 0.1859 - val_mse: 0.1859 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.2718 - mse: 0.2718 - val_loss: 0.1807 - val_mse: 0.1807 - lr: 1.0000e-04\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_46 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_46 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2355 - mse: 0.2355 - val_loss: 0.3177 - val_mse: 0.3177 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2299 - mse: 0.2299 - val_loss: 0.3099 - val_mse: 0.3099 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 0.3021 - val_mse: 0.3021 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2945 - val_mse: 0.2945 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2870 - val_mse: 0.2870 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.2079 - mse: 0.2079 - val_loss: 0.2796 - val_mse: 0.2796 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.2010 - mse: 0.2010 - val_loss: 0.2722 - val_mse: 0.2722 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1966 - mse: 0.1966 - val_loss: 0.2650 - val_mse: 0.2650 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1917 - mse: 0.1917 - val_loss: 0.2579 - val_mse: 0.2579 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 0.2508 - val_mse: 0.2508 - lr: 1.0000e-04\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_47 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_47 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2480 - mse: 0.2480 - val_loss: 0.4602 - val_mse: 0.4602 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.4467 - val_mse: 0.4467 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2343 - mse: 0.2343 - val_loss: 0.4335 - val_mse: 0.4335 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.4205 - val_mse: 0.4205 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 0.4076 - val_mse: 0.4076 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2147 - mse: 0.2147 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2085 - mse: 0.2085 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2023 - mse: 0.2023 - val_loss: 0.3702 - val_mse: 0.3702 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.1959 - mse: 0.1959 - val_loss: 0.3581 - val_mse: 0.3581 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1900 - mse: 0.1900 - val_loss: 0.3461 - val_mse: 0.3461 - lr: 1.0000e-04\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_48 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_48 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 0.4046 - val_mse: 0.4046 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3603 - mse: 0.3603 - val_loss: 0.3951 - val_mse: 0.3951 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.3529 - mse: 0.3529 - val_loss: 0.3858 - val_mse: 0.3858 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3458 - mse: 0.3458 - val_loss: 0.3766 - val_mse: 0.3766 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3379 - mse: 0.3379 - val_loss: 0.3676 - val_mse: 0.3676 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3301 - mse: 0.3301 - val_loss: 0.3587 - val_mse: 0.3587 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.3222 - mse: 0.3222 - val_loss: 0.3500 - val_mse: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.3143 - mse: 0.3143 - val_loss: 0.3414 - val_mse: 0.3414 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.3076 - mse: 0.3076 - val_loss: 0.3329 - val_mse: 0.3329 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.2995 - mse: 0.2995 - val_loss: 0.3245 - val_mse: 0.3245 - lr: 1.0000e-04\n",
            "Overall MSE:  0.31254578488213675\n",
            "(894, 90, 4) (894, 7, 4)\n",
            "Shape of test set:  (224, 90, 4) (224, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 714 , Test period 714 - 894 # train records 714 , # test records 180\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_49 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_49 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3560 - mse: 0.3560 - val_loss: 0.5506 - val_mse: 0.5506 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.3451 - mse: 0.3451 - val_loss: 0.5356 - val_mse: 0.5356 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3364 - mse: 0.3364 - val_loss: 0.5209 - val_mse: 0.5209 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.3260 - mse: 0.3260 - val_loss: 0.5064 - val_mse: 0.5064 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3179 - mse: 0.3179 - val_loss: 0.4921 - val_mse: 0.4921 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3074 - mse: 0.3074 - val_loss: 0.4780 - val_mse: 0.4780 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2984 - mse: 0.2984 - val_loss: 0.4641 - val_mse: 0.4641 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2882 - mse: 0.2882 - val_loss: 0.4504 - val_mse: 0.4504 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2824 - mse: 0.2824 - val_loss: 0.4369 - val_mse: 0.4369 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2731 - mse: 0.2731 - val_loss: 0.4235 - val_mse: 0.4235 - lr: 1.0000e-04\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_50 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_50 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.4733 - mse: 0.4733 - val_loss: 0.6362 - val_mse: 0.6362 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4632 - mse: 0.4632 - val_loss: 0.6210 - val_mse: 0.6210 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.4546 - mse: 0.4546 - val_loss: 0.6060 - val_mse: 0.6060 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4414 - mse: 0.4414 - val_loss: 0.5911 - val_mse: 0.5911 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4318 - mse: 0.4318 - val_loss: 0.5765 - val_mse: 0.5765 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4222 - mse: 0.4222 - val_loss: 0.5620 - val_mse: 0.5620 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4114 - mse: 0.4114 - val_loss: 0.5477 - val_mse: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4020 - mse: 0.4020 - val_loss: 0.5335 - val_mse: 0.5335 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3932 - mse: 0.3932 - val_loss: 0.5194 - val_mse: 0.5194 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3840 - mse: 0.3840 - val_loss: 0.5054 - val_mse: 0.5054 - lr: 1.0000e-04\n",
            "Overall MSE:  0.08859016373753548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_50_layer_call_fn, lstm_cell_50_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3240, 90, 4) (3240, 7, 4)\n",
            "Shape of test set:  (810, 90, 4) (810, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2555 , Test period 2555 - 2735 # train records 2555 , # test records 180\n",
            "Train period: 0 - 2920 , Test period 2920 - 3100 # train records 2920 , # test records 180\n",
            "Train period: 0 - 3060 , Test period 3060 - 3240 # train records 3060 , # test records 180\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_51 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_51 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3924 - mse: 0.3924 - val_loss: 0.0835 - val_mse: 0.0835 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.0812 - val_mse: 0.0812 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3759 - mse: 0.3759 - val_loss: 0.0789 - val_mse: 0.0789 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3658 - mse: 0.3658 - val_loss: 0.0766 - val_mse: 0.0766 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3558 - mse: 0.3558 - val_loss: 0.0744 - val_mse: 0.0744 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3459 - mse: 0.3459 - val_loss: 0.0723 - val_mse: 0.0723 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3378 - mse: 0.3378 - val_loss: 0.0701 - val_mse: 0.0701 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3319 - mse: 0.3319 - val_loss: 0.0680 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3249 - mse: 0.3249 - val_loss: 0.0659 - val_mse: 0.0659 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.3130 - mse: 0.3130 - val_loss: 0.0639 - val_mse: 0.0639 - lr: 1.0000e-04\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_52 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_52 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.4328 - mse: 0.4328 - val_loss: 0.0297 - val_mse: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4224 - mse: 0.4224 - val_loss: 0.0285 - val_mse: 0.0285 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.4100 - mse: 0.4100 - val_loss: 0.0273 - val_mse: 0.0273 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4024 - mse: 0.4024 - val_loss: 0.0261 - val_mse: 0.0261 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3944 - mse: 0.3944 - val_loss: 0.0250 - val_mse: 0.0250 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3831 - mse: 0.3831 - val_loss: 0.0240 - val_mse: 0.0240 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3746 - mse: 0.3746 - val_loss: 0.0230 - val_mse: 0.0230 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3660 - mse: 0.3660 - val_loss: 0.0220 - val_mse: 0.0220 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3547 - mse: 0.3547 - val_loss: 0.0211 - val_mse: 0.0211 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3492 - mse: 0.3492 - val_loss: 0.0202 - val_mse: 0.0202 - lr: 1.0000e-04\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_53 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_53 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.2983 - mse: 0.2983 - val_loss: 0.5281 - val_mse: 0.5281 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2921 - mse: 0.2921 - val_loss: 0.5168 - val_mse: 0.5168 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2857 - mse: 0.2857 - val_loss: 0.5056 - val_mse: 0.5056 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2795 - mse: 0.2795 - val_loss: 0.4946 - val_mse: 0.4946 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2729 - mse: 0.2729 - val_loss: 0.4836 - val_mse: 0.4836 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2668 - mse: 0.2668 - val_loss: 0.4728 - val_mse: 0.4728 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2608 - mse: 0.2608 - val_loss: 0.4621 - val_mse: 0.4621 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.2568 - mse: 0.2568 - val_loss: 0.4516 - val_mse: 0.4516 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2490 - mse: 0.2490 - val_loss: 0.4411 - val_mse: 0.4411 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.2429 - mse: 0.2429 - val_loss: 0.4308 - val_mse: 0.4308 - lr: 1.0000e-04\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_54 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_54 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4605 - mse: 0.4605 - val_loss: 0.3701 - val_mse: 0.3701 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.4497 - mse: 0.4497 - val_loss: 0.3608 - val_mse: 0.3608 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.4386 - mse: 0.4386 - val_loss: 0.3516 - val_mse: 0.3516 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.4292 - mse: 0.4292 - val_loss: 0.3426 - val_mse: 0.3426 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4171 - mse: 0.4171 - val_loss: 0.3338 - val_mse: 0.3338 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.4089 - mse: 0.4089 - val_loss: 0.3252 - val_mse: 0.3252 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3996 - mse: 0.3996 - val_loss: 0.3167 - val_mse: 0.3167 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.3084 - val_mse: 0.3084 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3813 - mse: 0.3813 - val_loss: 0.3002 - val_mse: 0.3002 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.3716 - mse: 0.3716 - val_loss: 0.2922 - val_mse: 0.2922 - lr: 1.0000e-04\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_55 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_55 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.4086 - mse: 0.4086 - val_loss: 0.1872 - val_mse: 0.1872 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.4005 - mse: 0.4005 - val_loss: 0.1826 - val_mse: 0.1826 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3939 - mse: 0.3939 - val_loss: 0.1781 - val_mse: 0.1781 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.1737 - val_mse: 0.1737 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.3799 - mse: 0.3799 - val_loss: 0.1694 - val_mse: 0.1694 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3726 - mse: 0.3726 - val_loss: 0.1652 - val_mse: 0.1652 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.1610 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3605 - mse: 0.3605 - val_loss: 0.1569 - val_mse: 0.1569 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3513 - mse: 0.3513 - val_loss: 0.1530 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3460 - mse: 0.3460 - val_loss: 0.1490 - val_mse: 0.1490 - lr: 1.0000e-04\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_56 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_56 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3363 - mse: 0.3363 - val_loss: 0.0691 - val_mse: 0.0691 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3278 - mse: 0.3278 - val_loss: 0.0679 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.3204 - mse: 0.3204 - val_loss: 0.0668 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.3135 - mse: 0.3135 - val_loss: 0.0657 - val_mse: 0.0657 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3061 - mse: 0.3061 - val_loss: 0.0646 - val_mse: 0.0646 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2998 - mse: 0.2998 - val_loss: 0.0635 - val_mse: 0.0635 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2937 - mse: 0.2937 - val_loss: 0.0625 - val_mse: 0.0625 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2870 - mse: 0.2870 - val_loss: 0.0615 - val_mse: 0.0615 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2805 - mse: 0.2805 - val_loss: 0.0605 - val_mse: 0.0605 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2730 - mse: 0.2730 - val_loss: 0.0595 - val_mse: 0.0595 - lr: 1.0000e-04\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_57 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_57 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.4680 - val_mse: 0.4680 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.3760 - mse: 0.3760 - val_loss: 0.4567 - val_mse: 0.4567 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.3669 - mse: 0.3669 - val_loss: 0.4455 - val_mse: 0.4455 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.3587 - mse: 0.3587 - val_loss: 0.4345 - val_mse: 0.4345 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.3518 - mse: 0.3518 - val_loss: 0.4237 - val_mse: 0.4237 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.3434 - mse: 0.3434 - val_loss: 0.4130 - val_mse: 0.4130 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.4024 - val_mse: 0.4024 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.3286 - mse: 0.3286 - val_loss: 0.3920 - val_mse: 0.3920 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.3207 - mse: 0.3207 - val_loss: 0.3817 - val_mse: 0.3817 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.3147 - mse: 0.3147 - val_loss: 0.3715 - val_mse: 0.3715 - lr: 1.0000e-04\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_58 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_58 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2630 - mse: 0.2630 - val_loss: 0.2323 - val_mse: 0.2323 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.2576 - mse: 0.2576 - val_loss: 0.2259 - val_mse: 0.2259 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.2517 - mse: 0.2517 - val_loss: 0.2196 - val_mse: 0.2196 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 0.2134 - val_mse: 0.2134 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2408 - mse: 0.2408 - val_loss: 0.2072 - val_mse: 0.2072 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2352 - mse: 0.2352 - val_loss: 0.2011 - val_mse: 0.2011 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2292 - mse: 0.2292 - val_loss: 0.1950 - val_mse: 0.1950 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.1890 - val_mse: 0.1890 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2182 - mse: 0.2182 - val_loss: 0.1830 - val_mse: 0.1830 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2132 - mse: 0.2132 - val_loss: 0.1771 - val_mse: 0.1771 - lr: 1.0000e-04\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_59 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_59 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.3095 - mse: 0.3095 - val_loss: 0.1443 - val_mse: 0.1443 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.3031 - mse: 0.3031 - val_loss: 0.1399 - val_mse: 0.1399 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2958 - mse: 0.2958 - val_loss: 0.1356 - val_mse: 0.1356 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.2893 - mse: 0.2893 - val_loss: 0.1314 - val_mse: 0.1314 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.2824 - mse: 0.2824 - val_loss: 0.1273 - val_mse: 0.1273 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2765 - mse: 0.2765 - val_loss: 0.1233 - val_mse: 0.1233 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 0.1193 - val_mse: 0.1193 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.2633 - mse: 0.2633 - val_loss: 0.1154 - val_mse: 0.1154 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2575 - mse: 0.2575 - val_loss: 0.1116 - val_mse: 0.1116 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 0.1079 - val_mse: 0.1079 - lr: 1.0000e-04\n",
            "Overall MSE:  0.35236350033018327\n",
            "(355, 90, 4) (355, 7, 4)\n",
            "Shape of test set:  (89, 90, 4) (89, 7, 4)\n",
            "Train period: 0 - 175 , Test period 175 - 355 # train records 175 , # test records 180\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_60 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_60 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3951 - mse: 0.3951 - val_loss: 0.1081 - val_mse: 0.1081 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.3894 - mse: 0.3894 - val_loss: 0.1047 - val_mse: 0.1047 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.1015 - val_mse: 0.1015 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3722 - mse: 0.3722 - val_loss: 0.0983 - val_mse: 0.0983 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.0951 - val_mse: 0.0951 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.3601 - mse: 0.3601 - val_loss: 0.0921 - val_mse: 0.0921 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.3468 - mse: 0.3468 - val_loss: 0.0892 - val_mse: 0.0892 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.3422 - mse: 0.3422 - val_loss: 0.0863 - val_mse: 0.0863 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3359 - mse: 0.3359 - val_loss: 0.0835 - val_mse: 0.0835 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3272 - mse: 0.3272 - val_loss: 0.0807 - val_mse: 0.0807 - lr: 1.0000e-04\n",
            "Overall MSE:  0.07238640636205673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_60_layer_call_fn, lstm_cell_60_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1028, 90, 4) (1028, 7, 4)\n",
            "Shape of test set:  (258, 90, 4) (258, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 848 , Test period 848 - 1028 # train records 848 , # test records 180\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_61 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_61 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.3277 - mse: 0.3277 - val_loss: 0.5967 - val_mse: 0.5967 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.3211 - mse: 0.3211 - val_loss: 0.5861 - val_mse: 0.5861 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3165 - mse: 0.3165 - val_loss: 0.5756 - val_mse: 0.5756 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.3083 - mse: 0.3083 - val_loss: 0.5653 - val_mse: 0.5653 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.3038 - mse: 0.3038 - val_loss: 0.5550 - val_mse: 0.5550 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2930 - mse: 0.2930 - val_loss: 0.5449 - val_mse: 0.5449 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2908 - mse: 0.2908 - val_loss: 0.5349 - val_mse: 0.5349 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2843 - mse: 0.2843 - val_loss: 0.5249 - val_mse: 0.5249 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.2781 - mse: 0.2781 - val_loss: 0.5151 - val_mse: 0.5151 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2734 - mse: 0.2734 - val_loss: 0.5054 - val_mse: 0.5054 - lr: 1.0000e-04\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_62 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_62 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3684 - mse: 0.3684 - val_loss: 0.8846 - val_mse: 0.8846 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3608 - mse: 0.3608 - val_loss: 0.8650 - val_mse: 0.8650 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3531 - mse: 0.3531 - val_loss: 0.8457 - val_mse: 0.8457 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3440 - mse: 0.3440 - val_loss: 0.8265 - val_mse: 0.8265 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3382 - mse: 0.3382 - val_loss: 0.8074 - val_mse: 0.8074 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.3299 - mse: 0.3299 - val_loss: 0.7886 - val_mse: 0.7886 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3215 - mse: 0.3215 - val_loss: 0.7698 - val_mse: 0.7698 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.3147 - mse: 0.3147 - val_loss: 0.7512 - val_mse: 0.7512 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3058 - mse: 0.3058 - val_loss: 0.7327 - val_mse: 0.7327 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.3004 - mse: 0.3004 - val_loss: 0.7144 - val_mse: 0.7144 - lr: 1.0000e-04\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_63 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_63 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4801 - mse: 0.4801 - val_loss: 0.4421 - val_mse: 0.4421 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4702 - mse: 0.4702 - val_loss: 0.4312 - val_mse: 0.4312 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.4624 - mse: 0.4624 - val_loss: 0.4203 - val_mse: 0.4203 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.4529 - mse: 0.4529 - val_loss: 0.4096 - val_mse: 0.4096 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.4429 - mse: 0.4429 - val_loss: 0.3990 - val_mse: 0.3990 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.4328 - mse: 0.4328 - val_loss: 0.3886 - val_mse: 0.3886 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4254 - mse: 0.4254 - val_loss: 0.3782 - val_mse: 0.3782 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.4153 - mse: 0.4153 - val_loss: 0.3680 - val_mse: 0.3680 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.4066 - mse: 0.4066 - val_loss: 0.3578 - val_mse: 0.3578 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3992 - mse: 0.3992 - val_loss: 0.3477 - val_mse: 0.3477 - lr: 1.0000e-04\n",
            "Overall MSE:  0.17155749599138895\n",
            "(949, 90, 4) (949, 7, 4)\n",
            "Shape of test set:  (238, 90, 4) (238, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 769 , Test period 769 - 949 # train records 769 , # test records 180\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_64 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_64 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 0.3920 - val_mse: 0.3920 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1794 - mse: 0.1794 - val_loss: 0.3815 - val_mse: 0.3815 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.1760 - mse: 0.1760 - val_loss: 0.3712 - val_mse: 0.3712 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1695 - mse: 0.1695 - val_loss: 0.3612 - val_mse: 0.3612 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.1657 - mse: 0.1657 - val_loss: 0.3514 - val_mse: 0.3514 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 0.3419 - val_mse: 0.3419 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1576 - mse: 0.1576 - val_loss: 0.3326 - val_mse: 0.3326 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1523 - mse: 0.1523 - val_loss: 0.3236 - val_mse: 0.3236 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1491 - mse: 0.1491 - val_loss: 0.3147 - val_mse: 0.3147 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.3061 - val_mse: 0.3061 - lr: 1.0000e-04\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_65 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_65 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.3580 - mse: 0.3580 - val_loss: 0.4841 - val_mse: 0.4841 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3477 - mse: 0.3477 - val_loss: 0.4728 - val_mse: 0.4728 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3404 - mse: 0.3404 - val_loss: 0.4617 - val_mse: 0.4617 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3311 - mse: 0.3311 - val_loss: 0.4508 - val_mse: 0.4508 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3205 - mse: 0.3205 - val_loss: 0.4401 - val_mse: 0.4401 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3170 - mse: 0.3170 - val_loss: 0.4295 - val_mse: 0.4295 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.3084 - mse: 0.3084 - val_loss: 0.4192 - val_mse: 0.4192 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3019 - mse: 0.3019 - val_loss: 0.4090 - val_mse: 0.4090 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2948 - mse: 0.2948 - val_loss: 0.3990 - val_mse: 0.3990 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2879 - mse: 0.2879 - val_loss: 0.3891 - val_mse: 0.3891 - lr: 1.0000e-04\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_66 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_66 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.3362 - mse: 0.3362 - val_loss: 0.3135 - val_mse: 0.3135 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3285 - mse: 0.3285 - val_loss: 0.3042 - val_mse: 0.3042 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3180 - mse: 0.3180 - val_loss: 0.2951 - val_mse: 0.2951 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.3103 - mse: 0.3103 - val_loss: 0.2860 - val_mse: 0.2860 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.3014 - mse: 0.3014 - val_loss: 0.2771 - val_mse: 0.2771 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.2920 - mse: 0.2920 - val_loss: 0.2684 - val_mse: 0.2684 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2852 - mse: 0.2852 - val_loss: 0.2597 - val_mse: 0.2597 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2751 - mse: 0.2751 - val_loss: 0.2512 - val_mse: 0.2512 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.2654 - mse: 0.2654 - val_loss: 0.2428 - val_mse: 0.2428 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.2622 - mse: 0.2622 - val_loss: 0.2345 - val_mse: 0.2345 - lr: 1.0000e-04\n",
            "Overall MSE:  0.1250783031185468\n",
            "(2184, 90, 4) (2184, 7, 4)\n",
            "Shape of test set:  (546, 90, 4) (546, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2004 , Test period 2004 - 2184 # train records 2004 , # test records 180\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_67 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_67 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2941 - mse: 0.2941 - val_loss: 0.5580 - val_mse: 0.5580 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2862 - mse: 0.2862 - val_loss: 0.5466 - val_mse: 0.5466 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2803 - mse: 0.2803 - val_loss: 0.5355 - val_mse: 0.5355 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 0.5244 - val_mse: 0.5244 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.5136 - val_mse: 0.5136 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2582 - mse: 0.2582 - val_loss: 0.5028 - val_mse: 0.5028 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2494 - mse: 0.2494 - val_loss: 0.4922 - val_mse: 0.4922 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2435 - mse: 0.2435 - val_loss: 0.4818 - val_mse: 0.4818 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.4714 - val_mse: 0.4714 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2317 - mse: 0.2317 - val_loss: 0.4612 - val_mse: 0.4612 - lr: 1.0000e-04\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_68 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_68 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.4664 - mse: 0.4664 - val_loss: 0.4731 - val_mse: 0.4731 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.4538 - mse: 0.4538 - val_loss: 0.4607 - val_mse: 0.4607 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4431 - mse: 0.4431 - val_loss: 0.4486 - val_mse: 0.4486 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4337 - mse: 0.4337 - val_loss: 0.4367 - val_mse: 0.4367 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4217 - mse: 0.4217 - val_loss: 0.4250 - val_mse: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4115 - mse: 0.4115 - val_loss: 0.4135 - val_mse: 0.4135 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4014 - mse: 0.4014 - val_loss: 0.4022 - val_mse: 0.4022 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3930 - mse: 0.3930 - val_loss: 0.3912 - val_mse: 0.3912 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.3803 - val_mse: 0.3803 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.3696 - val_mse: 0.3696 - lr: 1.0000e-04\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_69 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_69 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3557 - mse: 0.3557 - val_loss: 0.3167 - val_mse: 0.3167 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3468 - mse: 0.3468 - val_loss: 0.3083 - val_mse: 0.3083 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3372 - mse: 0.3372 - val_loss: 0.3001 - val_mse: 0.3001 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3277 - mse: 0.3277 - val_loss: 0.2919 - val_mse: 0.2919 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3184 - mse: 0.3184 - val_loss: 0.2840 - val_mse: 0.2840 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3101 - mse: 0.3101 - val_loss: 0.2761 - val_mse: 0.2761 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3003 - mse: 0.3003 - val_loss: 0.2684 - val_mse: 0.2684 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2922 - mse: 0.2922 - val_loss: 0.2608 - val_mse: 0.2608 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2822 - mse: 0.2822 - val_loss: 0.2533 - val_mse: 0.2533 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.2747 - mse: 0.2747 - val_loss: 0.2459 - val_mse: 0.2459 - lr: 1.0000e-04\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_70 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_70 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4515 - mse: 0.4515 - val_loss: 0.3920 - val_mse: 0.3920 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.4428 - mse: 0.4428 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4321 - mse: 0.4321 - val_loss: 0.3736 - val_mse: 0.3736 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.4228 - mse: 0.4228 - val_loss: 0.3646 - val_mse: 0.3646 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4128 - mse: 0.4128 - val_loss: 0.3557 - val_mse: 0.3557 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.4036 - mse: 0.4036 - val_loss: 0.3470 - val_mse: 0.3470 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3958 - mse: 0.3958 - val_loss: 0.3384 - val_mse: 0.3384 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3864 - mse: 0.3864 - val_loss: 0.3299 - val_mse: 0.3299 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3769 - mse: 0.3769 - val_loss: 0.3216 - val_mse: 0.3216 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 0.3134 - val_mse: 0.3134 - lr: 1.0000e-04\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_71 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_71 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.4018 - mse: 0.4018 - val_loss: 0.4043 - val_mse: 0.4043 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3930 - mse: 0.3930 - val_loss: 0.3956 - val_mse: 0.3956 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3842 - mse: 0.3842 - val_loss: 0.3869 - val_mse: 0.3869 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3765 - mse: 0.3765 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3681 - mse: 0.3681 - val_loss: 0.3700 - val_mse: 0.3700 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3595 - mse: 0.3595 - val_loss: 0.3616 - val_mse: 0.3616 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3515 - mse: 0.3515 - val_loss: 0.3534 - val_mse: 0.3534 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3431 - mse: 0.3431 - val_loss: 0.3452 - val_mse: 0.3452 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3361 - mse: 0.3361 - val_loss: 0.3370 - val_mse: 0.3370 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3281 - mse: 0.3281 - val_loss: 0.3290 - val_mse: 0.3290 - lr: 1.0000e-04\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_72 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_72 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.4512 - mse: 0.4512 - val_loss: 0.5054 - val_mse: 0.5054 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4397 - mse: 0.4397 - val_loss: 0.4927 - val_mse: 0.4927 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4296 - mse: 0.4296 - val_loss: 0.4803 - val_mse: 0.4803 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4204 - mse: 0.4204 - val_loss: 0.4681 - val_mse: 0.4681 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4074 - mse: 0.4074 - val_loss: 0.4560 - val_mse: 0.4560 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3979 - mse: 0.3979 - val_loss: 0.4441 - val_mse: 0.4441 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.4324 - val_mse: 0.4324 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3774 - mse: 0.3774 - val_loss: 0.4208 - val_mse: 0.4208 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3673 - mse: 0.3673 - val_loss: 0.4094 - val_mse: 0.4094 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3572 - mse: 0.3572 - val_loss: 0.3982 - val_mse: 0.3982 - lr: 1.0000e-04\n",
            "Overall MSE:  0.33987103402614594\n",
            "(395, 90, 4) (395, 7, 4)\n",
            "Shape of test set:  (99, 90, 4) (99, 7, 4)\n",
            "Train period: 0 - 215 , Test period 215 - 395 # train records 215 , # test records 180\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_73 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_73 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2992 - mse: 0.2992 - val_loss: 0.0514 - val_mse: 0.0514 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.2930 - mse: 0.2930 - val_loss: 0.0498 - val_mse: 0.0498 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.2869 - mse: 0.2869 - val_loss: 0.0482 - val_mse: 0.0482 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.2804 - mse: 0.2804 - val_loss: 0.0466 - val_mse: 0.0466 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.2750 - mse: 0.2750 - val_loss: 0.0451 - val_mse: 0.0451 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2707 - mse: 0.2707 - val_loss: 0.0437 - val_mse: 0.0437 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.2629 - mse: 0.2629 - val_loss: 0.0423 - val_mse: 0.0423 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2589 - mse: 0.2589 - val_loss: 0.0409 - val_mse: 0.0409 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2535 - mse: 0.2535 - val_loss: 0.0396 - val_mse: 0.0396 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.2478 - mse: 0.2478 - val_loss: 0.0384 - val_mse: 0.0384 - lr: 1.0000e-04\n",
            "Overall MSE:  0.09256263077259064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_73_layer_call_fn, lstm_cell_73_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(993, 90, 4) (993, 7, 4)\n",
            "Shape of test set:  (249, 90, 4) (249, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 813 , Test period 813 - 993 # train records 813 , # test records 180\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_74 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_74 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.1526 - mse: 0.1526 - val_loss: 0.2305 - val_mse: 0.2305 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1485 - mse: 0.1485 - val_loss: 0.2257 - val_mse: 0.2257 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 0.2210 - val_mse: 0.2210 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.1406 - mse: 0.1406 - val_loss: 0.2164 - val_mse: 0.2164 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.2120 - val_mse: 0.2120 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 0.2076 - val_mse: 0.2076 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 0.2033 - val_mse: 0.2033 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.1268 - mse: 0.1268 - val_loss: 0.1991 - val_mse: 0.1991 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 0.1950 - val_mse: 0.1950 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 0.1910 - val_mse: 0.1910 - lr: 1.0000e-04\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_75 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_75 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2805 - mse: 0.2805 - val_loss: 0.5897 - val_mse: 0.5897 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2739 - mse: 0.2739 - val_loss: 0.5745 - val_mse: 0.5745 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2669 - mse: 0.2669 - val_loss: 0.5595 - val_mse: 0.5595 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2609 - mse: 0.2609 - val_loss: 0.5447 - val_mse: 0.5447 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.2540 - mse: 0.2540 - val_loss: 0.5300 - val_mse: 0.5300 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2467 - mse: 0.2467 - val_loss: 0.5155 - val_mse: 0.5155 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.5012 - val_mse: 0.5012 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2333 - mse: 0.2333 - val_loss: 0.4869 - val_mse: 0.4869 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 0.4729 - val_mse: 0.4729 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2228 - mse: 0.2228 - val_loss: 0.4589 - val_mse: 0.4589 - lr: 1.0000e-04\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_76 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_76 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4236 - mse: 0.4236 - val_loss: 0.3198 - val_mse: 0.3198 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4128 - mse: 0.4128 - val_loss: 0.3127 - val_mse: 0.3127 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.4064 - mse: 0.4064 - val_loss: 0.3058 - val_mse: 0.3058 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3977 - mse: 0.3977 - val_loss: 0.2991 - val_mse: 0.2991 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3911 - mse: 0.3911 - val_loss: 0.2924 - val_mse: 0.2924 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.2859 - val_mse: 0.2859 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3764 - mse: 0.3764 - val_loss: 0.2794 - val_mse: 0.2794 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3708 - mse: 0.3708 - val_loss: 0.2731 - val_mse: 0.2731 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3619 - mse: 0.3619 - val_loss: 0.2669 - val_mse: 0.2669 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3527 - mse: 0.3527 - val_loss: 0.2607 - val_mse: 0.2607 - lr: 1.0000e-04\n",
            "Overall MSE:  0.20842940111955008\n",
            "(356, 90, 4) (356, 7, 4)\n",
            "Shape of test set:  (89, 90, 4) (89, 7, 4)\n",
            "Train period: 0 - 176 , Test period 176 - 356 # train records 176 , # test records 180\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_77 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_77 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 0.1944 - val_mse: 0.1944 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.7359 - mse: 0.7359 - val_loss: 0.1886 - val_mse: 0.1886 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.7180 - mse: 0.7180 - val_loss: 0.1830 - val_mse: 0.1830 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.6999 - mse: 0.6999 - val_loss: 0.1774 - val_mse: 0.1774 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.6813 - mse: 0.6813 - val_loss: 0.1721 - val_mse: 0.1721 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.6756 - mse: 0.6756 - val_loss: 0.1668 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.6545 - mse: 0.6545 - val_loss: 0.1616 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6446 - mse: 0.6446 - val_loss: 0.1566 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6312 - mse: 0.6312 - val_loss: 0.1517 - val_mse: 0.1517 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.6086 - mse: 0.6086 - val_loss: 0.1469 - val_mse: 0.1469 - lr: 1.0000e-04\n",
            "Overall MSE:  0.2914784252643585\n",
            "(336, 90, 4) (336, 7, 4)\n",
            "Shape of test set:  (84, 90, 4) (84, 7, 4)\n",
            "Train period: 0 - 156 , Test period 156 - 336 # train records 156 , # test records 180\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_78 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_78 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.5878 - mse: 0.5878 - val_loss: 0.0722 - val_mse: 0.0722 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.5770 - mse: 0.5770 - val_loss: 0.0702 - val_mse: 0.0702 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.5602 - mse: 0.5602 - val_loss: 0.0682 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.5478 - mse: 0.5478 - val_loss: 0.0663 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.5348 - mse: 0.5348 - val_loss: 0.0645 - val_mse: 0.0645 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.5188 - mse: 0.5188 - val_loss: 0.0627 - val_mse: 0.0627 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.5050 - mse: 0.5050 - val_loss: 0.0610 - val_mse: 0.0610 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.4964 - mse: 0.4964 - val_loss: 0.0594 - val_mse: 0.0594 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.4820 - mse: 0.4820 - val_loss: 0.0578 - val_mse: 0.0578 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.4673 - mse: 0.4673 - val_loss: 0.0563 - val_mse: 0.0563 - lr: 1.0000e-04\n",
            "Overall MSE:  0.4119245707988739\n",
            "(1056, 90, 4) (1056, 7, 4)\n",
            "Shape of test set:  (265, 90, 4) (265, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 876 , Test period 876 - 1056 # train records 876 , # test records 180\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_79 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_79 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3758 - mse: 0.3758 - val_loss: 0.3496 - val_mse: 0.3496 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.3411 - val_mse: 0.3411 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3582 - mse: 0.3582 - val_loss: 0.3328 - val_mse: 0.3328 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.3484 - mse: 0.3484 - val_loss: 0.3246 - val_mse: 0.3246 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3365 - mse: 0.3365 - val_loss: 0.3166 - val_mse: 0.3166 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.3293 - mse: 0.3293 - val_loss: 0.3087 - val_mse: 0.3087 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3178 - mse: 0.3178 - val_loss: 0.3010 - val_mse: 0.3010 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3112 - mse: 0.3112 - val_loss: 0.2933 - val_mse: 0.2933 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.3037 - mse: 0.3037 - val_loss: 0.2859 - val_mse: 0.2859 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.2945 - mse: 0.2945 - val_loss: 0.2785 - val_mse: 0.2785 - lr: 1.0000e-04\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_80 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_80 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3720 - mse: 0.3720 - val_loss: 0.7531 - val_mse: 0.7531 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3636 - mse: 0.3636 - val_loss: 0.7371 - val_mse: 0.7371 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.3557 - mse: 0.3557 - val_loss: 0.7213 - val_mse: 0.7213 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3473 - mse: 0.3473 - val_loss: 0.7056 - val_mse: 0.7056 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3406 - mse: 0.3406 - val_loss: 0.6902 - val_mse: 0.6902 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3315 - mse: 0.3315 - val_loss: 0.6749 - val_mse: 0.6749 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3232 - mse: 0.3232 - val_loss: 0.6598 - val_mse: 0.6598 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3162 - mse: 0.3162 - val_loss: 0.6448 - val_mse: 0.6448 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3071 - mse: 0.3071 - val_loss: 0.6300 - val_mse: 0.6300 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3012 - mse: 0.3012 - val_loss: 0.6153 - val_mse: 0.6153 - lr: 1.0000e-04\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_81 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_81 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.3799 - mse: 0.3799 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3722 - mse: 0.3722 - val_loss: 0.3726 - val_mse: 0.3726 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3652 - mse: 0.3652 - val_loss: 0.3636 - val_mse: 0.3636 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3571 - mse: 0.3571 - val_loss: 0.3546 - val_mse: 0.3546 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3493 - mse: 0.3493 - val_loss: 0.3456 - val_mse: 0.3456 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3405 - mse: 0.3405 - val_loss: 0.3368 - val_mse: 0.3368 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3340 - mse: 0.3340 - val_loss: 0.3280 - val_mse: 0.3280 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3264 - mse: 0.3264 - val_loss: 0.3192 - val_mse: 0.3192 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3185 - mse: 0.3185 - val_loss: 0.3106 - val_mse: 0.3106 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3116 - mse: 0.3116 - val_loss: 0.3019 - val_mse: 0.3019 - lr: 1.0000e-04\n",
            "Overall MSE:  0.1865087995926539\n",
            "(871, 90, 4) (871, 7, 4)\n",
            "Shape of test set:  (218, 90, 4) (218, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 691 , Test period 691 - 871 # train records 691 , # test records 180\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_82 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_82 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2626 - mse: 0.2626 - val_loss: 0.5723 - val_mse: 0.5723 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2543 - mse: 0.2543 - val_loss: 0.5578 - val_mse: 0.5578 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 0.5436 - val_mse: 0.5436 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 0.5296 - val_mse: 0.5296 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2355 - mse: 0.2355 - val_loss: 0.5158 - val_mse: 0.5158 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.5023 - val_mse: 0.5023 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.4891 - val_mse: 0.4891 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 0.4760 - val_mse: 0.4760 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2085 - mse: 0.2085 - val_loss: 0.4632 - val_mse: 0.4632 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2072 - mse: 0.2072 - val_loss: 0.4505 - val_mse: 0.4505 - lr: 1.0000e-04\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_83 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_83 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6356 - mse: 0.6356 - val_loss: 0.2904 - val_mse: 0.2904 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6164 - mse: 0.6164 - val_loss: 0.2824 - val_mse: 0.2824 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.6055 - mse: 0.6055 - val_loss: 0.2747 - val_mse: 0.2747 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5911 - mse: 0.5911 - val_loss: 0.2671 - val_mse: 0.2671 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.5772 - mse: 0.5772 - val_loss: 0.2597 - val_mse: 0.2597 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.5619 - mse: 0.5619 - val_loss: 0.2525 - val_mse: 0.2525 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.5500 - mse: 0.5500 - val_loss: 0.2455 - val_mse: 0.2455 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5380 - mse: 0.5380 - val_loss: 0.2386 - val_mse: 0.2386 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.5240 - mse: 0.5240 - val_loss: 0.2320 - val_mse: 0.2320 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5126 - mse: 0.5126 - val_loss: 0.2254 - val_mse: 0.2254 - lr: 1.0000e-04\n",
            "Overall MSE:  0.103615902364254\n",
            "(1056, 90, 4) (1056, 7, 4)\n",
            "Shape of test set:  (265, 90, 4) (265, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 876 , Test period 876 - 1056 # train records 876 , # test records 180\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_84 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_84 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3506 - mse: 0.3506 - val_loss: 0.3286 - val_mse: 0.3286 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3413 - mse: 0.3413 - val_loss: 0.3217 - val_mse: 0.3217 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3335 - mse: 0.3335 - val_loss: 0.3149 - val_mse: 0.3149 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3252 - mse: 0.3252 - val_loss: 0.3081 - val_mse: 0.3081 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.3181 - mse: 0.3181 - val_loss: 0.3014 - val_mse: 0.3014 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3095 - mse: 0.3095 - val_loss: 0.2947 - val_mse: 0.2947 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.3031 - mse: 0.3031 - val_loss: 0.2882 - val_mse: 0.2882 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2955 - mse: 0.2955 - val_loss: 0.2816 - val_mse: 0.2816 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2853 - mse: 0.2853 - val_loss: 0.2752 - val_mse: 0.2752 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2807 - mse: 0.2807 - val_loss: 0.2687 - val_mse: 0.2687 - lr: 1.0000e-04\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_85 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_85 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.4294 - mse: 0.4294 - val_loss: 0.8551 - val_mse: 0.8551 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.4169 - mse: 0.4169 - val_loss: 0.8350 - val_mse: 0.8350 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4063 - mse: 0.4063 - val_loss: 0.8152 - val_mse: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3974 - mse: 0.3974 - val_loss: 0.7957 - val_mse: 0.7957 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.7764 - val_mse: 0.7764 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.7573 - val_mse: 0.7573 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3684 - mse: 0.3684 - val_loss: 0.7384 - val_mse: 0.7384 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3585 - mse: 0.3585 - val_loss: 0.7197 - val_mse: 0.7197 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3502 - mse: 0.3502 - val_loss: 0.7011 - val_mse: 0.7011 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3389 - mse: 0.3389 - val_loss: 0.6826 - val_mse: 0.6826 - lr: 1.0000e-04\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_86 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_86 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5100 - mse: 0.5100 - val_loss: 0.5227 - val_mse: 0.5227 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4983 - mse: 0.4983 - val_loss: 0.5124 - val_mse: 0.5124 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4896 - mse: 0.4896 - val_loss: 0.5023 - val_mse: 0.5023 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.4826 - mse: 0.4826 - val_loss: 0.4923 - val_mse: 0.4923 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4728 - mse: 0.4728 - val_loss: 0.4826 - val_mse: 0.4826 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.4643 - mse: 0.4643 - val_loss: 0.4730 - val_mse: 0.4730 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4553 - mse: 0.4553 - val_loss: 0.4635 - val_mse: 0.4635 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.4462 - mse: 0.4462 - val_loss: 0.4542 - val_mse: 0.4542 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.4383 - mse: 0.4383 - val_loss: 0.4450 - val_mse: 0.4450 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.4312 - mse: 0.4312 - val_loss: 0.4359 - val_mse: 0.4359 - lr: 1.0000e-04\n",
            "Overall MSE:  0.21538452307383218\n",
            "(640, 90, 4) (640, 7, 4)\n",
            "Shape of test set:  (160, 90, 4) (160, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 460 , Test period 460 - 640 # train records 460 , # test records 180\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_87 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_87 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.2747 - mse: 0.2747 - val_loss: 0.3480 - val_mse: 0.3480 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2683 - mse: 0.2683 - val_loss: 0.3409 - val_mse: 0.3409 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2613 - mse: 0.2613 - val_loss: 0.3338 - val_mse: 0.3338 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2539 - mse: 0.2539 - val_loss: 0.3269 - val_mse: 0.3269 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2493 - mse: 0.2493 - val_loss: 0.3201 - val_mse: 0.3201 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2441 - mse: 0.2441 - val_loss: 0.3133 - val_mse: 0.3133 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.3066 - val_mse: 0.3066 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2319 - mse: 0.2319 - val_loss: 0.3000 - val_mse: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.2935 - val_mse: 0.2935 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2220 - mse: 0.2220 - val_loss: 0.2871 - val_mse: 0.2871 - lr: 1.0000e-04\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_88 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_88 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.1541 - val_mse: 0.1541 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.3643 - mse: 0.3643 - val_loss: 0.1507 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3582 - mse: 0.3582 - val_loss: 0.1474 - val_mse: 0.1474 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.3501 - mse: 0.3501 - val_loss: 0.1442 - val_mse: 0.1442 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3452 - mse: 0.3452 - val_loss: 0.1410 - val_mse: 0.1410 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3364 - mse: 0.3364 - val_loss: 0.1379 - val_mse: 0.1379 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3306 - mse: 0.3306 - val_loss: 0.1348 - val_mse: 0.1348 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3240 - mse: 0.3240 - val_loss: 0.1318 - val_mse: 0.1318 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.3193 - mse: 0.3193 - val_loss: 0.1289 - val_mse: 0.1289 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.3123 - mse: 0.3123 - val_loss: 0.1260 - val_mse: 0.1260 - lr: 1.0000e-04\n",
            "Overall MSE:  0.14431899040937424\n",
            "(450, 90, 4) (450, 7, 4)\n",
            "Shape of test set:  (113, 90, 4) (113, 7, 4)\n",
            "Train period: 0 - 270 , Test period 270 - 450 # train records 270 , # test records 180\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_89 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_89 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5668 - mse: 0.5668 - val_loss: 0.0749 - val_mse: 0.0749 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.5561 - mse: 0.5561 - val_loss: 0.0726 - val_mse: 0.0726 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.5463 - mse: 0.5463 - val_loss: 0.0704 - val_mse: 0.0704 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5360 - mse: 0.5360 - val_loss: 0.0682 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5212 - mse: 0.5212 - val_loss: 0.0661 - val_mse: 0.0661 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5089 - mse: 0.5089 - val_loss: 0.0640 - val_mse: 0.0640 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4993 - mse: 0.4993 - val_loss: 0.0620 - val_mse: 0.0620 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4870 - mse: 0.4870 - val_loss: 0.0601 - val_mse: 0.0601 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4745 - mse: 0.4745 - val_loss: 0.0582 - val_mse: 0.0582 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4683 - mse: 0.4683 - val_loss: 0.0563 - val_mse: 0.0563 - lr: 1.0000e-04\n",
            "Overall MSE:  0.15015603601932526\n",
            "(2689, 90, 4) (2689, 7, 4)\n",
            "Shape of test set:  (673, 90, 4) (673, 7, 4)\n",
            "Train period: 0 - 365 , Test period 365 - 545 # train records 365 , # test records 180\n",
            "Train period: 0 - 730 , Test period 730 - 910 # train records 730 , # test records 180\n",
            "Train period: 0 - 1095 , Test period 1095 - 1275 # train records 1095 , # test records 180\n",
            "Train period: 0 - 1460 , Test period 1460 - 1640 # train records 1460 , # test records 180\n",
            "Train period: 0 - 1825 , Test period 1825 - 2005 # train records 1825 , # test records 180\n",
            "Train period: 0 - 2190 , Test period 2190 - 2370 # train records 2190 , # test records 180\n",
            "Train period: 0 - 2509 , Test period 2509 - 2689 # train records 2509 , # test records 180\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_90 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_90 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0949 - mse: 0.0949 - val_loss: 0.0796 - val_mse: 0.0796 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.0772 - val_mse: 0.0772 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.0749 - val_mse: 0.0749 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0727 - val_mse: 0.0727 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 0.0705 - val_mse: 0.0705 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0684 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0663 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0643 - val_mse: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.0761 - mse: 0.0761 - val_loss: 0.0624 - val_mse: 0.0624 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0605 - val_mse: 0.0605 - lr: 1.0000e-04\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_91 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_91 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.3454 - val_mse: 0.3454 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2217 - mse: 0.2217 - val_loss: 0.3390 - val_mse: 0.3390 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2180 - mse: 0.2180 - val_loss: 0.3327 - val_mse: 0.3327 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2134 - mse: 0.2134 - val_loss: 0.3266 - val_mse: 0.3266 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2103 - mse: 0.2103 - val_loss: 0.3205 - val_mse: 0.3205 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2058 - mse: 0.2058 - val_loss: 0.3145 - val_mse: 0.3145 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2016 - mse: 0.2016 - val_loss: 0.3087 - val_mse: 0.3087 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 0.3029 - val_mse: 0.3029 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 0.2971 - val_mse: 0.2971 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.1920 - mse: 0.1920 - val_loss: 0.2914 - val_mse: 0.2914 - lr: 1.0000e-04\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_92 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_92 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.5448 - val_mse: 0.5448 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 0.5329 - val_mse: 0.5329 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.5212 - val_mse: 0.5212 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.2194 - mse: 0.2194 - val_loss: 0.5097 - val_mse: 0.5097 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2142 - mse: 0.2142 - val_loss: 0.4984 - val_mse: 0.4984 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.2081 - mse: 0.2081 - val_loss: 0.4874 - val_mse: 0.4874 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 0.4766 - val_mse: 0.4766 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.1988 - mse: 0.1988 - val_loss: 0.4659 - val_mse: 0.4659 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.1949 - mse: 0.1949 - val_loss: 0.4555 - val_mse: 0.4555 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1903 - mse: 0.1903 - val_loss: 0.4452 - val_mse: 0.4452 - lr: 1.0000e-04\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_93 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_93 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.2786 - mse: 0.2786 - val_loss: 0.2032 - val_mse: 0.2032 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2703 - mse: 0.2703 - val_loss: 0.1975 - val_mse: 0.1975 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.2652 - mse: 0.2652 - val_loss: 0.1918 - val_mse: 0.1918 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2584 - mse: 0.2584 - val_loss: 0.1862 - val_mse: 0.1862 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2527 - mse: 0.2527 - val_loss: 0.1806 - val_mse: 0.1806 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2456 - mse: 0.2456 - val_loss: 0.1752 - val_mse: 0.1752 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2395 - mse: 0.2395 - val_loss: 0.1699 - val_mse: 0.1699 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2321 - mse: 0.2321 - val_loss: 0.1646 - val_mse: 0.1646 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.1594 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.2200 - mse: 0.2200 - val_loss: 0.1542 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_94 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_94 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2512 - mse: 0.2512 - val_loss: 0.6557 - val_mse: 0.6557 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.2451 - mse: 0.2451 - val_loss: 0.6401 - val_mse: 0.6401 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2390 - mse: 0.2390 - val_loss: 0.6246 - val_mse: 0.6246 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.2324 - mse: 0.2324 - val_loss: 0.6094 - val_mse: 0.6094 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.2285 - mse: 0.2285 - val_loss: 0.5943 - val_mse: 0.5943 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.2223 - mse: 0.2223 - val_loss: 0.5795 - val_mse: 0.5795 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.2171 - mse: 0.2171 - val_loss: 0.5648 - val_mse: 0.5648 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2105 - mse: 0.2105 - val_loss: 0.5503 - val_mse: 0.5503 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 0.5359 - val_mse: 0.5359 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.2007 - mse: 0.2007 - val_loss: 0.5217 - val_mse: 0.5217 - lr: 1.0000e-04\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_95 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_95 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.0775 - val_mse: 0.0775 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.2177 - mse: 0.2177 - val_loss: 0.0743 - val_mse: 0.0743 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2113 - mse: 0.2113 - val_loss: 0.0712 - val_mse: 0.0712 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 0.0682 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1985 - mse: 0.1985 - val_loss: 0.0653 - val_mse: 0.0653 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1925 - mse: 0.1925 - val_loss: 0.0623 - val_mse: 0.0623 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1866 - mse: 0.1866 - val_loss: 0.0595 - val_mse: 0.0595 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1807 - mse: 0.1807 - val_loss: 0.0567 - val_mse: 0.0567 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1747 - mse: 0.1747 - val_loss: 0.0540 - val_mse: 0.0540 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1684 - mse: 0.1684 - val_loss: 0.0513 - val_mse: 0.0513 - lr: 1.0000e-04\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_96 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_96 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2687 - mse: 0.2687 - val_loss: 0.6230 - val_mse: 0.6230 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.2621 - mse: 0.2621 - val_loss: 0.6108 - val_mse: 0.6108 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2549 - mse: 0.2549 - val_loss: 0.5986 - val_mse: 0.5986 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.2492 - mse: 0.2492 - val_loss: 0.5866 - val_mse: 0.5866 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2431 - mse: 0.2431 - val_loss: 0.5747 - val_mse: 0.5747 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2360 - mse: 0.2360 - val_loss: 0.5629 - val_mse: 0.5629 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.2305 - mse: 0.2305 - val_loss: 0.5512 - val_mse: 0.5512 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2238 - mse: 0.2238 - val_loss: 0.5397 - val_mse: 0.5397 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.5282 - val_mse: 0.5282 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.2130 - mse: 0.2130 - val_loss: 0.5168 - val_mse: 0.5168 - lr: 1.0000e-04\n",
            "Overall MSE:  0.2934971920081547\n",
            "(398, 90, 4) (398, 7, 4)\n",
            "Shape of test set:  (100, 90, 4) (100, 7, 4)\n",
            "Train period: 0 - 218 , Test period 218 - 398 # train records 218 , # test records 180\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_97 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_97 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4491 - mse: 0.4491 - val_loss: 0.0999 - val_mse: 0.0999 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.4370 - mse: 0.4370 - val_loss: 0.0971 - val_mse: 0.0971 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4280 - mse: 0.4280 - val_loss: 0.0944 - val_mse: 0.0944 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.4193 - mse: 0.4193 - val_loss: 0.0918 - val_mse: 0.0918 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.4085 - mse: 0.4085 - val_loss: 0.0892 - val_mse: 0.0892 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4026 - mse: 0.4026 - val_loss: 0.0867 - val_mse: 0.0867 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3926 - mse: 0.3926 - val_loss: 0.0842 - val_mse: 0.0842 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3808 - mse: 0.3808 - val_loss: 0.0818 - val_mse: 0.0818 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.3715 - mse: 0.3715 - val_loss: 0.0794 - val_mse: 0.0794 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.3660 - mse: 0.3660 - val_loss: 0.0771 - val_mse: 0.0771 - lr: 1.0000e-04\n",
            "Overall MSE:  0.1781563013792038\n",
            "(353, 90, 4) (353, 7, 4)\n",
            "Shape of test set:  (89, 90, 4) (89, 7, 4)\n",
            "Train period: 0 - 173 , Test period 173 - 353 # train records 173 , # test records 180\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_98 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_98 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6144 - mse: 0.6144 - val_loss: 0.2511 - val_mse: 0.2511 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5995 - mse: 0.5995 - val_loss: 0.2435 - val_mse: 0.2435 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.5831 - mse: 0.5831 - val_loss: 0.2361 - val_mse: 0.2361 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.5737 - mse: 0.5737 - val_loss: 0.2289 - val_mse: 0.2289 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5545 - mse: 0.5545 - val_loss: 0.2218 - val_mse: 0.2218 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5425 - mse: 0.5425 - val_loss: 0.2148 - val_mse: 0.2148 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.5276 - mse: 0.5276 - val_loss: 0.2080 - val_mse: 0.2080 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5108 - mse: 0.5108 - val_loss: 0.2013 - val_mse: 0.2013 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4999 - mse: 0.4999 - val_loss: 0.1948 - val_mse: 0.1948 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4877 - mse: 0.4877 - val_loss: 0.1884 - val_mse: 0.1884 - lr: 1.0000e-04\n",
            "Overall MSE:  0.12879233062267303\n",
            "(244, 90, 4) (244, 7, 4)\n",
            "Shape of test set:  (61, 90, 4) (61, 7, 4)\n",
            "Train period: 0 - 64 , Test period 64 - 244 # train records 64 , # test records 180\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_99 (LSTM)              (None, 90, 128)           68096     \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 90, 128)           0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 90, 4)             516       \n",
            "                                                                 \n",
            " cropping1d_99 (Cropping1D)  (None, 7, 4)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,612\n",
            "Trainable params: 68,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1997 - mse: 0.1997 - val_loss: 0.0319 - val_mse: 0.0319 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1947 - mse: 0.1947 - val_loss: 0.0313 - val_mse: 0.0313 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1893 - mse: 0.1893 - val_loss: 0.0307 - val_mse: 0.0307 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1835 - mse: 0.1835 - val_loss: 0.0302 - val_mse: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 0.0297 - val_mse: 0.0297 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.1748 - mse: 0.1748 - val_loss: 0.0293 - val_mse: 0.0293 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.0288 - val_mse: 0.0288 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1658 - mse: 0.1658 - val_loss: 0.0285 - val_mse: 0.0285 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.1611 - mse: 0.1611 - val_loss: 0.0281 - val_mse: 0.0281 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 0.0278 - val_mse: 0.0278 - lr: 1.0000e-04\n",
            "Overall MSE:  0.16859771311283112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting all mses during the cross-validation\n",
        "for i in range(0, len(finName)):\n",
        "  print(\"Company\", tickerName[i])\n",
        "  print(\"Overall mse\", allMse[i])"
      ],
      "metadata": {
        "id": "Lkyn-K4z7Fj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3913249-a690-4338-a9d1-000bce6d4b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company VCB\n",
            "Overall mse 0.32936919586999075\n",
            "Company SSB\n",
            "Overall mse 0.5039544701576233\n",
            "Company BID\n",
            "Overall mse 0.29909762740135193\n",
            "Company NVB\n",
            "Overall mse 0.3899608254432678\n",
            "Company ACB\n",
            "Overall mse 0.36142922937870026\n",
            "Company BAB\n",
            "Overall mse 0.056449200958013535\n",
            "Company VIB\n",
            "Overall mse 0.21154641608397165\n",
            "Company CTG\n",
            "Overall mse 0.4286357079233442\n",
            "Company EIB\n",
            "Overall mse 0.31254578488213675\n",
            "Company TPB\n",
            "Overall mse 0.08859016373753548\n",
            "Company STB\n",
            "Overall mse 0.35236350033018327\n",
            "Company PGB\n",
            "Overall mse 0.07238640636205673\n",
            "Company VPB\n",
            "Overall mse 0.17155749599138895\n",
            "Company HDB\n",
            "Overall mse 0.1250783031185468\n",
            "Company MBB\n",
            "Overall mse 0.33987103402614594\n",
            "Company SGB\n",
            "Overall mse 0.09256263077259064\n",
            "Company LPB\n",
            "Overall mse 0.20842940111955008\n",
            "Company MSB\n",
            "Overall mse 0.2914784252643585\n",
            "Company OCB\n",
            "Overall mse 0.4119245707988739\n",
            "Company KLB\n",
            "Overall mse 0.1865087995926539\n",
            "Company TCB\n",
            "Overall mse 0.103615902364254\n",
            "Company KLB\n",
            "Overall mse 0.21538452307383218\n",
            "Company VBB\n",
            "Overall mse 0.14431899040937424\n",
            "Company BVB\n",
            "Overall mse 0.15015603601932526\n",
            "Company SHB\n",
            "Overall mse 0.2934971920081547\n",
            "Company NAB\n",
            "Overall mse 0.1781563013792038\n",
            "Company ABB\n",
            "Overall mse 0.12879233062267303\n",
            "Company VAB\n",
            "Overall mse 0.16859771311283112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the filtered company\n",
        "goodCom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKohUAclMRza",
        "outputId": "293bd276-522d-4c17-fa7f-43e13f2f30ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BAB', 'TPB', 'PGB', 'SGB']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def good_companies(goodCom):\n",
        "    \"\"\"Load model from the best company with its model\n",
        "    Input: path to saved filtered companies csv\n",
        "    Output: List of models associated with each company\n",
        "    \"\"\"\n",
        "    filtered_companies_model = []\n",
        "    for company in goodCom:\n",
        "        filtered_companies_model.append(keras.models.load_model(filepath=bestModelDir + company))\n",
        "    return filtered_companies_model"
      ],
      "metadata": {
        "id": "X6mDvCOZlth6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_companies_model = good_companies(goodCom)"
      ],
      "metadata": {
        "id": "W0b9JEC9xz4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c92b10-bdc3-4a25-e50e-490dce16d568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_companies_model\n",
        "filter_compiled_model = []\n",
        "#Compile the save models\n",
        "for i in filtered_companies_model:\n",
        "  i.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mse'], run_eagerly=True)\n",
        "  filter_compiled_model.append(i)"
      ],
      "metadata": {
        "id": "amH3p4xOzeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dfindicators(df):\n",
        "    \"\"\"Get the stock indicators used later in task 3 and task 4 , using pandas_ta. The indicators here are STI and RSI - supertrend and Relative strength index\"\"\"\n",
        "    indicators = {\"sti\": ta.supertrend(df['High'], df['Low'], df['Close'], length=3, multiplier=3),\n",
        "                  \"rsi\": ta.rsi(df[\"Close\"], length=3)}\n",
        "    return indicators"
      ],
      "metadata": {
        "id": "n0EtQD86sKmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_company(company, companyPath, model):\n",
        "    \"\"\"Function to predict one company\"\"\"\n",
        "    X = pd.read_csv(companyPath).iloc[-(window_size+prediction_day):-prediction_day][columns]\n",
        "    X_norm= normalize_training(X)\n",
        "    y_pred_norm = model.predict(X_norm.to_numpy()[None, ...], batch_size=1, verbose=0)\n",
        "    y_pred = np.squeeze(denorm_training(y_pred_norm, X_data))\n",
        "    X = pd.concat([X, pd.DataFrame(y_pred, columns=X.columns)], ignore_index=True).iloc[-(window_size+prediction_day):]\n",
        "    indicators = dfindicators(X)\n",
        "    return company, X, indicators"
      ],
      "metadata": {
        "id": "DeJGWvrxu1e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict one company\n",
        "prediction = predict_one_company(goodCom[1], goodComPath[1], filter_compiled_model[1])\n",
        "print(prediction[0])\n",
        "print(\"Price prediction for latest \", prediction_day, \" days :\")\n",
        "prediction[1].plot(title=prediction[0])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "eYAjfQ-oxn9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a79693-6b7c-4ef2-afe7-b44f9128da82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPB\n",
            "Price prediction for latest  7  days :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAGzCAYAAAAsQxMfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADAGElEQVR4nOyddXxV5R/H3+fWulmxDRYwYHSndJcoIgZiIwoqoID1wxYLsRAMFBRBBBFpGN2dGywYrFh3bzfO749nwaRGqzzv12uv3XvOc57znLPdez/3m4qqqioSiUQikUgkdyia270AiUQikUgkktuJFEMSiUQikUjuaKQYkkgkEolEckcjxZBEIpFIJJI7GimGJBKJRCKR3NFIMSSRSCQSieSORoohiUQikUgkdzRSDEkkEolEIrmjkWJIIpFIJBLJHY0UQxKJRCKRSO5opBiSSCT/WBRFqdHP1q1biY2NrbZNq9VSp04d7rnnHo4ePXrZee3s7AgJCeG9996jqKjo9lysRCK5bSiyN5lEIvmnsmDBgmrPf/75Z0JDQ/nll1+qbe/Tpw/FxcUEBATw4IMPMnDgQMxmM6dOnWL27NmUlpayd+9eWrRoAQgx1KdPH0aPHg1AQUEBO3bsYOHChdx3330sWbLkllyfRCL5Z6C73QuQSCSSSzFq1Khqz/fu3UtoaOgF2wFiY2MBaNWqVbX9nTt3ZujQocyePZtvv/22cntwcHC1cWPHjqWsrIxly5ZRUlKCtbX1Db4aiUTyT0W6ySQSyX+anj17AnD27NkrjvXy8kJRFHQ6+T1RIrmTkK94iUTynyYmJgYANze3attLSkrIyMgAoLCwkF27djF//nweeughKYYkkjsM+YqXSCT/KYqKisjIyMBsNhMREcHEiRMBGDFiRLVxc+fOZe7cudW2DRs2jO+///6WrVUikfwzkGJIIpH8p3jzzTd58803K587Ojry0Ucfce+991Ybd/fddzN+/HhACKi9e/cyc+ZMHnroIZYuXYqiKLd03RKJ5PYhxZBEIvlPMWbMGEaMGIFGo8HZ2ZnGjRtjZWV1wThfX1969+5d+Xzo0KG4ubnx8ssvs2rVKoYMGXIrly2RSG4jUgxJJJL/FPXr168mcq6GXr16AbB9+3YphiSSOwiZTSaRSCTlmEwmQNQdkkgkdw5SDEkkEkk5K1euBKB58+a3eSUSieRWIt1kEonkjiQqKqqywnVFAPX8+fOpV68ejzzyyG1enUQiuZVIMSSRSO5IQkNDCQ0NBUCr1eLt7c1TTz3Fu+++i52d3W1enUQiuZXI3mQSiUQikUjuaGTMkEQikUgkkjsaKYYkEolEIpHc0UgxJJFIJBKJ5I5GiiGJRCKRSCR3NFIMSSQSiUQiuaORYkgikUgkEskdzR1dZ8hisZCUlISDg4PsUC2RSCQSyb8EVVXJz8+ndu3aaDTXb9e5o8VQUlISfn5+t3sZEolEIpFIroGEhAR8fX2ve547Wgw5ODgA4mY6Ojre5tVIJBKJRCKpCXl5efj5+VV+jl8vd7QYqnCNOTo6SjEkkUgkEsm/jBsV4iIDqCUSiUQikdzRSDEkkUgkEonkjkaKIYlEIpFIJHc0UgxJJBKJRCK5o5FiSCKRSCQSyR2NFEMSiUQikUjuaKQYkkgkEolEckcjxZBEIpFIJJI7GimGJBKJRCKR3NFIMSSRSCQSieSORoohiUQikUgkdzRSDEkkEolEIrmjkWJIIpFIJHcWFjMc+AESDtzulUj+IUgxJJFIJJI7i12fw+qXYNlTt3slkn8IUgxJJBKJ5M4h+ThsmS4eZ8dCQdptXY7kn4EUQxKJRCK5MzCVwp/PgMVYte3codu3Hsk/hqsSQ9OnT6dt27Y4ODjg4eHBsGHDiIyMrDame/fuKIpS7Wfs2LHVxsTHxzNo0CBsbW3x8PBg8uTJmEymamO2bt1Kq1atsLKyol69esybN++C9cyaNQt/f3+sra1p3749+/fvv5rLkUgkEsmdxJb3Ie0k2NaC4P5i260SQ9mxkBN/a84luWquSgxt27aNcePGsXfvXkJDQzEajfTt25fCwsJq455++mmSk5Mrfz7++OPKfWazmUGDBlFWVsbu3buZP38+8+bNY9q0aZVjzp49y6BBg+jRowdHjx5lwoQJPPXUU6xfv75yzOLFi5k0aRJvvvkmhw8fpnnz5vTr14+0NGnylEgkEsnfiNsDu74Uj4d+CfX7ise3Qgyd/Au+bgtz7oLinJt/PslVo6iqql7rwenp6Xh4eLBt2za6du0KCMtQixYt+Pzzzy96zNq1axk8eDBJSUl4enoCMGfOHKZOnUp6ejoGg4GpU6eyevVqwsLCKo974IEHyMnJYd26dQC0b9+etm3b8vXXXwNgsVjw8/Pj+eef55VXXqnR+vPy8nByciI3NxdHR8drvQ0SiUQi+SdTWgBzOgvrTIuHYdg3kHQUvusG1k4wNQ4U5eac++CPsGoSUP5R2286dHzu5pzrDuJGf35fV8xQbm4uAK6urtW2//rrr9SqVYsmTZrw6quvUlRUVLlvz549NG3atFIIAfTr14+8vDzCw8Mrx/Tu3bvanP369WPPnj0AlJWVcejQoWpjNBoNvXv3rhxzMUpLS8nLy6v2I5FIJJL/NjkfPE7atkxUR1/oPx2T2cIHBzWYNQYoyYWsMzf+pKoKWz+CVRMBFTybiO0HvgeL5cafT3Jd6K71QIvFwoQJE+jcuTNNmjSp3P7QQw9Rt25dateuzfHjx5k6dSqRkZEsW7YMgJSUlGpCCKh8npKSctkxeXl5FBcXk52djdlsvuiYiIiIS655+vTpvP3229d6yRKJRCL5l2E5u5+UJSdQLQ44PD0FG2snNoYl893uBAZZ+9OcKEg8CG5B13aCtFMiKNvGRQgezybg2RgOzxe1jAC6ToHOL8JnIUJ4xWyG+r0vP6/klnLNYmjcuHGEhYWxc+fOatvHjBlT+bhp06Z4e3vTq1cvYmJiCAq6xn+2G8Srr77KpEmTKp/n5eXh5+d3G1ckkUgkkpuGqlL882uoFuECK87QYgPsOp0JwCFTIM11USJuqPnIazvHzs8h+Zh4fGZr9dOjoAz4GNqXfy62HAV7Z8H+b6UY+odxTW6y8ePHs2rVKrZs2YKvr+9lx7Zv3x6A06dPA+Dl5UVqamq1MRXPvby8LjvG0dERGxsbatWqhVarveiYijkuhpWVFY6OjtV+JBKJRPIvJvEQlFwi5OH0RgqPVXkLio8fB2BXTAYARy31xI5rDaIuLYBTK8Tj7q9Cu2cw+XUkV7UjW7XnXauXKG75ZNX4tk8CCkSHQmbMtZ1TclO4KjGkqirjx4/nzz//ZPPmzQQEBFzxmKNHjwLg7e0NQMeOHTlx4kS1rK/Q0FAcHR0JCQmpHLNp06Zq84SGhtKxY0cADAYDrVu3rjbGYrGwadOmyjESiUQi+Y8TuQ5+6Anf94DCjOr7LGYInUZRmqFyU8nx46TklnAmXWRAH1XLvRUpx8FUdvXnP7USjEXgVg+6TYWBH7Oo8bc0L/2OVqVz+DG3FR+uPVU13i0I6vcBVBFYLfnHcFViaNy4cSxYsICFCxfi4OBASkoKKSkpFBcXAxATE8O7777LoUOHiI2NZcWKFYwePZquXbvSrFkzAPr27UtISAiPPPIIx44dY/369bzxxhuMGzcOKysrAMaOHcuZM2eYMmUKERERfPPNN/z+++9MnDixci2TJk3i+++/Z/78+Zw6dYpnn32WwsJCHn/88Rt1byQSiUTyT2aPyCYm8zT8eh+U5lftO7oQS9IpirOqxFBZXBx7jopgab1WIV71IE9xAHMZpIZx1RxbJH43e6AyG23xgXhAoU+IMADM3xPHjuj0qmPalbvMjvwCZdXL0khuH1clhmbPnk1ubi7du3fH29u78mfx4sWAsNhs3LiRvn370rBhQ1566SWGDx/OypUrK+fQarWsWrUKrVZLx44dGTVqFKNHj+add96pHBMQEMDq1asJDQ2lefPmzJgxgx9++IF+/fpVjhk5ciSffvop06ZNo0WLFhw9epR169ZdEFQtkUgkkv8gaacgdgcoGhG8nHQEfntYVJkuK4Qt71OcoQeLgs7LC32dOgCc2XkQgPta+wIKh02BYr6rdZXlJsLZ7eJxs/sBCDuXS9i5PAxaDR8Ob8YjHeoCMHnJcXKLyqteB/UClwCRxXb89+u6BZIbx1UFUF+pJJGfnx/btm274jx169ZlzZo1lx3TvXt3jhw5ctkx48ePZ/z48Vc8n0QikUj+Y+z/XvxuOAi6TIR5Q+DsNlj2NHg0hvxkCvN8ABXbdm3BomKMj6f4xHHw78GgprXZdzaLY9lBdOcYnDt8dec//jugQt0u4CJEz28H4tGbjbyVupO8J3/m5bffZke0LbGZRby1MpyZI1uARgPtnob1r4lraP3YzatxJKkxsjeZRCKRSP5dlOTCsd8AMAU/gOrRDB74FTR6Ue156wcAFBUJa5Bdu3bYNGsKgE/KWQw6DW38XWhdx4WjlvK4oXMHa35+Va08P80fEOcqM3Fg2xFmbvuKlntWU3z0KBkTJjBjUH00Cvx55BxrTiSLY1o8DHpbSAuHuN3XeTMkNwIphiQSiUTy7+LoQjAWUlhSn+hHXiXplVchqAdZ/b/GgrCyZNk1pvj0OQBs27XDuqkQQ8HZCbT2c8Zar6WNvwvHKsRQRpQQWTUh6QhkRILOGkLuRlVVdn/1Ex9u+JSgvCS0rq7oPDwoO3sWz9kf8Ww34Yp75Y/jHIrLAhtnaFaeyl9Ri0hyW5FiSCKRSCT/HiwW2P89qgVSD9qAyUTe6tVsWruHHmtdmWIcwylLHb6M6wkmk4gX8vPDulEjzBotrqX59HQTIR+t67qShSMJqoeYO+nyoRmVVFiFGg7CYtaS9NJL+Hz/GdZmI1kNW2D16yyip9wLej35oRsZHbudNnVdyCsx8fAP+9gckSrcYwCRa6sHfktuC1IMSSQSieTfw5nNkBVDbqIrpYlV6fRhM2eTW2wk2nsoj1rNxJwgrDy27dqiKAqqwYo4J5Hh1bZEuKsCa9nhbKvnqOUqgqjNRghbCoAl5D4Sxo0nb81aTIqGn5oMwnXORzxx4CWmZv7Agv7WAGR9+SXfNjbTvYE7JUYLT/98iD+S3MA1CEzFokRATTGbYOuHooq15IYhxZBEIpFI/j3s/x6LSSE93BmAw0FtAOiRcJgXWzizZGwnnu0eRNMMUdTQqnVbAMKTcjnlJDoOeJ4T+zQa5W9xQzUIoj69EYoyUW08SJq9jqK9ezFaWTO1y7NkDrmPj45OI604DY2iYUXjIjY3U8BiIfnliczq5c29LX0wW1ReWnqcQw49xZxhf9T8+sOWwtbpsPCBqw/6llwSKYYkEolE8u8g6yxErScr0g5Tbgklbh68FTKcSPdA9KqZh8/txaDTMLKpOw2zEwDYaiME0K7TmUS6iMdlJ05UTtn6/LihmliGji1CVSElsj75oaGg1/NJlyc56RaAjec6DqUewk5vx9IhS/lfx2n8OdSdGC/Q5hWy/+n7+Ojexjx9lyhYPDWqvpjz9EYozq7ZPaiobWQuhd9HQ2FmzY6TXBYphiQSiUTy7+DAD5hKFDIjnQFY3W4YRq0eHhgFQPai3zAXFKCeDENvMZFu48TM8ELKTBZ2x2QQ6SKyy4rDw1FNJgBa13EhXPXHhAbykyEv6dLnj1wHkWtJP+FAzu6zoCjEPzuVHQ4B1PIMZ1uqsPC83/l96rvU5/4G97Ni5FrSXn+MYgN4xeVxbMMCXh8UwuR+DTit+hJFHbAY4dSqK19/7jk4U16+xskPchPgjydEtW3JdSHFkEQikUj++eTEw+FfyAh3wFJmQd8ohHnWwrLSauQQDIGBWAoKyPl9CUX79wMQ5RXMudwSFu6L40BsFokOHmBrh1pcTGmMqETd3M8Zk9aGKEt50+6EfRee21gCa6ei/jqSzHA9mScdALCd+hpT0t3RWKVgdhMFFJ9s8iS96vaqPNRWb8sTfaaS1Fn0QUtZ/CsAY7sFUdvJmuXGDmJgTVxlJ8prG9XpBA/9LtLzz2yFze9dMDTt9GGiD2258pwSQIohiUQikfzTMZbA4kcoTS8gO8YOgJjhj2NSFRp6OVCnlj1uT4hWTFk//0zBrl0AeHXrBMD0tRGUGC24Othg27QJACUnRNNWa72WxrWdquKG/ngKFo6EsGVgLEZNi6RkendS5ywkeoUnaUedAKj1wgu8qQaTW5qHU91fMamldPDuwPMtn7/oJQSMehqAOofOkZUSh1ajMKKNH6ss5f00z26DgvSLHgtcWNvIMwSGfiWe7/xMWJbyklF3fUnOjLZ4LOhB/ZXDSD4TfpU3+85EiiGJRHJjMRth8/uQeBVF7CSSS6GqsOYlSD5KengtsIB9t26sUGoDJtz9trMtYRuOQ4eida+FKSWFkmNC6HS7vx8eDlaUmiwAdApyqyy+WHz8vLihui78ZO5Pok1DsJggah3Gn58kbXQIZ4YM5uzCXLIi7TGXaNE6O+M+cSKhrQayNSoJO7+fMWnT8bbz5uOuH6PVaC96GY07DyXJxxq9GQ7+PAOAEW18ScBTZLOpFji5/NL3IfkYpEeA1goaDxPbmt4HHZ6jOEtPytTnKXy1OUro/3DOj6o8LDfjMm4/SSVSDEkkkhvLiSWw/WP48xnxQSaRXA+H5sGRBeQl2pAfpwWNBueJE9kWlY7eZR9HCxYzfvN43j00HYeHH6w8TOflhX2AP892D6rc1rmeW2XxxeLzgqjb1HUhWvVlvOY9cgI/JPZwC06v8CTziDVluTpUDZg7dsT3m1nU376Nwvse5r01YVj7LEJjexZ7vT1f9vwSF2uXy16KZZDIHjOs3obFYsHXxZau9d1ZaS63DoUtu/TB59U2wlpYp1SLhcyEAGI3upMdZU38JjdObPfjk6z7SVTdxTnNphrd5jsdKYYkEsmNJX6P+J15WjTTlEiulcSDsGYyphINKUdFjSC3p57iiMaVglITNq5VRRKXRi1lotNasBW1fSrqCz3Yrg6+LjZY6zV0DXbHplkzAEqjorAUFwPQys+J4dFbeXPeSyR/8CXFUWmAQrybJ3vbt+P+/m8z1Gs4P1r8MGp0TPr9KGa3pegdTmLQGPiy55c0dG14xctp++hLlOrAM7WMsO1C+DzQ1o/V5vK4ofjdIkj675iN4ksGQHMh+Ezp6SQ8PYa0GTPBAukuzpgVBV2SmUEb91B0yApjsQaLqeyqb/udiBRDEonkxhJ/XgDqqZW3bx2SfzcF6bD4EVSzkeSTDTAXlGDVoAG1xo8j9GQqGkMqqiERnaLjk66f4G7jTnhZLEvaicwqx0GDABET9Ne4zoRO7Ia3kw06T0907u5gNlNy8iSm9HRKX3qBp8JXYW02kmhXi58b9uPVEW/jsehPRnw3l34dGmBRYebGKHp8upUTRYswOB9Eg4aPu31MW6+2NbokZ7faJLYTGW0JC34EoFcjT0z23uyzlIup8D8vPPD0JijKADt3COpJwY6dnBl2D4W7dqFaWfF16/sZ3fV1Fo/9COvuPVAsZsynLZxZ44ElO+f6/g53CFIMSSSSG0dRlujZVMGpFbdvLZJ/N+tfhfwkctP9KYjKBb2e2h9/hKLXs/FUKjonYRXq4tuF/gH9WTp0KXf53MWSDhYenaTlV+cqq6SbvRV+rrYAKIqCdbl1KOvnXypFhUlv4MsW9/F076kUjnyUn1+/h5Z1XLC30jHj/uZ8PrIFdgYtaZr1WNUS6e1vdnqTXnV6cTX4PvgYAD77zpKfnYpBp2F4K9/zXGUXySqrqC3U9H5y16wlYcwYzJmZ6OoHM23AFFb7taNXI0/efn4wAXO+oe6vC0APFqMG0tKuan13KlIMSSSSG0fiAfHboTYoWkgNg8yY27smyb+Pkjw4tZKyAi2pe8XHlPsLz2PdoAHhSXkk5xZhKBdDQ4OGAuBq7cqsXrOY2GYSxVYK3xz9hh2JOy46vU153FD++vWYMzOxCg7G9M1PpHbtzycjmvPFAy1wtNZXO6ZvExf6d9+BtecaACa0msC99e+96ktr1mskae56rIyw/5fPABjZ1o+15naYVQWSDkPcnqoDinNE/zKgoDiYpFdfA1XF8d57eX/wyxzEibputnw2sgUajUJ+WT4RvgqFtqJhrcVovOo13onobvcCJBLJf4j4veJ3UE/ISxQ1UE6tgC4Tb+uyJP8yIteiGktIPuyLpagEm5YtcXviCQA2nkpFa3sGRZ+Lg8GBbr7dKg9TFIUnmjxBUkESiyMXM3XHVBYPWoyfo1+16W1atqx87PLQQ3hMmYzG2ppld11iOVmRTN4+mbO5Z1FQeLbFszzR5IlrujSNRkPJwC4wfwvqilB44SMC3e0JCghgV2ITumpPwE/9wbOJ6GxvLgVzKUXmYBLf/gJMJhyHDGHhXQ+zddtZbPRaXhpixZt7JxORFcG5AhFzNEOvYgdklMgK1TVBiiGJRHLjSBDF7qjTHsythBg6+Q8QQxYz7P5KtD1w8RcfNF5NwCMEbF1v79okFxL2B9nRdhQlWVBsban90YcoWpGyHnoyFb2T6Mk1wH8ABq3hgsOntp3KqaxTHE8/zsStE/ll4C/Y6Gwq99u2a4vna69hCAzEvkvnSy5DVVUWRixkxsEZGC1G3G3cmX7XdNp7t7+uy2v96Esk/7IFn8RiIvaupWGHATzYzo8pZ8cwXb+Q7sohlNQwCA0DoCRHR8L2MtSSMuy63kX4qBeYtegYYKF/lwim7f8Fs1pVhdrLzguLkghAsanoutZ6pyDFkEQiuTGYjVW9nfzag7UzrH5JmP1zEsDZ77KH3zRyz8GyMRC3UzyP/ZvrpE4nGDEPHDxv+dIkF6EoC0vkJjLC3QDwePklDHVE0HFSTjHhyenYBwuRMCRoyEWn0Gv1fNbtM+5fdT+R2ZG8s+cdPujyAYoiXEeKouA6+pELjkspTOFU5imisqOIzI4kIiuChHzR46ybbzfe7fzuFdPna0Kt2kHsa+FF4OEUYn6eQ8MOAxjQxJs3//Lk8aLnebFzLZ5zP4FV+BLKTh0gYVstLMVlWLdowc6HX+KDZeEoulwCGq1gY4ooqjjAfwAjGowg2CUYJysn1n8VAqgg3WQ1QoohiURyY0g+DqZisHEBt/qg0UCdjiJdOGIVdHj21q8pYjX8NU40wdTbQbfJUFYEqeGQekK0eIjfDT/2hUf+BNfAW79GSXUiVpF7xoC5VIu+dm1c7r+/ctemU6noHMJRNGXUcahDc/fml5zG086TT7t9ytMbnmbVmVU0qdWEhxs9fNGxRcYipu+fzvLTyy/YZ9AYmNRmEg81fKhSTN0Iaj30MByege/2KEpSk7H29OaxzgF8uSmaL3Zl8Ku9PxN7fEOHpeMwFcdR5ufP5CajCFt7Gq39SZwC/iDdVIiNzobX27/O0KCh1danlkcEW0xSDNUEKYYkEsmNoaKnk197IYQAQoYKsXFyxS0VQxZjKed+n4Rf9AKxwbs5DP8RatWrPjAzBhbcC9mxMLcvjPpDjJXcNtTjS8mMsAfA9bHHUHRVH1Ohp9IqXWSDgwZfUZy09WrLxNYT+fTgp3y4/0NOZJzg+ZbP42PvUznmVOYppmyfQmxeLAoK9V3q08ClAcEuwQS7BtPYrTFOVk43/DpbDXiUdV98Qb0EE6e+nE7L979kYu/6NPB04OP1EcRlFrHni7m0OhtHgY0DY0MeIbssFUf/9ag2JzEDjVwb8XHXj/F38r9gfotGAdTKhrSSyyPFkEQiuTEklAdP+7Wr2tZwMKx7RRRizE+9Za6oiJ9fJCShPB2543joNQ10VhcOdAuCJzbAguHCUvTTIHhwIQR0vSXrlPyNgjTyd+7HWOCCxsEe5+FV2VqH47PZHXsa60CRnTg4cHCNphwdMppzBedYFLGI1WdWsyF2Aw81fIinmj7FyjMrmXloJkaLEU9bT6bfNb3GNYOuF71WT/LIrtT7dDO6FZswvpiG3sODQc286RPiyeKtp6j/0lsAzGvYhZKgjdg7HULFglbRMqrRKF5o9cJFY6YALOU6UbVIMVQTZGq9RCK5flS1qtiiX4eq7c5+ULsVoELk6luzljNbK4XQi+YJ5Hd76+JCqAIHT3h8NfjfBWX5QhhFbbg1a5VUQw1fTuYp0YjV5eGH0diJx+n5pTy34DAahyMoikorj1b4OdQsBk1RFF5r/xq/Df6N9l7tMVqMzD85nx5LevDxgY8xWoz09OvJ0iFLb5kQqqDVoMeI8AGd0UL6999XbjfoNPQ7EYpTaQFZtZzY22crGqcDqFjoXac3f979Jy+3ffmSQgjAUv7pLi1DNUOKIYlEcv3kxENBCmh04NOq+r4QUQeGk7egAGNxDqZlYwH4xdSbv4ztWHsi5crHWTvBw0uFJctcBqH/u8kLlVyM4nULKck0oOi0uI4aBYDJbOH5RYdJLczE1k0E6FfUFroaGrs15vu+3zO792zqu9THZDFh0Bh4vf3rfN7jc5ytnW/kpdSIVl6t2dhLZDPmLF6MsbxAojElhax58wCY262AMq2Rlh4t+WXAL8zsMZMAp4Arzq1qhGlIlb3JaoQUQzeDsiJIPCSbVEruHCrihbybk1ig0vP9dUz67Qh5JUZoVP7BFbtDVKi+HgrS4beH4YvmEB164f51r6ArSCbW4snHFhEs+8fhxJrNrbeGu78Wgi49AjKir2+tkqsjN5HMbXEAOA3pj65WLQA+WhfBgZT92AV+gVmbjqPBkT7+fa7pFIqi0MWnC0sGL2FWr1ksu3sZDzR84IYGRl8NGkVD3d5DifQBpcxI1ty5AKR/+RVqaSkp9Vw5UB96+vVkfv/5tPBoUeO5K8QQZvPlB0oAKYZuPGYTfBwIP/SE3ITbvRqJ5NZQUWzRrwOHlqxhxsIpePz8DQO/2MHhQldR18digqj1136OmM0wu5PITMuOhV/vg3WvgalU7D+5Ao4twoyGScZnebpXUxQF9p3NIiGrhrVWbFwgoLyI38m/rn2t/zYyoqEk97YuoXTDXAqSRJNV1zHjAPjrWDzzI+ZgU2cuii6PAKcAfuz3I44Gx+s6l1ajpatvV+o61r3udV8vAwIGsqSL+CjO/m0xBTt3kfun6E/2VadcUBSea/HcVQu2SjeZjBmqEVIM3WBUjZYcO/ECK0k4coXREsl/hPJii2WGevjP/hBrs5EOyeEkZhczYs4eDhtal4/be/Vzm40QOg1+uQcK08C9EbR+TOzbOwvm9hHtC1ZNAGCOaTBhmoY82smfTkGiVs3yIxfpBH4pKtx6d0pftf3fw9dt4POmsOsLMJbclmVk/rYcAIc29bAKCGBPXAyv730Wq1pbUBSV4fWH89ug32jg2uC2rO9m0aRWEzKb+hLpA2ppKYnPPguqytnW3kT7KPSp2+eartlSaRmy3OAV/zeR2WQ3GEVR2Jbrxd1EUBB7GOumd9/uJUkkN5eSPEgLx2JSSJy5DENxIQCexdnc18CZpZE5fB/jzGwDmBMPo72aufNT4LeHqoo5tnkC+n0AehsI7g/Ln6MsOoz8zcPR25spDq7H59n30T3EHScbPfe09GXX6Uz+PHKOJ10KyA8NFdWoz8OmRQscBwyo2tBwMKyaCMnHIDsOXG6/9eCmcWIprJksHpfkCtG57zvo+QY0ux80V/XXumaMEfvJPVUMKLg+NwmAlzdPQ7GOR6PaML3r2wwMHHD5Sf6lKIrCgMCBLOnyHW8stqAajaDTMbNtOgDPNHvmmuaVbrKrQ4qhm0CybTAUbUVNPnG7lyKR3HzOHUS1WEg+5kNpdAy51vZAKU4lRt5uZk37ps2Y81d5f6S0k8LyoLeu2dzrXxNCyNoJhn5dabUx5+WRdyyf3CNtKT5a9ToLT/ZH38jEkOa1AejfxIs3lx2j045lxP64CcVykW/J839GX6cONo0bczajkO93JDPVox1OqXvh1EroNP567s4/l9Ob4M+xgAptnwaf1rD5PdFTbvlY2DML+rwFQb3gJsfU5P3wIVgUbHxtsO3Ug3O5OeQSjgLMuGs2vQNb39Tz3276+/fnh4DvifLREHzOQnhXP1JcEq7ZKgRSDF0tUgzdBPKdGkER2GSF3+6lSCQ3n/h9ZEfbkhetglbLh107MOL0JlqdgbKoKEY82JqM/E5kbbXHlQJICxcfvFciOw7Cl4vHo/+C2qK5ZsacOWR8Mxu1rEzsUxRs6vtSfPocjc+cZFbqTFo8FAjUxiojla8PfI9XfCQADn37YvD3rzxF0aFDFB86RNonn3Jw/Dv8b0U4RWVmnGwaM5W9wlX2XxRDiQdh8SNgMUKT4TDgY1Eos/Ew2Pct7PhM1F1aMBwCu0Ofd25eMcqM0xQcOAYYcBwsxO6Ph0JRNGa0Zjd6Bba6/PH/AYJdggl0DmLmsBiez+vIdM8DwLVbheA8MWSRYqgmSDF0EzB7NoZksC9JEdkzshGk5D9M0e4tpB4RFXqNTz7HSfUU8XnQ6gwURpzCBQjxceKEJZBu2uOQdKRmYmjvN6CaIbBHpRAq2L6d9M+/AMCqfn2c7h6K4+DB6L28mP31MhrN/RSvwkxSHh1N6f0jyF21Gq+8PIp0VsxtN5KZn03BSlfl+jGeO8fp/gMo2ruX31hMkVcjNAosK27JVGtEllxeMjh63+jbdvtIjxTB58ZCCOoJw+ZUVQzX20CXCdBqNOyYAfu/E812v+2K2vR+SpuMxDovVrQzSQmDzGjw7wJ3fwPW1xbUbFk7jeJ0PQB2Qx8FYEv8dlCggWO725bpdStRFIX+Af35Jvcb3nIUQuh6rEIAasXf9GLWUMkFyADqm4B7LQ/iLB7iScrx27sYieRGUlYIYX/Axrfh1xGonzbi3B9nQVVw7NGJiLsGozGkE+8uPsByT4r//0beDhxXRd8vU+LhK5+nKAsO/ywed34BAHNODsmvvwGAcu/9BKz4C7ennkLv5YXFovJzvhPjekyisGM3MJnIXrgIS14e1k2b8uaQV1jj0YwtEenVTnPcZMOGhiJ77InwVbzUM4ivH2pFKq4cVeuLQRGrruuW/aMoLRBCqDgbfNrA/b+A7iKF+2xdod/7MP4gNBW9wZQTv2O9aLhovnvwR0jcL+Y5tRLmD4aCtKtfT/w+inZsRLUo6L3cMQT4k1dcRprpKAD3NOx1HRf776K/f/9qz6/HKgTnu8mkGKoJUgzdBHycbQhX/cWTFBk3JPmPkJMA33WHpU/Azs8gegPFZzMwFenQWGvw/vhzTqcXorFKJ85DvBFbYmJRVRUPB2tiDcEAGBNqIIYOzAVjEXg1FZYhIOXd9zClp5Pq4sVQY0sembufsHMiHfxQfDbJuSVoHBxo/O3XeL37Dvo6dXAbMwb/hb/Suatw8Sw7nEhqXgnfbY+h/+fbGT57D9/7daXQYIt/fiqP5IUxoIkXbeq6sNpUXo34v5RVtu0jUSDTuQ48vASs7C8/3qUuEZ1nMFr3MVvMzUmwuHNA3wZzpwkwfC489DvY1hLB5nP7QtbZmq9FVWHDGxSmiOrgdnd1R1EUfjt6AEWfA6qeoQ3uuuZL/bcR4BRAI9dGwPVbhaDKMqSoUgzVhKsSQ9OnT6dt27Y4ODjg4eHBsGHDiIyMrNyflZXF888/T4MGDbCxsaFOnTq88MIL5OZWr1+hKMoFP7/99lu1MVu3bqVVq1ZYWVlRr1495pVX4zyfWbNm4e/vj7W1Ne3bt2f//v1Xczk3DV8XG05ayjNQkqVlSPIfIC0CfuwHGVFg7wmtH4eBn1Lo/QQAdj36onFwICotB40hkyQ3MGlAV1SKKTkZgDLPFgBYZUeJwqSXwlgC+78Vjzu9CIpC3po15K1ejarR8EGz+ynT6tl5OoPBX+1kwm9HmLc7FoC+jb2wMehwGTGCehvW4zFpIopez70tfQHYeCqVjtM38cGaCCJS8jFoNfTrEIz3eFHXJv2LL1GLi3ltUCPWWkSPNTV2FxRm3uAbehtIPSlcjwADP62R+37/2SxGzNnD9gJfpru+yxDdN4zIn8QXysPQ9D4I7gdPbhDiKvus+B+p6XveqRWQuJ+CVBsA7Dp3BmBF9GYAfKybYKu3vfrr/BfzUpuX6OHXg5favHTdc6laaRm6Gq5KDG3bto1x48axd+9eQkNDMRqN9O3bl8JCkUqblJREUlISn376KWFhYcybN49169bx5JNPXjDXTz/9RHJycuXPsGHDKvedPXuWQYMG0aNHD44ePcqECRN46qmnWL++qmDb4sWLmTRpEm+++SaHDx+mefPm9OvXj7S0azDV3mB8XaosQxbpJpP820nYLz7k8s5BrQbw9GYY8jm0e5rCE6JisH2XLgBEZ8ahKGbMWoVzosQPJeVfmLx8/ElTndGo5stbTI8tgsJ0cPKDxsMwpqaR8vY7AKxrMYAolzo80qEud7cQGWPLjyax+rgQXEOae5NbmsuSqCVM3jaZH078QEphCg28HGjm64RFBYsKbeq68P49TTjwem9m3N8c78dGoff1xZSeTua8ebSq40LzJs0Js/ijqOZb11ftZqGqwr1lMYnSAcH9rnhI6MlUHpm7j/wSE23qurDkmU68N6wJALO2nOZoQo4Y6BYET4aKwpoFqRR/35/wH54hb9cPIhPwYsLXbISNb2Es1FCWqwWNBruOHSguM3O26CAAff2736CL//fQ3rs9X/b8Eh97n+ueqypmSHZCqAlXFUC9bt26as/nzZuHh4cHhw4domvXrjRp0oQ//vijcn9QUBDvv/8+o0aNwmQyodNVnc7Z2RkvL6+LnmfOnDkEBAQwY8YMABo1asTOnTuZOXMm/fqJF/Fnn33G008/zeOPP155zOrVq/nxxx955ZVXruaybjhONnpidSI+QsmIBmOxCEyUSP5tRK2H3x8FUzH4ti13iwiLgjk3l+ITQtTYdepEidFMakk8NkAtGw/i3ZOpm65SEBGOQ48eNKrtxHFLAL21R0QQdZ32F57PYobdX4nHHZ5D1ehI/t8bmHNzKQ2ozyzfrjha63i5XwOcbPQ81SWQD9acYs+ZVNw9YvkraROT9m/FaDECsC52HV8e/pJ2Xu24u0sfhhY2pWewD3Xc7CpPabKYQKfBbcILpLw8hcwf5uJy//1M6d+APyLa0YRYsg4uxbXV6Jt6q28qxxZB/G5UnS0pR70o+X04VvXrY9WwIcV+/rxytIR4Y/WaQkk5xVhU6NPIgy9GtsTGoDCoqTcbmqey4lgSk34/yurn78LGoMVs58m3AV/ROvlZ2hNB48TfIFFY+1U0qK5BaLybgGdj8GwqMtWyzlCYI2IrbZo2RevkxLpjp1GsYwEYEXJtLTck5WjL3WQygLpGXFc2WYX7y9X10ubW3NxcHB0dqwkhgHHjxvHUU08RGBjI2LFjefzxxyuzBvbs2UPv3r2rje/Xrx8TJkwAoKysjEOHDvHqq69W7tdoNPTu3Zs9e/Zcci2lpaWUlpZWPs/Ly6vZhV4liqKgd65NRq4jtcgT5mnf/3adjJtKwn5Y9AC0HCVSfCW3hoT9sOhBkdFVrw/cPx8MVSKicM9esFgwBAWh9/YmKikXjUEEKLf1bE2WzzY4mUfGiUN4A428HVlnCaS39ghq0mEumiMUuQayYkRdoVajyV22jMLtO1AMBma0eRCzUcuTXQJxshHZR019nXhxMCRt/5Ks0jQ2xotp6jnXo4dfDw6nHeZQ6iH2pexjX4ron/bF6YtfrqKqvO8N9ZKL2P72OHp+tRhDk2Fw6nccknZhKcpGY+tS/SCLRfRcO74YIteCg7coVtjsfnCsfe33/kZSlAUbROB5ofvD5CwQVq6SkyfhL9Fy5PXLHb8C4j4SDxVra14ICiKk1JGTNp78qE1n2PBuTFwTw/6zWRh4lSl1onDPP4VrQRSNNPHUUvJQsqIhKxrC/6w2dUFZYyASu3LL4u9hm1AUC47a2vg51qwrveQSVMQMSctQjbhmMWSxWJgwYQKdO3emSZMmFx2TkZHBu+++y5gxY6ptf+edd+jZsye2trZs2LCB5557joKCAl54QWSNpKSk4OnpWe0YT09P8vLyKC4uJjs7G7PZfNExERERl1zz9OnTefvtt6/lcq8aHxdbTmbXpav2hMgok2Lo2igtgGVPQ1GmaBXgfxfUl98YbwmHfxZCKHgAjPwFtPpquwt37QLAvouI9TidVlAphgKdAymsnwihRyiLFuojyN2ek0p5RlnCYarPVs6uL8Xvtk9hMSmkff45ABn3P8aOAkccrXU81tkfAKPFyOyjs/nhxA+oqLhZuzEocBBDgobQwKVB5ZercwXnWH1mNStjVhKbF3vJy1UVhV96ann7VzMem45TeuYMDw3uQ8xJH4KUcxg/CQbPEDRe5RaOglQ4sUS4DysozoKNb8LGt7AEdCXOZwh1uz+GRnfRq701bHoHijJRazUkY7Pol+gwoD9W9eqRc+Ik8QeOU7swo0ZTqSUlGMPD6QZ0AzixnLw58JyNM0Oca+PfvgXN6rRCY9Oa1LwS1sVkEn4mHtWSiZNbMQ018TTVJRDAOYy1mlG0NgUQ8UKlJjNh2XvBATp6d7k59+IOQtVKMXQ1XLMYGjduHGFhYezcufOi+/Py8hg0aBAhISG89dZb1fb973//q3zcsmVLCgsL+eSTTyrF0M3i1VdfZdKkSdXW6Od3Y799GMtK2DX/QzrsOUSYl2+VGJJcGxveEE05FQ2oFvhrPDy3R9ZuutlYLBBV7hbvMLZSCKXllbDvbBYDm3hRsEu89isCX88XQwFOASQ3KQSOYH0uE0tZGQaDgUK3ZpALuuzTUJoPVg5V54zfK9K1tQZo9wyZP83DnJ6B3s+P96yaQUFJpVUoMT+RqTumcjxdvLaG1x/OlLZTLhpw62Pvw5hmY3i66dMUGAuwXCa7pshYxMZ9vWhzWuXcxx8SOOc7IluMw+PouzhQDClHxc/5WDuhhgwjPzcQKxcLVmmhEL8bzdltBJzdRtSptQSPW3LLWltUI/EgHJoHQKH3kxQfm4libY3Xa6+hc3fny+Vh/OIcR2c/e34e1eKK05mysiiNjCL/5HGObN+NfUI8noVFeBbn4FmcA8tPkrR8YeX41uU/ANsfnMCb6j3kFZvQYqZheBKf5n6BxsEBm2ZN2RSdhsUmAg0wvGHvi5xdclVU/L9JMVQjrkkMjR8/nlWrVrF9+3Z8fX0v2J+fn0///v1xcHDgzz//RK+//Lei9u3b8+6771JaWoqVlRVeXl6kpqZWG5OamoqjoyM2NjZotVq0Wu1Fx1wqDgnAysoKKyurq7jSq0erM2A/63e6lqjM698ODMj0+mslOhQO/SQeP7hYtGbIjIY1L8N9P97etf3XOXdIBDFbOUHdzpWbn/v1MAfjsrF0ciE4KRlFr8e2TRsAolPz0ViJBIYApwDsg+0osP4B+xKVsjNnsG7YEC+fOiTluFJbyRJZR/5Vc7NLFFOk+QOYSjRk/ij+xgn3PU7E2ZJKq9DWhK28uuNVCowFOOgdeLPTm/Tzv3JAsKIoOBgcLjvGycqJbUPr0HJmHKVbd1B08CAd7xnHriYjmLF4Pe5Fp2mqS2CoVxZ+tZxQmtwL9ftRuHsf56aMReviQsAfSzlXlMPyeZ/ynHY5wZmbKPlrItbDvrjpbS2qYTaJHmuoqM0eJGOxyNJyeeABdO7uJOUUs/hAAigm/Brt493wLVecMqski6jCKM65nYN7xDbbEi1Ncx3pYwymaa4Dtueyq7WAsBQWUBp9mh5rfmLUn3+yIwt+3hNHnTXifJG1G+BRamHJ8X1odAXosKa1l7SkXzcVliGZWl8jrkoMqarK888/z59//snWrVsJCAi4YExeXh79+vXDysqKFStWYG195R5ER48excXFpVKodOzYkTVr1lQbExoaSseOHQEwGAy0bt2aTZs2VWahWSwWNm3axPjxt7d0vkajIau2PXZn8jEVlIAzolqrxXx7vhn+WynKElYggPbPQnBfsHUTHcrD/oCGg0QbAcnNIbL89Ve/d6VV6ERiLgfjsgGIW7+FYMCmTWs0tsIaE5mRjOJagoJCXce6uNu4s9kdQhIgJ/woXg0bEuLtyPETQdTWZokg6goxlB5Vfk4FOr1A+lezUIuKsG7WjA8KvIFCnuwSiFnJ55Udr1BoLKSFews+6voRte1vbGyOd+O2bG4RT58jKqkff4L/4t/oXN+DhhPu5+Ulx/g0Mp1P46G/gxdfNWiJXqshZ5mIhTFnZ5P4wot8NHAi60zDibL48LX+K6yPzQcnT+h52eicG8vBucIqbe1MocMQio+9jGJtjduTohzC7K0xlJktBNTfw+qEq8+W87D1IMgpiIisCPZZZ7OPQ+ALQZ2CaOXZigYuDWjg2oB69v6kj3qSkpMnyXzrTfp9+y39Gnuxf8WnAKy1rssHX+yg0HYnuEAT1zYYtBcpBCm5KhSt+HhXpBaqEVclhsaNG8fChQv566+/cHBwICVF+HudnJywsbEhLy+Pvn37UlRUxIIFC8jLy6sMUnZ3d0er1bJy5UpSU1Pp0KED1tbWhIaG8sEHH/Dyyy9Xnmfs2LF8/fXXTJkyhSeeeILNmzfz+++/s3p11Qt20qRJPProo7Rp04Z27drx+eefU1hYWJlddjsp8/eCM/m45WVTjBU2xiLIjAH34Nu9tH8Pa16GghSoFQy93xTbfFtD15dF4bjVL0GdTv+tNgn/JCrEUIOBlZvm74mtfOwcLrrI25e7yIxmC+cKYrFyBS/b2lhprbDSWpFZ2wES8kk5vh+v4Q/QyNuRXZYA+msPQNJ5xRf3fFV5vtJcDTlLlwIQc9+TRB8urLQKzTr2CYXGQhq5NuLH/j+i19z4WJzm7s35vMufdAtX4fhx8tetw3HAANzsrfjxsbb8tCuWD9dGsC48hfdXn+J/3Xwp2CysLhpbW0rCwgjO/47Q1vfTpO+j/C+0gPf1P8L2j8GuFrS/vsrCNSI/RTRdBdRe08j49BfgQquQYkgnR78BVHiw4YO4Wbtddlp7gz3BLsHUd66Ps7UzIGK3dp3bxcqYlWxN2EpMbgwxuTHVjuvSvw7Pn9ZTuH0HOb8vwXHQQBzPiPjOjIYtSMkrwdblFFpgSP2eN/RW3KmoOmEZ0kg3WY24KjE0e/ZsALp3715t+08//cRjjz3G4cOH2bdPZGzUq1ev2pizZ8/i7++PXq9n1qxZTJw4EVVVqVevXmWafAUBAQGsXr2aiRMn8sUXX+Dr68sPP/xQmVYPMHLkSNLT05k2bRopKSm0aNGCdevWXRBUfTuwbtAANkfjn5PFKYsfrTSnxTc0KYZqxomlwvqjaOGeOdXLEnSdLGJZko/BiudFFd07oHfRLSUzBtIjQKODeiJ2I6uwjBXHkgBw1UPTdBEUXZEFFJdZiKoXLrL6LkGVUylBdWFfGEWR4oOvkbcjc8rbcljOHRGFzvJT4Fh50dXOL5A2fQaYzdj37sWvhc5AOqM7+pNjTGJJ5BIAJrWZdFOEEEAz92bk2ius7qDjnu2lpH02E/tevdAYDCiKwhNdAvB1sWHML4eYtzuW7lE78TQasWrQAI/JLxP31BgGxO3DuVVzHu82gEHH7mVGWh4v6ZfC2inCwtn0vpuy9krWvw6leaQ7NmHy3DymHjsGVn+3CpnxClpNoWqki08XXm336jX1AdNr9HT36053v+7kleWx69wuIrMiicyOJCorirTiNHZaxeN8l8roTZD64YdYiorAbMZQty7zXhvGa3/tZVORCO7u6nfnVJ2+mVRZhqQYqglX7Sa7HN27d7/imP79+9O/f//LjqmY68iRI5cdM378+NvuFrsY7k3aAquom1VEuKVRlRi62W+A/wWMJbBmsnjcdfKFDT21erjnO/i2K5wOFam6Te699ev8L1MROF23M9g4A7D4QAJlJgtNfBy5T0nF2myk0M4Jq2Ah8E+nFaCxqgqersCpcTMgDMPZciFlZyDFriEYQZN9RvS22vctmMvArz2FKRoKtmwBrRbb8S+w6xdhYbi7RW2+OPwmJtVEF58udPDucNMuP8gpCFudLcvaFnJPuAvGhARyFi3C9dFHK8f0bezF+B71+HrLabL+/AtPwGnoULY6BrKjUX8eO7WWjqt+ouTBXkzoXZ8xv9yDly6fh5X18Ocz4NMKXANvzgXEbIGwpaBoeMP4GEOPidpvK/074BCeR/8mtiw+kIDO8TiF2gistFa81v61G9IQ1dHgyICAAQwIGFC5LbM4kxkHZ7BKXUHraGgcX0zaxx+Lne1a8Gvkj5zRr0RRVIJdgvGyu3Tcp+QqkG6yq0L2JrsJBLTsCoBrgcqpslpio2zLUTPOHRTpyXYewiV2MTwaQqdyEXxs0a1b251C5FoA1Hr9yV25kpL4BBbsFZWmR3f0p11mNAAH3OpRZBTvtCKTrCp4uoK6LcS3fLvcUkzZIt6otrcP8RZ3MSB2l4htAdQO40n7RMSRON8/gp0ldpSZLQS521GoxBAaF4pG0TCpdVVG6M1Aq9HStFZTSg0K5x4Q68/4Zjbmv9Ulm9gnmKHuFhplnsWiKJh69uHjdZH8HtyD1GbtwWgk8YUX6eGlJ8TbiTdKHyHeoZWoAn18yc1ZvKlUuJiBwmaPUnY8mUbZcZTp9CwK6MpH6yLo89k2ytQiHGqLsIOnmj6Fn8PNq+njZuPGB3d9wPt3Teenu+0pNiAqYgPvqiv56shXxObFYq215rHGj920ddxpKFoRo6pcwUAhEUgxdBNwdPUi00X8I2YXlWdVpJyofAOQXIbY8lINAXddUNemGs1Git8xm0WwteTGUJQFcbsBSN+WRtLkKcQMvZsGx3fiYqtnaPPaWB8T7RL2uwezNVJYg6IvYRlq5NeKNCfxODNMWHobeTtWdrBnw+tQkgtu9Sgq8KTkxAk0tra4jxvH2hMiJrF/Yy9mHBTV6IfVG0Z9l/o39x4gXGUA25vrMNQLwpybS9onn1Qbo9UovKycAeCwezBDFkYSn1VELUcbWn8zE4O/P6aUFLLnzWNC7/qoaJidW27RClt6c94Pdn9JWexZ0iO8iPnsKFMOiS8Lng8/xLRH78LH2QaTRcXKfQMmJY+6jnV5oskTN34dF2FI0BC+eWQpG4aJDGSjFk7W0dDeqz3vdn6XLfdvYUjQkFuyljsBGUB9dUgxdJPI8xOVam3zc7GghaIMyE++zav6F1AhhvyvUHTNvYEo628x/be6it9uokNBNWO0aUTW4uUAaEqKmXx4ER9FLkOTfI7SkycBOOpen7Vh4n86Ki0TjT4HgECnKvePo8GR9Noi2yzhmPjbNvJ24ISlfEx2rPjd6XkKy6vH2/fsSZmjM1ujhKXJzTOKo+lHsdHZMK7FuJt15dVo7i663B/LCsNr2jRQFHKWLCV/69bKMaqqUrZmFQDb/duQli+q20/qE4xDLRdqjRNrLdixkz4hnoR4O7KqrBUmxSAa3qaG39A1m84cIe6Nb4lZ7UnGUQ369FSKdFacad8bjxee556Wvmx6qRvP97fBynUvAK+1f+2WZm7VdazLpGmrOft0H2JeGsaKh0P5od8PDKs3DHuD/S1bx52AopNi6GqQYugmoQbWAaBObhppVuKxdJVdAWMJJOxHVUGt07narovGolXECoX9ceE+ybVRnkWWftIVtbQUpVkLfm7YDzMKfoe2cXaYKC5jCaxPtrUjWyLSRHPN3FgAHA3OlVlGFZgCRNPJvJOi3lbI+ZYhEC7RZg9QtEd8QNt17MC2yHRKjBZ8XAwsO/sdAKNDRuNh63GzrrwaTd2bAnAm9wym5g0q44WS3/hfpbuv+PBhjImJaGxt6T/2AQAaejkworWwfGzzFuNKIyIwZ2QwoXd98rFli0UIrRv6f1tWRNZbT1KUpgcF7O7qwk89Hueh/m9imPoGGjvRRiWnLJ09ed+gYqG/f3861e5049ZQQww6AwNf+pJ7npgu44NuIkp51XON9EjUCCmGbhIODUWLEv+cXE5ryt0Gsvji5Tl3ENVYytmN3px5fBJlsbEAnErOo8mb63l/9cnq4yvE0NkdIiNJcn2YSuH0JkqydeTujwVgXdf7WdSwD0sfeR2dt7fIAgJq9eiKt5M1hWVmFu2Px6QVBVCDnC6sPWbXMAQAzRmRLRRQy44ozXliqP0YzKUmisPCxPgOHVgbJv6eDepFEJcfh6u1K483uXVlM1ytXanjIL7EhGWE4T5xgnCXZWSQ8tbbqKpK7nLR18uhf3+Gd6rHque7sPDpDmg1CnOOzeH18I85U/5ZX7h7N31CPAmsZcdyo6iXRtgfN8ZVpqqwaiL5ESKmqfa0qVjP+IrfnRpTpjfQzl9Ua98cv5n7Vt5HZHYkjgZHJredfP3nlvxj0ZQXO5aWoZohxdBNonZz8YZXJ7OUo8byKt0px27jiv4FxO6kJFtPaaZCWcwZYh96mOLwcH7ZG0dhmZnvd5zlYOx58UEu/uDTBlDh5F+3a9X/HWJ3Qlk+aWHuoKrY9OvP92mirEGfkf0IXP4njgMHoHFywmnoUPo1Fp/0320/Uxk8Heh8YYZUxWvBOSkP1WJBp9VQ29OLv8ydyHMMhrZPUbT/AJjN6OvWweLpxeYIMV+x/iggrEJ2ersL5r6ZVMQNHU8/jsbKitoffgQ6Hfnr15O7bBl560TWndPddwPQxMcJZ1sdH+z7gFlHZwFwLEBkaBXs2oWiKLQLcGWzpQVlGhvIiYNzhy9y5qvkwA+U7lhKWZ4edFrsBw9n71nxOgnxdsTKYOb9ve/z4pYXyS3NJcQthIWDFt4yK5vk9lDRD0+KoZohxdBNom7jDpRpwdoIJ7LLKxhIy9Dlid1JYVpVuxRzVhZxj4wmPnRr5bY3lodhNJ/36q6oQi1dZddP5FoKkq0oPKeAXs+a9sMoLDNTz8OeTkFuaJ2c8PnsM4L37sG6QTADmggxlJJXctHg6QoaNutBmRasylTSTovXQCNvB140jueHJgvAxoXCvSJeyK5DR3adzqCg1ISHo0J0nvgC0c232624A9WoEEPHMsQabJo0ptazYwHhLrPk56Or7Y1tW9GOpMxcxpTtU/gt8jcUFMa1GFdNDKkWC839nCnGmgNW7cVJrvf/Nn4frHuF/ERR6d+uUye0Dg7sPZMJQOO6Rh5a8xC/RYo6To81fowFAxZQ17Hu9Z1X8o9HoxexYBophmqEFEM3Cb3BmgxP8QZlKcgXG7PjwFh8G1f1D6Y8XqgoTbyAa73wPLYdOqAWFTFl67cMyAjDxVZPREo+83fHVh3XeBigQMI+yIm/HSv/b2CxoJ5aQ9oxRwBMQ4czI6wQEAHBFTVowjLC+Pzw5+SX5dPG35Va9uVvuIZLiyE7G0fSPYXIPXtkGyAyygBOJovXxvnxQhVZZK2Ccyg1l4q2D85Bf5/2pnO+ZaiiuWutMWOwbtq00r3lNGQoikZDUkESz218jvWx69FpdHzc9WPGNh9LSSN/SvRgycyiNDKS5r7OACwqaidOEr5MNMW9FvJT4ffRYDGRly6EqWPfvgCVYuiU6Tuis6NxtXZlTu85vNTmJfSXy9KU/GfQlP+dFRkyVCOkGLqJFNcVZmiv/FRMVs6AChnRt3VN/1jK44WKM8SHpkPPnvh99y1nGrdHbzEzfuc8XmIjADNDo0jOLReVjrWrGomG/3k7Vv7vR1Vh3VRyj2dRmqNH4+DAq7ZtMFtU7m5Rm4FNvcuHqUzbPY0fw37knT3voNUo9AnxAixoDBnAxcUQQHGg+LDO2Saac1aIoVPJeZgyMiiNFq8LQ5u2hJ4S8Ue2ziJtvVPtTjekIODVEuwSjLXWmvyyfGLzYgFQ9Hpqf/QhipUVaDRoB/ZkxsEZDP5zMPtS9mGjs2FWr1n0DxCFZRt7NSe8jlh74a5dBHvaY6PXsqG0MWaDo8gwjd9z6UWoqug8v/plLN/3ovibbmR93oWkTzqS+XlnKEih1BBMaUoRaLXY9+pFWl4JZ9IL0drGElsQjl6j57dBv9HZp/OlzyP5z6E1VFiGpBqqCVIM3UT0weLbrH9uBrl25bEUGVG3cUW3mcRD8FUbOP77hfvK44UsRgWNk6hsXKZoeTVkJGtCfNAALRetZHRJJIVlZt5ddV4w9WWyysxmyz+vvtOheTCrPaSdut0rEWz7GMvu70k/IQTK4a7DCMsHT0cr3hnapHJYZHYk0dlCtKyLXcfas2sZ0MQLRZ+NojGh1xiobXfxpqmOQ0T9GK8dkZhyc2nkJc51LqeYXUtE7I1Vo0YczFbJKTLiamcgtlDE09yOjCcQbSZC3ETw9/H0qkxQq8BAav86n5PTRjLk8Fjmhc/DaDHS3qs9CwYuqLbeZu7NOBZY7irbuQudVkNTHyfK0BPv2UsMupirLDsWtn0MX7eBH3rBge/RnDuITdpRXHNOULvwJG7mdPJUW8LLRP8427Zt0bm4VMYLudUW9aKGBg3F21728LvTUKSb7KqQYugm4hLSAoC6WfmkGMrT69Mjbt+CbicWC6yaAJnRokLu3wslnhcvZNu2DYpGw7aodPJMJcwbnMv6VgoaFUaG/kjr9CjWnEhha6QIsiXkbtHHLPkYZIieWZTkkvnXa5S8682Brx65ddd5JfJTYN2r4v+gvJHmbeXAD7D1A7Ki7DAVazF7eDFNIwTAx/c1x8m2yqWyIkbUc3LQOwDw3t73CPI24ecpXF11Heui1Wgvepo2Ax4j0V2DlVEleuF3ONnq6RAospwOLw8FoCCkRWXdoq4NDUTnRKOg3NTWG1eiot7Q+WIoPCOcB6Ne463SJeSX5VPfpT6ze8/m+77fE+wSfMHxFXFDxYcOYSkqormfqEK5TV/eg+vkcjCbxOPsWPjjKUrfbUXRko8pioyjINuedWmtmZrzFOPUqUx3fosFgR/zled7dC/9jNTNBwBw6CP6yO09k4nGkEax/jgKCo82fhTJnYdWL95PZQB1zZBi6Cbi30oEfXrnmIk2lzeQTY+8jSu6jZxYIvqzgag4vGNG1b6/xQvZtRPxFCuPJaF3OgraEn7so2F3IwWN2cxbB34mODueN1eEU2I0i07ggd3FXMcWwZ5vUL9ogduRWdhRQqus1f+c1PstH4BRpKcTsbpKvN0OwpbB6pcxlWjIjBLdyuc26IdRq2dUhzp0C3avHGqymFh9RrRveLfzuzR2a0xeWR7v7n2b0V1FxlnQRTLJKrAz2HGmd0MAChf/gWqx8MOjbXmhZz1aljd9fSfJlt8PivR7b2/xO8QtBBdrlxt84TWnsvhi+jEsqoX54fMZtXYU8fnxeNh48G7nd1kyeAldfLpc1JVX36U+2e7WpDmBajRSdPAgzf2cAVieW080bS3KFIJo3WvwdVvSF63lzBpP4ja6E7fRnYT1jtTdnMzo9ev4oH0LXp0wkVGjn2H0o2NxUrX4p50FwKF3H0CIIb3rDgC6+3W/pOtS8t+mQgxp/mGG8X8qUgzdRGr51CfPVlg0otJLxMY7UQwZS2Dzu+JxPfGGzf7vqqoP/y1eyLZdO4rKTGw6lYreRZj6721wH18P1nDCX0FXVsJ7e+dijo1l+ppTmHNzKdS0JivKjvxFX8P6V1GKs4i2+BBj8UaLhaJDv93ii74IaafgyC8A5NoHAirs+fr2rOXMVlg2BlDJSG+HpcRIuncAy10bU9fNltcGNqo2fHfSbrJKsnC1dqWrX1c+6PIBVlordiXt4tcIcU1X+tD1ve8hCq3ALiWXwl27sbfSMb6RLZ5FWVg0Wk7WCsRoVnGw1pFhFllnt8tFVkFF8cXTOacZGzqWTw9+isliok/dPiy7exnD6g27pDUMQKfR0di9Cccrssp27qwMog5PKcTUUKTl88eTsHcW+fEKGWHChaj386PEw5skOzcybJzRqBaS3/hfZXyVk62el21EA9xo9wCMLq6k5ZVwNjsZvZNwMd7K2kySfxY663IxJC1DNUKKoZuIRqMhw0uUmM9PE9kdZMWA2XgbV3Ub2DcHchPA0QdG/iKsOOYy2FQukC4SL7TxVBpluhi01ilY66yZ2HoiTWu34pN7NeQHeeFQWsinO2bR862niWrfgfh3F5B62InEnS6UmD15R3mG/mUfMtcs4in+EQ1dQ98E1cIx+7t4OvNhse3oQihIu/VrWTMFLEZKPfuTvU98oH4a2A9Fo+Gz+5tja9BVG74yZiUAAwMGotfoCXQOZEKrCQBkFJcHTzteXgx1rd+Xbc2FcDg3T1SVLtxdnlLfsgUrJvfh0Y51+Wh4U/aniOyy2y2GPGw98LbzxqJa2JO8ByutFdM6TmNGtxk4WTnVaI7zXWWFu3bj62KDm50Bo1klxququ3uZIYSkQ6Jat8uoUTguW8HoHlN5ss+rxH69ALtOHVGLikgc/zzmfOGaDDl9CIAtnk2Yu+Mse89moXfZjaIx09y9OS09Wt7I2yH5F6HXi2xmjQUsZvNtXs0/HymGbjKl/iKg1CEjDVVvJ3ppZZ29zau6hRRlwY7PAEhvO5nRv5xgXe1xqCiiWeW5wxeNF1p5LAm9q7AKDQ4cjJOVE/fWv5cSK4WPR+oxBATgVFaIR3EOAKqXN1pHO0BhoWkMPxZ3o56nM+l1BlCq6rDNjri9dZ7Obofo9aDRMUs3iv1qQ05qgsFcKqxkNSF2J/w87PrbumSdgYxI0OhID3MFk4m0xm047l6PHg08aF3Xtdrw/LJ8NsdvBqjWSPOhRg/Rzqtd5fMrWYYcDA6k928NgHn3Acri48+rL9SBeh4OvH13EwJq55JVkoWtzrbSTXU7aevVFoB6zvX4bdBvjAgecVXZbc3cmxFWV8GiQFlMDKaUlEpX2W5jfbjnWyyD5pC4uxaWohJsWrXCc8pk3l99ivxSE818nXDyPMlXd+sxe7hSFhdH0iuvYsrIoOSwsADt8m7KnG0xrDgWg8FFCElpFbqz0VpViSGT6Q77An4NSDF0k7FvJNwNdbKzMLnWExvvpCDq7Z9AaS54NuXH/HZsj0pn7EYj+xzK3WXrXr0gXii32Mi2mNPoHEQjywcaiL5Pfev2xV5vT6SaTOaMiXi+9x4LHnyN4YPe5ZmBb2A9bAQAOYdFW4f37mmCb+3abLS0Euc6dptcZRYLbPifeNz6cQ4X1AIUviwpt1rt/x5KCy4/h6kUlj8LZ7bAksegrPDa1xMtShQUaVqQv2kraDR821BYKIa2uDAbLDQulDJLGUFOQTRyrXKfaRQN73Z+F0eDIy5WLjWKTWnX9m6OBCooKmT/upCivfsAUV+ogl1Ju8RY73b/iJo4L7d5mU+6fcKiQYuo51Lvqo9v7t6cQhuF095VKfYtysXQsYQc1GYjSV50gNLTp9G618Ln85nsic/jr6NJKApMGejDe/veZV3Obl4fmItJp1CwaRMJzz4HFgtWISF4NQigsMzMtuQ1KNoS3K196eHX40beBsm/DJ2hQgwpmI1lt3k1/3ykGLrJ1G4hKs3WzSwm36G8cFzGdcYNpUf9O1xtWWfEBz1An7c5nJBXuWti+hBK0UPC3gvihTaEp4DDHhTFQmvP1jRwbSD26W0ZFDgIgKXpobjeN5zJk0fi5ulKQlYxPxcIt0VIViwjWvvS1t+VIHd7/jSXZ+2cWFKVtXMrCfsDko+CwYGyLpPJKBDdzTdY2pCu94GSHDiy4PJzHPihqqhkVoxwuV0r0RtQVUjbI0znlv6D2W12wlqvoXcjzwuGV2SRDQkacoFFpLZ9bf4a9hdLhy7FWmd9xVP38OtBaBvhKsv69VfM2dkoNjbYNGtWOWZPkrAW3W4XWQUu1i709+9fo+u7GLVsauFj78Oxcq1YsGtXpWUoPDaDzO9/IG/NWtDp8P38cyyubrzxlxD0j3Soy/7sPyk2FVPLphYJPga+7yv+BiUnhKUzv1NjhncqQ2t7BoPbTgAea/woGkW+vd/JGKxEYoNGBaO0DF0R+Wq5yQS06IoFcC5SOV3mLDZeTxD1oXkwq62wEvzDKf5lKiVZKgT1xBTQg+OJuQB8OqI5Bjc/fjSJwnQV8UImO3uW51jzy97T6F32A/BgwwerzXlvfVFTaGP8RrJLsnG2NTD74dZY6TQsKRZZR3XzU5nSSdRVCXK3Z5ulOTk4QkGqCBz+O9lxwgV1MzCWwKZ3xOMuL5JqdqjcZUHDVyXiHrB31qWFWnG2qDkD0Lz8fhz4Hk5vuvr1lBVB7A7yE60pjklFsbFhfbuhAPRq6ImdVfVYocT8RA6lHkJBqRSif6eWTa0a97lysXZB27EdKc6ASVyvbZs2KOUF4oqMRRxOu731hW4GzWo141igeLst3LmLOrM+YM6mT5g5fwLpnwk3sufUqdi2bs1Pu2I5k15ILXsDT3T14LcIYdF8u9PbrLxnJbb3DGFjiypROlmzjE9PvIht3e/Q6HPQWBwY2eieW3+Rkn8UBmshhrQWsEgxdEWkGLrJ2Dm4kuYivglHp5ZXTb5WMZSfilrhbjmxBE5vvPTYqA1wcsVtKzhYdmgDcd+e4Ow6DxJ3ORNx6CTFRjMOVjrubenDque7ENfoGbJU+8p4of2O/ryyPJyTebvQ6Apws3anZ52e1eYNcQuhkWsjjBYjq86sAkSDzA/uaUqulT2JdrUAsDktChoGedhhRMdyU3mn8L8HUqeehG/vgnmDIOnojb8R4X9Cbjw41IYO40jNE1mFvi42NPJ2ZLHxLor1LsLqc3L5xefYMUNYj9wbwd2zoO3TYvtf44VQuhpid6IaS8g4JeKCXB97jD9ihaVqSPMLC/NV3OP23u3xsvO6unNdgt4BfVjfuuqtx65DlYvsYOpBTBYTPvY+lV3j/ws0c2/G6dpQaqPDkp9Pyfp11M1PRatasDg44jZmDC6jHiarsIxZm0Wpgan9G7LszAKKTcU0dmvMXT534WPvw4d3fUivmYuIbOfF9i7OWAcGEuAUgJ+9P9aqDw/Wex4rrdUVViT5r6MrjxnSWsAo3WRXRIqhW0CalzMAeUnlGWUZ0dfWjyj0fyileZSp5am8ayYLy8PfiVgNC0fA74/A+teuvffRdVCw4GNUi/j2mr91L8rjDzD2+HI61dKg0Sg4WOv58OG7ONXlKxKy/AAoadyc3o08cPc5CMCDDUei11wYMzK8vmjO+kfUH6jlYm94a1/eHtoYmgh3S9HhIwC421vhYK3jjwpXWcQqKCl312XHwYJ7Rd0jgFMrbvyNOCt6cdH8ATDYkpwr/l61nWx4sJ0fpRhYoi3PKNr5ubDcnE92HOz7Vjzu8w5otNDnbXANgvwkWDv16tYTvZ7iTD2lWaBYW5PQ+27O5RRjb6Wje4Pq1h1VVSuzyIYGDb2681yGnnV6srWpQkn5n9auS1WbiN1JImj+drXguFk0d2+ORaPw02AbHO++G/dJk1j98BRG9fsfm6b/gsekiSiKwlebo8kvNdHI25HuIbaVVqHnWjxX7X6EeDdn2M9beOaHPawYtoIVw1awZvhKDjy2jlfuevBSy5DcQej0VYLYUlZ6G1fy70CKoVtAka9Il7VKyQCtAUzFwlpwNZzdAccXY1EVHjW+QorqImJydn1efVzGafhzbNXzvd/An2PAdAu/GSQdpfC4+HbrNKg3dl3vQmM2c/eZnYyfO5WMOXOwFAsrWafuQ7DNFCbcJ8ffx/gBegqIQafRMTx4+EWnHxg4EGutNTG5MRxLP1a5/dFO/rQZ3B2A4vIsG0VRqOdhzwk1gAKHQDCVwMm/oCAdfhkmekMZyl1XkWtv7H1QVYxhO4jd5MaZT7ZxZsgQvCc+wexNnzDmz08YoM/BSqfhs5xumPV2kHoCvusOKWFVc2x+T5QhCOgK9cuDzg12cM+3oGjg+GIIX17j9RC9gZwYWwAc+/dnZYwI3O4b4om1vqpejkW18Hvk78Tnx2Ojs6FXnV434IYIPGw9qF+nJdPv13L2pXuwbtCgcl+FGOpc+7/VR6uha0MMGgOb6xVjfv05ao15Gtce3cm0ceJYufs4LrOQBXvjAHhtYEN+OTW/mlVIIrkadLoqMWQqlWLoSkgxdAuwCm4MgGdaFrhVZJRdRY8yUxnq6pcA+NXciz2WxrxjLG8xseMzyIwRj0sLYPEoKM2DOh3h7m9AoxMutUUPXDljKXYX/DQI5vaF0vyrucRqqJunU5QqXoguT4ylznff8fnAF4l28kFXUkz6518Q068/OUuXUnziBJaiosr6QvPC5wEinb6WTa2Lzu9gcKB3XdF6oCLluwLblqKuSvGJE6hGIbKC3O0BheNu5RaYw/Ph1+FCTDrVgadCRTuPtJM3tuxBThzZR3IpTreiNC6Z0ujT2CXF4Z+fik/cKbLGPMnTthnk4MBcv+lg7yWC67/vCfu+E2UHTpT3cevzLpxvKfFrC10micerJl7Y3uRiZERhTk8gL75cDA0fzuoTov3FkOZVWWS7k3YzctVI3tsn2oUMDRqKrd72+u/HefSu25tTdRR+8T7LH1F/8MG+D3h07aOczT2LVtHS1rvtDT3f7Uav1dPITWTiVQj4FnWcxfPEHFRV5eP1kRjNKl2D3Wnsp620Cj3b/Nn/lJVMcmuoaNQKYCm7iAdBUg0phm4Bga3FtzrfzDJKna4hvX7P1ygZkaSrjszRPcSoDnVYY2lPmE0bUadmzWTxrX/FeEg/BfaepPX7lp32/Qjr9h1mrQ3EbCL/uwEUJZ280G2WFgELH4B5AyFuJyTsg6PXWKQw6SjFuzdjMWnQOjth3agR2YVlrDf48WL3F3F6bzp6Hx9MaWkkv/E/4p8S8S+2bdsQlx9fKW4ea/zYZU9TEVy7N3lvte2GwEA0Tk6oJSWURIh7LMQQbNB2BRRIPCD6mNnWgtHLyXOsR4lPedxK1Lpru+6LEbuTwmQhCms99yx15v3En6Ne49XOz5DTqAWWoiIGLvyYrolH+eK0J4VPboP6/cTfdO1kzPMGi3majYTaLS6cv9tU8GgMxVk1q2QdvYG8OBtUs4IhMJDjLnVJzy/F2VZP53q1iMqO4pnQZ3gm9BkisiKw19vzYqsXmdJ2yo27J+VUiNmwzDDe2vMWiyIWVQZOd/frjqPB8Yaf83bTzF24cCvEUIi3IzqNQkZBGatPJLP6eDKKAq8OaMi88HkUm4oJcQuhq2/X27lsyb8Uja4qxMAsLUNXRIqhW0Drtl0oMoDBBGH55em5NU2vz45DLc8k+sD4MGP7t2FUh7qAwoT8UahaK4jZBIseFMG6Gh2Fw36k/49RjJq7j8FrrRle9CpZqj0Omcex/a4j6nQf+L4XrHxRuNRmd4SotcI64lteRG//d5eONTKVQcSaqlib89n2EQUpQgDYdbkLRaPhaEIOAP7utoS3tcPjr8V4vDIVrZMTapGIkbFr146fT/6Miko3324EOQdd9ra09xYlCyKyIsgtrVqHotFg26IFUOUqC3K3A+Bgjh0ElLsbDA4w6g9wC+KJnw4wI678fBGrL3veq8F4fBMl2eLbmcvDD2PXoQOH3II46l6f7P99iMOA/igmE1MP/kqvU9tYdbqM073nssl/EmXo0BoLKUXPoaDxmLKzKdy7l9zVq1HLyl2eOgP0fF083vftla1D0RvIOSMsPM733cfK46Jf24AmXmSXpvPImkfYnbQbnUbHqEajWHPvGp5q+hQGreFys14TPvY+3FPvHtxt3Ong3YFHQx7l/S7vs3TIUmZ0m3HlCf6F/L3pq7VeSyNvIfpe+UOkyQ9v5YuDfV5VrFDz56RVSHJNVI8ZkpahK6G78hDJ9aLX60nwsKFBYjEx5/JpraVGbjJj1GHyvpiAKVFPsupJI5tCem9ZhAK8FJ1AXomJSPd2uGQfgyO7AEfw78rxmasYHpuN0caOAh9/zrn5McX2I8bkf00zTqMvKqb02DFKt57EVKrBNVhF22ww9H6L7SlaOi7vgj4zGs5uhaCeFy5szUtw+GfhYrpvLviVC6ikoxC5hsIU0eDTrrOI+zgcLzKe3GofYNLWX2ns1pj5j8zH+d57yZz7I2Vnz2Lqdxd/bfgCuLJVCETcSaBTIGdyz7A/ZT996vap3GfTsiUF27ZRdOQoro8+SpCHsAzFpBViGfoGGt6H7q9A7RYk5RRzMC6bVKUlr2t/hrjdIkPL5jqbg6oqhbtFQUHr4Lro3EQj1JTyAGqvWo74zJhBqqsb2b/+yrMnlrP9tTgWl8cvRdOHVko0Ofn22Cx/muiKoG+g9NmxeLz4onjSYCB4NRXVtfd8Db2mXXw9JXmUHN1PSZYr6HTYDRnC2tlCLA5pVpslUb9RZCoi2CWYz3t8jp+D3/Vdfw14p/M7N/0c/yQqxFBUdhTrYtfRwKUBzXwdOHEul4KyQmxcT5Jmt4yByw6gokqrkOS60Gn1WBAWD2Np8e1ezj8eKYZuEZm1PSExlsKETPBHpNeravU4EMCckUT+LzPJXbuRovhiQAHssaKMu9hITnm8cO/y8WoMZGFfNUHkYXw5jG/F8/JYXI29PQVefuxO0uL9NwuC0XcQtR/4jjUnkhm38DDTtF14XLdeFEz8uxhKDYfDojEnufHwY3/o8Rp0mQjbPsJUqqEkW5hn7ToLV9aR+BwAcjTCpRWeGc70fdN5q9NbeEycAMBXR76izFJGs1rNaO3Zukb3tL13e87knmFf8r7qYqhVedzQ4cOoqkodV1v0WoVio5lkp2b4PFqVNbYzWvTVSlA9iVT9aECCqNDcbESN1nBJcuIoOFME2GDfsy8AFotamVrv5WiNotHg+cbrlDo4UzRnFl0TjlwwjQNV2WV5ds44FuaQ89tiao0di8bKSvz/dH8VfntIWIc6jgdb1wvm4ew2ck6Lb4oOvXuzJ8tCTpGRWvZWtKzrwKvLlgAwptmYWyKE7kQ8bT3xtvMmuTCZydsmA6BTrLD1r4XGKg1FY+RIuhjbyqMV0zpOk1YhyTWj1WixaMrbcZRKy9CVkGLoVhHUAPbH4piUBQEa0aKiIBUcqmq3ZL09hrTft6OaK94AFSweOvY5N8Cpdn3uqu9eOTYtv4Slh86h1yo80coJbW48eDUlIq2IzRHp2Bk0PBBkizEqitKYGCwFBdiePkVFGGyOnTNeTRtSsncvuRt2Eb9xPxO2ZKKq8Iu5D4/r1qNGrkXJjgUX/6rrCH0TUIVFwmAngrM3vwuRa+DcIYpSbUEFq+Bg9B4emC0qRxNyUAzppJbGoFW0WFQLf0T/QdNaTRkePJwiY1GlW+CxJo/V+AOgvXd7FkUsYl/yvmrbbZo2BZ0OU1oapqQk9D4+1HWz43RaAfGbdmBe/RtuY57BrkN7tkWnV12auRUNdAniWv4mhmKObad09Wuod02m8V13X3Ft6ultFJa7C+17CumaUViKyaKiUcDdQexTFIW6E8az38ufwgMHCXC3w/a8rC69T20Oatx47WgRmSaF+RunUys7m+zVa3C7t7ywXg2sQ5bwteTGiiJsziPuY+nBRAAGN/NmU0IoWSVZeNh4XFDXSXLjUBSFj7t+zPLTy4nKjiI6O5oScwlam3MA+Nr7MbTeEAYHDpaCVHLd6BQdZg3oLGC6WAkWSTWkGLpF+LbpDIvW45dWhNm5DtrsWGEdKhdDano0Gcu2oZo1GFwUnLq1Iu/uMfT8Kx8bvZa9r/XCyaYqIM5dVRnz4WaScktoO7w1fRt7YbGovPfFdqK0BUzuXw/3LnWx1lmjGo2UnjlLWcxpCm0deXBjOrEmA890DeQRp2/JX7+emPc+pKzDk/QN8eRgnIHtZU3pqj0BB+ZC3/Lu8me2wulQ0Oih3/vgEiAsR6tfhnOie3ZBSTCQVukiO51WQEGpCTtPERPRsXZHWnm04ssjX/L+vvdp4NqAY+nHyCvLo45DHXr61fzDuK1XWzSKhti8WFIKUyqLAmpsbLBu1IiSEycoOnwEJx8fgtztSE9Ixu7DzynMz6Xo6DF8585l12lhGbq/jS8bD7VmvO4v1NMbUUxlIiYHMBblYrv8KYLUVGK2vw81EENF29diMWrQ2lth3aQJUOUic/Y8yIBlM3mr01t08ekCQLsHBsMDgy86Vx+gYe8iXvjtCCv9O/L4ybXsn/ktav0ODGjiJcTj5axDqkr+xs1YjBr0nm4sKPNg9Qnhpr2npQ8fn/gAgBENRly0rpPkxtHCowUtPFoAYLaYSchPYGPMceo6edE7sK20BEluGFqNFrMWMIFZWoauiAygvkV07NoXkwYcSiBOKf/Wd14l6rLFr2Iu1aBoFQK2HqHWhwuId20IQF0322pCCMS3zH5NxIf/ujARCLs1Ko2o1ALsrRRWZ73E4D8Hk1yQjKLXY90gGMeBA/Hu3oXXHxLuq+92nOFA75GYFA2tUk7xkC6Vrx5qyQs96zHfLFw76uGfRSHA85uNtn0SXAOFi6bFQ/DMdvBpg2rrTmGC6HdVUUjvSHw2oGLtLIJGBwQM4MmmT9LDrwdGi5GJWycyP3w+AKNDRqPVVFlFroSjwZEQ1xCAC6xDthWusiPlQdS17HjhyFL0+bmg0aAWFRE/5hkcUhNxsNIxbUhj4qwbkKY6o5Tmiay6ck4vmIC3mirmMUZSknTq8gtTVQr2i+u1b9ccRSNeZhViSON4mNSiVCZumcjRtKM1ulY/V1t+f6YjLcc+ilGjxT89js+/Xs69s3dzMDaryjpUVnBhZlnKCbLDRdB1YucBfLheCKHXBzZCZ3OO4+nH0Wl03Bd8X43WIrkxaDVa/J38earVUPoEtZNCSHJD0SpaKpwMJpMUQ1dCiqFbhKODE+fchKA5lVH+H1qRURa/l6J9olO3TZNGIhYESMwWQW++LlU1XiyqhY1xG8kpyWFAE9E+YeOpVMpMFr7ddgaAPi1LSciPI7UolUlbJ1Fqrp5W2SfEk/vb+KKqMHFXFqsDhDh6ImwVBo3CQ+3rcta5E/EWd5SSHAhbKtxhKcfByhG6/i3VulY9eHoTZXevwpSeiWJlhW1rEfdzJD4HjVUKZZoUDBoDPfx6oFE0vN/lffwd/UkpTCG5MBlXa1furndli8vfqcgqu8BV1lJ0qi86chSAVqd20yklHLNGS91fF2DdvBlKfh7v7/6Ofu4q9lY67m9bl41mIaIqCjBmHllJo6RlAJxRxf1O3TX/8ovKiaMwVogPu35V15RSHi9k1qYBUGIuYdymcZzOPl2ja9VrNTzYtzlOg0SPsHtid3MkPocR3+7h571xwjoEwjpUmCEKdf41jtIvBlOcbgUKTC7yB2BstyCe7hrIoghRQqGff79L1nWSSCT/PrSKFnP5J7xZZpNdESmGbiGp3iKjKDu5PCi2Ioh6w/8oThcuGZuOVZVmq8SQTeW2eeHzmLh1Iu/te4/WdV2oZW9FXomJb7fFsO9sFjqNgpdXVXXrsMwwpu+bfsFa/jc4BB9nMe+uTnej2NljjDhF3qpVGHQaJg9ozC9mEZRs3P2NiAsCESht53bR6yvYIwKkbdu0QWMtSggcSchG5yiivu/yvQuH8mwpB4MDM7vPxEYn1vBAwweuqSv4+WJIPa8Pm0158cXSyEhKoqKovWA2AEubD8K2ZUv85swhzdUb9+JcHv5jBqbsbEZ1qMsmVYg448nVUJiJbtULAKyyvYddfs8A4By97LItTowHVlOaqwcF7LtVuf2Sc0tAU4QJUfyyiVsT8sryeCb0GZIKkmp8zR6jRcHN7knHeLC+PaoK0/4K57O4INQK69DnTWH+YCwHF5CyS3jDozzrkG7tzP1tfJnavwFZJVmsPStE398b4kokkn83iqJgqRBDsjfZFZFi6BZSGhAIgCG5PE06PVK0hkjcT1G6sAbZtm5TOT4xW4imCjFUZi7jl5Mik2t74naMllL6NvYE4LONwvUxtEVtjmeJju8DAgagoPBH9B8si15WbS0O1nrmP9GWsd2C+HZ8L2o9MwaAtM8/x1JaSv8mXkTVHkaxakCfcQpyE8DRFzo8e9FrWxeWzLE/1wNg10XEweSVGIlOy0fvKFxG/QP6Vzumnks9ZvWaxeiQ0Twa8mjNb+R5tPRoiUFjIK04jbN5VdWj9Z4e6H18wGIh4amnUYoKCXf15+c6XcgtNlJsY8/Udk+SZuOMdXIiCWOewcdKxVCvh7jmgnPkzR2GkzmLaNWH+g99hFvru8lTbXEqS63mRvs7BZvFfbAJqIXW2blye2puCRqDiFHysPVgTp851HOuR1pxGs+EPkNWSQ2qSAM2TZtg3bwZGI1MKjvJxN7BAHy5JYZfrB4Sg4xFqHonEsKbUZRuRZHOipmN7qNPiCcf3NMURVFYFr2MMksZjd0a06xWs6u57RKJ5F9AlRiSRRevxFWJoenTp9O2bVscHBzw8PBg2LBhREZWLx5YUlLCuHHjcHNzw97enuHDh5OamlptTHx8PIMGDcLW1hYPDw8mT56MyWSqNmbr1q20atUKKysr6tWrx7x58y5Yz6xZs/D398fa2pr27duzf//+q7mcW06tZqLFgFdauWWoMA3Wv46xUIOxUAsaTaVFAy50k606s4qMYvFhWmwqZn/KfgaUxw1VGEUe6liLsAyRTz+p9STGtRgHwPt73yc8I7zaeup5OPDKgIbUdrbBdfQj6Ly8MCUlkzFnDoU7djCpMIIjuwM4s9ad0ys9OL3ckdMDhnK6dx9iBg4i49vvsBQXk5hdxEu/HsDltJi/qJmwrhxLyEGxSkRjyMJGZ0NXnwtrprT1asvktpOvud2Dtc66MiD1AldZK+EqM6WlodjaMq/baCyKhjPpBeyJySTF2plvBr6A1tmZkhMnSHz+BR5qH8AOS1MAHLOOY1S17GjyPg18PenUwJfVFmGJKjqw4OILUlUKjkQDYH9Xp2q7ks8TQ/6O/jhZOTGn9xy87byJzYvlqQ1PXTKGqNBYyDdHv+HBVQ+yPXE7rg8/DEDOb4t5oXsA7w1rgqLAtMg6/ODxBkfazeSPY/0pOpmBUaPlrfaP49GiCV892BKdVoPJYuL3SNHq48GGD8p4FYnkP4hZiqEac1ViaNu2bYwbN469e/cSGhqK0Wikb9++FBYWVo6ZOHEiK1euZMmSJWzbto2kpCTuvffeyv1ms5lBgwZRVlbG7t27mT9/PvPmzWPatKp04LNnzzJo0CB69OjB0aNHmTBhAk899RTr16+vHLN48WImTZrEm2++yeHDh2nevDn9+vUjLS3teu7HTaVd94EAuOdZyDSU94LKS6QoX6TMWzdqhNbernL8+W4yi2rhp7CfAHC2cgZgS8IWOgS6VQZXdwt2J9tyCotqIdApEC87L55u9jTdfbtTZilj4taJlWLq72isrXEvL+SXOXsOCWOewfDjHFwS8inN1WMs1GFMy8GYmIgxMZGyM2dInzmTmP4DWDn9WxqknMbabCTD2pH716cSnZrPkfgc9OUusu5+3W94f6sKLh031KLyseeUKTgGBgAQk17IjvL6Qg3aNWXt820oNSgU7t5NwHefctSmY+Vx83QjGDl0CADOtgaOuYm/oT5y5YUd5gFLajSFicKFZj/4gWr7UvNK0FiJ89Z1rCvWZefJd32+w9XalejsaB5Z+wgTtkzgbK6wchktRhZHLGbgsoHMPjabsMwwXtj8Alvrl6F1dcWUmkr+ps2M6lCXbx5qhUGr5b34EJbPOUTj4zswo/Br3zHc/dgQ5j/errIZ67aEbSQXJuNi5XKBxU4ikfw3qLAMqWbj7V3Iv4CrEkPr1q3jscceo3HjxjRv3px58+YRHx/PoUMirTo3N5e5c+fy2Wef0bNnT1q3bs1PP/3E7t272btXxJNs2LCBkydPsmDBAlq0aMGAAQN49913mTVrFmXlbQbmzJlDQEAAM2bMoFGjRowfP5777ruPmTNnVq7ls88+4+mnn+bxxx8nJCSEOXPmYGtry48//nij7s0Nx9enDqlO4sMovLgq7qZIIywYtm2qig2WGM1kFAg17+diy7aEbcTmxWKvt+d/HURW17aEbWg18Fgnf+wMWib2CWbXORGIXdG7S6NoeP+u96njUIfkwmR6/t6TQcsGMWnrJGYfm832xO2YLSIDzGnoEGzbtAGNBkNQEI4DB6J7ZjxfdH6AKV3HEvXmF/gv/g3/xb/h/cEH6GvXxpSaSvcV3zFtnxBqp+s0JjmvlPvm7GHFsUR05S6yAf4Dbtp9rRBD+1P2V14LgEPPnuDkgE3/PjiPvL+yR1lMegHby+sLBdTO4QfTVj6+V0HVaclft44OcfkkWtzYaW5Mnbtfx86qqgKFR6OuxFvc0ZuLLtq6o2j9b6hmDTp7LVZNWlRuV1W1mmWoQgwB+Dv5s2TIEobXH45G0bApfhP3/HUPb+x8g3v/upf39r1HVkkWdRzq0N2vO2bVzBv73yauh+j2nvnjXPI3b6ZL+il+DSljTPQGHogSPd50k1/lo89f4Km7ArExiP+9ImMRs4+JGKrhwcOx0laV7ZdIJP8dLOUGX4tRiqErcV0xQ7m5oieUq6uoaXLo0CGMRiO9e/euHNOwYUPq1KnDnj17ANizZw9NmzbF09Ozcky/fv3Iy8sjPDy8csz5c1SMqZijrKyMQ4cOVRuj0Wjo3bt35ZiLUVpaSl5eXrWfW805L9GLKLUio6xWMMXxwrJm07pKDFVYhRysdDja6Cq7uY9oMILuft2x09uRXpxOeEY4E/sEE/Z2P5r7OrEnSVx/hRgCkYL+RY8v8Hf0R0UlPj+e0LhQvjn6DeM2jeO3SFHwUNFqqfPLzzQ8dpSg1avw+WwG9SeOo81jj3DCtR6vnrKQ7lsfm+bNcb73HgLWrGZD15Hk622wsgg3Z79H76aFnzO5xUbO5oeh0edhq7Ons0/nm3ZPG7s1xl5vT35ZPhFZojlrkbGIt05/xchni5jSMxmLaqnsUbYlIo24zCJ0GoUTBX8BcCJAw66n2oKi4L4tlFXxI1jfajZ9m1YvfndXAw+WWUSQu3rswma2Bdu2A2DfzL+a6ymv2ESx0YzGIESYv6N/teM8bD14q9Nb/DHkD7r7CsHzV8xfxObF4mrtyqvtXmX53cv5oscXle1K3vPaj0WjUHLsOInPjSPxuXHYv/sK94RvAMB94kQaPvlItfMYzUYmbJlAZHYkzlbOMnBaIvkPY9aK9yCLtAxdkWsuumixWJgwYQKdO3emSUVRuZQUDAYDzucFjQJ4enqSkpJSOeZ8IVSxv2Lf5cbk5eVRXFxMdnY2ZrP5omMiIi7dDX769Om8/fbbV3+xN5BCPz+IzKY0XYVugzE1G0Pp12MBKtPRoSp42sfFhuMZxzmcdriygaZBa6Bz7c5siNvAloQtNHUXAbGxubEkFSah1+gvaGlRz6UeK+9ZSWZxJlHZUURlR7EveR87zu1gwckFPNjwQTSKRnyA66vXNHqicwChJ1PZdzaLl5Yc5bcxHdFqFLbH5jHTtS3z+jdlicsZ7Irz8RwygIVoeO7Xw+zJXQ5A7zq9bkqzzwp0Gh1tPNuwNXEre5P3oigKU7ZPIS4vDhSFU9kR/BXzF/U8RMxSREo+AE38zWxOCK2cZ5lfCvdN+x8pb79Dt70rcHApI+VIVfd0xWCg0bBhTNN2ZwLL4MwWyE+pKpxZmENBmKgmbNejevFIkVavojVkAtUtQ+dTz6UeX/X6igMpB/j55M80dG3IoyGPYm+oarnyUpuXcLN2Y8ahGfzSQ2HgWRf8HPyolF6KgkP/frg+Wj0o3Wwx89rO19iTvAcbnQ3f9PoGD1uPq7vZEonkX4MqLUM15prF0Lhx4wgLC2Pnzktn1fzTePXVV5k0aVLl87y8PPz8bm3Ze/uQlrDxOO4pefDArxRvFu4MQ2BgZTNPqB48PS9sHgCDAwdXfnh19+vOhrgNbE3cygutRPr3riThImvl2eqS8TluNm50tOlIx9odGRE8gt5Le5NYkMjOczsv2RRSo1H4dERz+n++nQOx2fyw4wxPdglg+lpRfHBEjxDqDRyORbWQkJ9AZFYkrZpHciL8BGUWGBh481xkFbT3bs/WxK0sjFjI10e/xmQx4WnrSWefziyLXsbXR77mh17dqx1j47YLc4GZFu4tOJFxgsSCREqGd6dWZhYZX39N/tp1F5wne/FihnYbwUGX+rTRRov6S+2fxRj6Fec++BZjnoKiVbEb9HC145Jzi1F0eaApQ6to8XHwuez1tPVqS1uvtpfc/1iTx3C1cWWaMo3V7fL4ptc47vK965LjVVXlw/0fsi52HTqNjs97fE5T96aXXYNEIvl3UxkzZJJi6EpckxgaP348q1atYvv27fj6VrYExcvLi7KyMnJycqpZh1JTU/Hy8qoc8/esr4pss/PH/D0DLTU1FUdHR2xsbNBqtWi12ouOqZjjYlhZWWFldXvjI5p06QVfzscn00h2ThZlBw4C1a1CUCWGnByzCY3fBFTv5t7VtytaRUt0djSJ+Yn4Ovhe1EV2OWz1ttxb717mn5zPwoiFl+2Q7edqy5tDGjPlj+PM2BBFWn4pUakFONnoGde9HnNPzOXb499SbKreHdndxp123u1qtJ7roSJuKK1IBND3qtOLtzu9jY3Ohn3J+zhXcI7QxCXYGupSVGYGbSHRReK+PtviWb4+8jUnMk5wMPUgg8c9h1VwfUpPVy+GWHzsGIXbttN940ISvdwxddCg2/8deb//SPKmIixGDRoDeL88Bq1rdatlynnxQr4Ovjek7cXQoKGczDzJr6d+ZVn0ssuKoTnH5vBb5G8oKEy/a3qN/0ckEsm/FxlAXXOuKmZIVVXGjx/Pn3/+yebNmwkICKi2v3Xr1uj1ejZt2lS5LTIykvj4eDp2FBk6HTt25MSJE9WyvkJDQ3F0dCQkJKRyzPlzVIypmMNgMNC6detqYywWC5s2baoc80+lceNW5NkoaFXYu209ReXB5+cHT0OVmyxJXY+KSjffbgQ5B1Xud7JyoqWHSMPfmrAVo9nI/hQhMq/mg25kg5EoKOw6t0u4lS7DiDa+9G7kQZnZwtydItvp+Z71SC6J4YvDX1BsKsZKa0Vjt8bcU+8eXmn3CvP7z78l/a7qOdcj0CkQg8bAG+3fYGb3mThZOWHQGnixlciS+zHsR/w9RKaXk8cBSi0lNHRtSEfvjrTxEvWdDqQcQFEUHPv2xf2556r9+M2Zg+e0/4HBgG9KOmfWuXNuTR7n1pVgMWqwCfIiYMVqHEdPumB9KXkXD56+XobXHw6I/4FLZQquO7uOb459A8Br7V+jv7/MHpNI7gQsmoqYIdMVRkquSgyNGzeOBQsWsHDhQhwcHEhJSSElJYXi4nIrhpMTTz75JJMmTWLLli0cOnSIxx9/nI4dO9KhQwcA+vbtS0hICI888gjHjh1j/fr1vPHGG4wbN67SajN27FjOnDnDlClTiIiI4JtvvuH3339n4sSJlWuZNGkS33//PfPnz+fUqVM8++yzFBYW8vjjj9+oe3NT0Gq1JHiIQN7UvdsoOXkSAJvzii1CuWVIU0JEwRagulWogh5+PQDxQXg0/SjFpmLcrN0Idgmu8Xr8HP0qLQoVneMvhaIoTL+3Ga52Iv7Hz9WGUR3qMOPgDFRU+vn3Y+9De/lt8G+80/kdHm70MH6Ot8YNqSgKiwYtYtOITYxsOLJa8HJ///40cWtCkakIi9N6UIxonXcD4r4qikJbT+GSOpBy4LLncH3oIQKWLCHJ2RtziZa8eFtQwO3Jx6i7fAMG/8CLHissQyJ4+kaKofou9Wnm3gyTamJFzIoL9pssJr488iUATzR5ggcaPnDBGIlE8t+kIpsMKYauyFWJodmzZ5Obm0v37t3x9vau/Fm8eHHlmJkzZzJ48GCGDx9O165d8fLyYtmyqurHWq2WVatWodVq6dixI6NGjWL06NG88847lWMCAgJYvXo1oaGhNG/enBkzZvDDDz/Qr1+/yjEjR47k008/Zdq0abRo0YKjR4+ybt26C4Kq/4lk+4oeV/47DoLJhM7LC71P7WpjErOL0VonYlLL8LH3uSAgGqrE0MHUg6w7K+JbOtbuiEa5uiTBioyiv07/RZHxwto55+PuYMXMkS1o4OnA9HuacTBtL3uT96LT6JjQagI6zTWHoV03tnpbnK2dL9iuKAqT2ghrTbJlGz4BWzGSh7edN339RUPalh4t0SpaEgsSSS5Ivux5rBsEs33Sx/wV2IUsnwDq/PQTHpOnougvbQE73zL090yy66XCOrQselm1liQgCnUm5Cfgau3KM82euaHnlUgk/2zU8mwyVYqhK3JVn1x/f6O9GNbW1syaNYtZs2ZdckzdunVZs2bNZefp3r07R44cueyY8ePHM378+Cuu6Z+GLjgEdkXjmSFS6m1bt65myaioMaR3Ff2qQtxCLloh2M/RjyCnIGJyY/gj+g/g6lxkFXSq3Ym6jnWJy4tj1ZlV3N/g/suO7xbsTrdgd8wWM/etnAEIQeXr4HvZ424nbb3a0t23O1sTt5JnJdyrj4Q8UunCszfYE+IWUhk3NMR+yGXn69zYlzHNhrG+lh1byq2elyMltwSN7Y13k4GwfH20/yPi8uI4mHqwMvDaZDHx3fHvAHi88eM3reilRCL5Z1JhGVLN5ssPlMjeZLeDoPbdqj23bXsRFxlgbScsFCFuIZecq7tfdwDMqvhn71j76mOmNIqGBxoI98miiEU1Er0AK2JWcDrnNA4Gh3+F1WFi64loFVF40NHgWGlRqeD8uKEr0THIDa1G4WxGIQv2xpFfcvkAxaTcQhSD6D12o8WQrd6WAQEiY+/8HnTnW4WuJHAlEsl/D0u5ZQgphq6IFEO3gfYde1J6nk3uwkwy4arS2YiaNY1cG11yrgoxBNDApQG1bGpd05qG1huKjc6G0zmnOZh68Irji03FfH3kawDGNB2Dk5XTNZ33VhLoHMiI4BEAjGo06gJLSU3ihipwsNbTMVCUQnhjeRht3tvI+IWH2RyRitFcvaN9cZmZfFMaimLBWmt9U2r73Bd8HwChcaHkluZKq5BEIkHVVLjJpBi6ElIM3QasrKxIcLcGoNTOBkNQULX9FcHTJq3IuGvkdmkx1LRWU1ytRQXw/7d373FRlYn/wD9n7oDcBQYUFG+gpOZlJTIvrSiauVFurWaJhVqtlpe+pm43tUzTtbK0rN+uWptaulu2oVmIIqV4Q9G84Q1TS8QUGEFuM/P8/hjm6Cx3HRw8fN7f13nBnPPMmecc9ut8ep7nPM+tPC7tpfPCsDa2rqE1xyrPrPy//nXkX8gtzkWIRwhGdrxzZjGe3ms6Vg5eifFdxlc6Vp9xQwDw/shumBYXgXaBzVBqtiLp4AU8vXIvRnyyExbr9da1nP9Zk6y+Y7rqIso/Ch18O6DUUooNpzewVYiIYK0YXiFxzFCtGIZc5FKIrQUnO9QHksrxz3A+rxhqve3L2OhhlMNOVdQqNRKiEtDcrTkeavfQLdXJPpB6y9ktyCnKqbbc5eLLWH7ItgbcC91fuKPWttKoNOgR1ANqlbrSMfu4IQB1ah3z89Bhwv3tkDylL/47sTfG3Nsa7jo1Mn7JQ8rR63NgNdSTZDeSJEnu9vv3iX+zVYiI5JYhWOs29KEpYxhykSuDBuJ4CLCue+U/wfm8a1AZau8is3v6rqex9bGtDvMQ3Yx2vu3Qy9gLFmHB2qy11ZZbfmg5isqL0Mm/kzxWRSnqM27ITpIkdGnpg1l/isLomNYAgM/Sr8/ZlGMqbpA5hv7X0DZDoVfrcSLvBFuFiOiGMMRustowDLnIoLjH8EqCBgfDcnG+4IrDMdtj9RVhqIYusoZgbx369/F/o9RSWum4qcyEfx//NwBg4t0TG6TLx5WqGzd0uuA03t79Nnb8uqPG94+KDoNKAn46+TtO5trWQLtxtfrW3q2dX+kK3npvDGw1UH7NViGips3+aD2s1poLEsOQq3QxtobaHAhJElj7c6rDsfN5xVAZbI/VR/lH3dZ69Q/tD6OHEXmlefjhzA+Vjq/NWotr5mto79se97W477bW7Xb433FDQgh8feJrjEgagc+Pfo5nNj+D8T+Mx9HLR6t8f6ifOwZ0tM119a+K1qGLBQ0z+3RV7APE2SpERMI+BIMDqGvFMORCoe5dAABp56+3NpSUW/B70VWo9BWDp+vQTeZMGpUGf4n4CwBg9dHVDsfKLGVYdXQVgOszNyvNjeOGtp7bipfSXsJrO15DsbkYHXw7QKPSIP1COv6S9BfM/HEmfiv8rdI5xtzbGgDw74zzuFpSjvP5BVBpCwA4f8LF/9U9qDuWxS7DisEr2CpE1MRxzFDdMQy5UJ8WtjmBzhQdkPfZWoUuQJIEmrs1R4B7wG2v1yPtH4FWpcWhy4fw86Wf5f1Jp5Pwe/HvCHQPxJDWyhordCP7uKF5u+dh05lNUEtqTOo+CWsfXItv47/FA+EPQEAg6XQS4r+Jx6n8Uw7vv7etP9oGeKCozIKv9v2K80XnAADuGq/bMgVB7xa90ca76mVBiKjpEOqKr3h2k9WKYciFRnS5H0JIsGhycOSi7QvzfN41qA3XZ552BT+Dnzww2v6YvVVYsfLwSgDAkx2fhFbd8Iuvuop93BAAtGjWAp8O+RRjO4+FWqVGS8+WeLvv2/jiwS/Q0a8jis3FcmuZnSRJSKhoHfo0/QwulZy3ncsj7LZdAxGRvWVIYhiqFcOQC4X5BEBvtS1hsfawbUFWW8tQ3Z8kayiPRz4OANh0ZhMuF19G2vk0ZBdko5m2mTzBn1JFB0ejb8u+GN5+ONYNW4euAV0rlYnyj8L/9fw/AMDG7I2V1nR7pHtLNNNrcPpSEQottmkS2jTg4GkiokrsU4iwm6xWDEMu1rZZNwDAzt92AnDtk2Q3imoehS7Nu6DcWo7/nPgPVhxaAQB4NOJRNNM1c1m9bgedWoelA5Zi1r2z4KnzrLZcT2NPhHqGoqi8CN+f+d7hWDO9Bn/uYQu69sHTEX7suiKi28feTcaWodoxDLnY/a17AwB+K/sZVqsVZ6/kQ6W3TdjXyc813WR2IyJt65UtP7Qc+3L3QaPS4ImOT7i0To2JSlLhkfaPAHBcE8zuiXtsT47Jj9X7tL5tdSMigsoehtgyVBuGIRd77K4+EEINoc7HznNZOG06DUmywkPjDaOH0aV1i2sdBz+DH4rKiwAAQ8OHNsi6Wneyh9o+BLWkRualTJzMO+lwrF1gM/Rp3/y2PVZPROTAPoC6jotvN2UMQy7m7+4JD2HrPvnqaCoulti+UNt6Rbj80XWdWucwPmhM1BjXVaaRCnAPQL+W/QAAX52s3DqUcF8AJI1tPFGYJwdQE9FtpLaNGWLLUO0YhhqBSG/bqvW7c3bjmmSbqK9L4O2dbLE6IyNHop1PO4yIGIF2vu1cXZ1GaXgH25pg3576FmWWModjzX1NAIBgj2AYNIbbXjciaroEw1CdMQw1AoPb2mZyvmI5Ig+evjuocYSh5m7N8fVDX+Ple152dVUard4hvRHoHoj80nxsObtF3l9iLsE/f/4ngIafbJGIqBJ7GGIWqhXDUCPwUKd7IKx6SJprULvZwpCr5hii+lOr1Hi43cMAbCvGA7Y13J5Jfgap51OhU+nwdOenXVlFImqK7GHIwjRUG4ahRsBdq4eP1EF+rYY7WjZr6cIaUX093P5hSJCw68Iu7Lu4D2M2jcG+3H3w1Hri44Ef457ge1xdRSJqajT2liGGodowDDUSXfyvz3rspwl3+eBpqp8WzVogJsS2vMpT3z+FE3knEOAWgBWDV8jLexAR3U4qtQYAIHGaoVoxDDUSD3boK/8e6tHehTWhmzW8vW0gtVVY0cqrFT4b8hki/CJcXCsiaqokjT0MsWWoNgxDjcSgdncDFg8AQKQLl+Ggm3d/6P3oGdQTvYy98OngT9HSk12dROQ6kr1liFmoVhpXV4BsNGo1Hm71LH769Uc894c/ubo6dBO0ai1WDF7h6moQEQEAJI1tQW12k9WOYagRmTNgDIAxLq4FEREpgRyGOIC6VuwmIyIiUiCV1haGVGwZqhXDEBERkQKp2E1WZwxDRERECiRpdQDYMlQXDENEREQKpK4IQ3yarHYMQ0RERAqk0nLSxbpiGCIiIlIgjVYPgN1kdcEwREREpEBqnQGArZvMarG4uDaNG8MQERGRAtnDkMoKWCzlLq5N41bvMJSWloZhw4YhJCQEkiRh/fr1DsclSapyW7hwoVymdevWlY7Pnz/f4TwHDx5Enz59YDAYEBoaigULFlSqy7p16xAZGQmDwYDOnTtj48aN9b0cIiIiRdLorz9NZjEzDNWk3mGoqKgIXbt2xdKlS6s8fuHCBYdt+fLlkCQJw4cPdyg3Z84ch3LPP/+8fMxkMmHQoEFo1aoVMjIysHDhQsyaNQuffPKJXGbHjh0YOXIkEhMTsX//fsTHxyM+Ph6HDh2q7yUREREpjuaGlqHycoahmtR7OY4hQ4ZgyJAh1R43Go0Or7/55hvcf//9aNOmjcN+T0/PSmXtVq1ahbKyMixfvhw6nQ5RUVHIzMzEO++8g/HjxwMAFi9ejMGDB2PatGkAgDfeeAPJyclYsmQJli1bVuV5S0tLUVpaKr82mUy1XzAREdEdSKt3A2ALQ1a2DNWoQccMXbx4ERs2bEBiYmKlY/Pnz4e/vz+6deuGhQsXwmw2y8fS09PRt29f6HQ6eV9cXByysrKQl5cnl4mNjXU4Z1xcHNLT06utz7x58+Dt7S1voaGht3qJREREjZLW/jSZAMzmMhfXpnFr0DD06aefwtPTE4888ojD/hdeeAFffPEFtm7dimeeeQZvvfUWXnrpJfl4Tk4OgoKCHN5jf52Tk1NjGfvxqsycORMFBQXydu7cuVu6PiIiosZKrbv+aL31hgYHqqxBV61fvnw5Ro0aBYPB4LB/6tSp8u9dunSBTqfDM888g3nz5kGv1zdYffR6fYOen4iIqLFQVyzUqrZKKC8vraV009ZgLUM//vgjsrKyMHbs2FrLRkdHw2w248yZMwBs444uXrzoUMb+2j7OqLoy1Y1DIiIiakrsky4CgLWc3WQ1abAw9M9//hM9evRA165day2bmZkJlUqFwMBAAEBMTAzS0tIcRr8nJycjIiICvr6+cpmUlBSH8yQnJyMmJsaJV0FERHRnUmmvj7u1lLFlqCb1DkOFhYXIzMxEZmYmACA7OxuZmZk4e/asXMZkMmHdunVVtgqlp6fjvffew4EDB3D69GmsWrUKU6ZMwRNPPCEHnccffxw6nQ6JiYk4fPgwvvzySyxevNihe23SpEnYtGkTFi1ahGPHjmHWrFnYu3cvJk6cWN9LIiIiUhyVRiv/bi0pcWFN7gCinrZu3SoAVNoSEhLkMh9//LFwc3MT+fn5ld6fkZEhoqOjhbe3tzAYDKJjx47irbfeEiUlJQ7lDhw4IO677z6h1+tFixYtxPz58yuda+3ataJDhw5Cp9OJqKgosWHDhnpdS0FBgQAgCgoK6vU+IiKixu5k7jFxJCJSHImIFCd2JLu6Ok7l7O9vSQghXJjFXMpkMsHb2xsFBQXw8vJydXWIiIic5kx+NorveQAAoP54ETr0e8DFNXIeZ39/c20yIiIiBdKotbAvWG8tZzdZTRiGiIiIFEij0sBa8S0v+DRZjRiGiIiIFEgtqWGp+Jbn02Q1YxgiIiJSILVKDYva9jvDUM0YhoiIiBRILalhkWy/WzgDdY0YhoiIiBRIo9LI3WTWMg6grgnDEBERkQKpJbU8gNrCAdQ1YhgiIiJSILXqhgHU7CarEcMQERGRAt34NJkws2WoJgxDRERECqSSVOwmqyOGISIiIoWSu8nM5a6tSCPHMERERKRQ8gzUFoahmjAMERERKZRVZZtoyMoxQzViGCIiIlIoa8Wki4LdZDViGCIiIlKo691kZtdWpJFjGCIiIlIohqG6YRgiIiJSKPuYIYahmjEMERERKZTcMmRmGKoJwxAREZFCyS1DVouLa9K4MQwREREplGAYqhOGISIiIoWyd5NJHDNUI4YhIiIihbK3DMHClqGaMAwREREplH3MEKxW11akkWMYIiIiUih5zJCFYagmDENEREQKJdgyVCcMQ0RERAplVVV8zfNpshoxDBERESmUUNtbhoRrK9LIMQwREREpVUXLkMRushoxDBERESmU/DQZB1DXiGGIiIhIqdQVLUOCYagmDENERERKJQ+g5pihmtQ7DKWlpWHYsGEICQmBJElYv369w/ExY8ZAkiSHbfDgwQ5lrly5glGjRsHLyws+Pj5ITExEYWGhQ5mDBw+iT58+MBgMCA0NxYIFCyrVZd26dYiMjITBYEDnzp2xcePG+l4OERGRYgl7yxDDUI3qHYaKiorQtWtXLF26tNoygwcPxoULF+RtzZo1DsdHjRqFw4cPIzk5GUlJSUhLS8P48ePl4yaTCYMGDUKrVq2QkZGBhQsXYtasWfjkk0/kMjt27MDIkSORmJiI/fv3Iz4+HvHx8Th06FB9L4mIiEiRhL1lSDAM1URT3zcMGTIEQ4YMqbGMXq+H0Wis8tjRo0exadMm7NmzBz179gQAfPDBB3jggQfw97//HSEhIVi1ahXKysqwfPly6HQ6REVFITMzE++8844cmhYvXozBgwdj2rRpAIA33ngDycnJWLJkCZYtW1bfyyIiIlIeje1rni1DNWuQMUOpqakIDAxEREQEnnvuOVy+fFk+lp6eDh8fHzkIAUBsbCxUKhV27doll+nbty90Op1cJi4uDllZWcjLy5PLxMbGOnxuXFwc0tPTq61XaWkpTCaTw0ZERKRY7CarE6eHocGDB+Ozzz5DSkoK3n77bWzbtg1DhgyBpWLF3JycHAQGBjq8R6PRwM/PDzk5OXKZoKAghzL217WVsR+vyrx58+Dt7S1voaGht3axREREjZlabfvJLFSjeneT1WbEiBHy7507d0aXLl3Qtm1bpKamYsCAAc7+uHqZOXMmpk6dKr82mUwMREREpFwqWxhSWZiGatLgj9a3adMGzZs3x8mTJwEARqMRubm5DmXMZjOuXLkijzMyGo24ePGiQxn769rKVDdWCbCNZfLy8nLYiIiIFEtjbxliGKpJg4eh8+fP4/LlywgODgYAxMTEID8/HxkZGXKZLVu2wGq1Ijo6Wi6TlpaG8vJyuUxycjIiIiLg6+srl0lJSXH4rOTkZMTExDT0JREREd0RJHkAtYsr0sjVOwwVFhYiMzMTmZmZAIDs7GxkZmbi7NmzKCwsxLRp07Bz506cOXMGKSkpeOihh9CuXTvExcUBADp27IjBgwdj3Lhx2L17N7Zv346JEydixIgRCAkJAQA8/vjj0Ol0SExMxOHDh/Hll19i8eLFDl1ckyZNwqZNm7Bo0SIcO3YMs2bNwt69ezFx4kQn3BYiIqI7n6SuCENsGKqZqKetW7cK2IZiOWwJCQni2rVrYtCgQSIgIEBotVrRqlUrMW7cOJGTk+NwjsuXL4uRI0eKZs2aCS8vL/HUU0+Jq1evOpQ5cOCAuO+++4RerxctWrQQ8+fPr1SXtWvXig4dOgidTieioqLEhg0b6nUtBQUFAoAoKCio720gIiJq9P755khxJCJSbPljhKur4lTO/v6WhGi6HYkmkwne3t4oKCjg+CEiIlKcFW+Pxj0r9uBiiED/LcdcXR2ncfb3N9cmIyIiUiiVxjZfH8cM1YxhiIiISKEkLccM1QXDEBERkUKpNFrbT7YM1YhhiIiISKHYTVY3DENEREQKpdIyDNUFwxAREZFCqbW2bjJJAMLKRFQdhiEiIiKFUuv0AGwtQxZzeS2lmy6GISIiIoVS6WzdZCorYGYYqhbDEBERkUJpdQYAtm4yhqHqMQwREREplKaim0xlBazlDEPVYRgiIiJSKHVFy5Ctm6zMxbVpvBiGiIiIFEpzw6P1VovZxbVpvBiGiIiIFEqlvT4DNccMVY9hiIiISKHU9uU4BGBlGKoWwxAREZFC2WegVlslmMtLXVybxothiIiISKHUFWuTAXyarCYMQ0RERAplX7UeAMxlbBmqDsMQERGRQtmfJgMAUVrswpo0bgxDRERECnVjN5mFLUPVYhgiIiJSKPuq9QAgyjnpYnUYhoiIiBRKrdbCWvG7tYxhqDoMQ0RERAqlUWlgrfimZ8tQ9RiGiIiIFEotqWFW2363cp6hajEMERERKZRapb6hZYjzDFWHYYiIiEihNJIGFsn2u5XdZNViGCIiIlIotUoNi/2bngOoq8UwREREpFBq6Xo3GccMVY9hiIiISKE0Ko3cMiTMbBmqDsMQERGRQqml691kFjMHUFeHYYiIiEihVJKK3WR1wDBERESkUBqVBmZ7GLKwZag6DENEREQKdeMAasFusmrVOwylpaVh2LBhCAkJgSRJWL9+vXysvLwc06dPR+fOneHh4YGQkBCMHj0av/32m8M5WrduDUmSHLb58+c7lDl48CD69OkDg8GA0NBQLFiwoFJd1q1bh8jISBgMBnTu3BkbN26s7+UQEREplkpSyWOGrAxD1ap3GCoqKkLXrl2xdOnSSseuXbuGffv24dVXX8W+ffvw1VdfISsrC3/6058qlZ0zZw4uXLggb88//7x8zGQyYdCgQWjVqhUyMjKwcOFCzJo1C5988olcZseOHRg5ciQSExOxf/9+xMfHIz4+HocOHarvJRERESmSJEnXxwyxm6xamvq+YciQIRgyZEiVx7y9vZGcnOywb8mSJejVqxfOnj2LsLAweb+npyeMRmOV51m1ahXKysqwfPly6HQ6REVFITMzE++88w7Gjx8PAFi8eDEGDx6MadOmAQDeeOMNJCcnY8mSJVi2bFl9L4uIiEiRrCoJgGA3WQ0afMxQQUEBJEmCj4+Pw/758+fD398f3bp1w8KFC2E2m+Vj6enp6Nu3L3Q6nbwvLi4OWVlZyMvLk8vExsY6nDMuLg7p6enV1qW0tBQmk8lhIyIiUjJrxXIcwmJxbUUasXq3DNVHSUkJpk+fjpEjR8LLy0ve/8ILL6B79+7w8/PDjh07MHPmTFy4cAHvvPMOACAnJwfh4eEO5woKCpKP+fr6IicnR953Y5mcnJxq6zNv3jzMnj3bWZdHRETU6MkDqNlNVq0GC0Pl5eV47LHHIITARx995HBs6tSp8u9dunSBTqfDM888g3nz5kGv1zdUlTBz5kyHzzaZTAgNDW2wzyMiInI1q7qim8zKlqHqNEgYsgehX375BVu2bHFoFapKdHQ0zGYzzpw5g4iICBiNRly8eNGhjP21fZxRdWWqG4cEAHq9vkHDFhERUWPDbrLaOX3MkD0InThxAps3b4a/v3+t78nMzIRKpUJgYCAAICYmBmlpaSgvv96kl5ycjIiICPj6+splUlJSHM6TnJyMmJgYJ14NERHRnc02gBqA1VxzwSas3i1DhYWFOHnypPw6OzsbmZmZ8PPzQ3BwMP785z9j3759SEpKgsVikcfw+Pn5QafTIT09Hbt27cL9998PT09PpKenY8qUKXjiiSfkoPP4449j9uzZSExMxPTp03Ho0CEsXrwY7777rvy5kyZNQr9+/bBo0SIMHToUX3zxBfbu3evw+D0REVFTJ4chM1uGqiXqaevWrQJApS0hIUFkZ2dXeQyA2Lp1qxBCiIyMDBEdHS28vb2FwWAQHTt2FG+99ZYoKSlx+JwDBw6I++67T+j1etGiRQsxf/78SnVZu3at6NChg9DpdCIqKkps2LChXtdSUFAgAIiCgoL63gYiIqI7wmfxd4kjEZHih7F9XV0Vp3H297ckhBAuSWGNgMlkgre3NwoKCmod10RERHQn+nR4F/Q6XI5zvZtj0D9/dHV1nMLZ399cm4yIiEjBhDxmiN1k1WEYIiIiUjA5DFmsrq1II8YwREREpGBWtX3WRYah6jAMERERKdj1bjKGoeowDBERESmYPQxJDEPVYhgiIiJSMGHvJrM22YfHa8UwREREpGQqexhiy1B1GIaIiIgUTFSEIYktQ9ViGCIiIlIwezcZw1D1GIaIiIiUTH60nmGoOgxDRERECsYB1LVjGCIiIlIwoVYDYDdZTRiGiIiIFEyqCENgFqoWwxAREZGSsWWoVgxDRERESmYPQ8xC1WIYIiIiUjBJo7H9ZMtQtRiGiIiIlExtC0PgBNTVYhgiIiJSMJW9ZYjzDFWLYYiIiEjJ5G4yF9ejEWMYIiIiUjB5zBAbhqrFMERERKRgKq0WAFuGasIwREREpGAqjQ4Aw1BNGIaIiIgUTNJe7yYTViaiqjAMERERKZj6hpYhq9Xi4to0TgxDRERECqbWXR8zZDaXubg2jRPDEBERkYKpdAYAgCQkmMsYhqrCMERERKRgaq0eQEXLkMXs4to0TgxDRERECqbRVowZEoDVXO7i2jRODENEREQKptbbwpDKAlgYhqqkcXUFGjur1Yoy9rE6lU6ng0rFHE5EdDuo1RUDqAVgKef3WVUYhmpQVlaG7OxsWDkvg1OpVCqEh4dDp9O5uipERIpnn4FaZQUsHDNUJYahagghcOHCBajVaoSGhrIlw0msVit+++03XLhwAWFhYZAkydVVIiJSNJX6+kKt7CarWr2/4dPS0jBs2DCEhIRAkiSsX7/e4bgQAq+99hqCg4Ph5uaG2NhYnDhxwqHMlStXMGrUKHh5ecHHxweJiYkoLCx0KHPw4EH06dMHBoMBoaGhWLBgQaW6rFu3DpGRkTAYDOjcuTM2btxY38upltlsxrVr1xAQEAB3d3cYDAZuTtjc3d0REBCAa9euwWzmf6EQETU0uWVIAFYLw1BV6h2GioqK0LVrVyxdurTK4wsWLMD777+PZcuWYdeuXfDw8EBcXBxKSkrkMqNGjcLhw4eRnJyMpKQkpKWlYfz48fJxk8mEQYMGoVWrVsjIyMDChQsxa9YsfPLJJ3KZHTt2YOTIkUhMTMT+/fsRHx+P+Ph4HDp0qL6XVCWLxTZLJ7tynM9+T+33mIiIGo790Xq1VYKZY4aqJm4BAPH111/Lr61WqzAajWLhwoXyvvz8fKHX68WaNWuEEEIcOXJEABB79uyRy3z33XdCkiTx66+/CiGE+PDDD4Wvr68oLS2Vy0yfPl1ERETIrx977DExdOhQh/pER0eLZ555ps71LygoEABEQUFBpWPFxcXiyJEjori4uM7no7rhvSUiun22/vytOBIRKY5ERIrjGamuro5T1PT9fTOcOhAmOzsbOTk5iI2Nlfd5e3sjOjoa6enpAID09HT4+PigZ8+ecpnY2FioVCrs2rVLLtO3b1+HVpm4uDhkZWUhLy9PLnPj59jL2D+nKqWlpTCZTA4bERGRkqkruskAwFpW6sKaNF5ODUM5OTkAgKCgIIf9QUFB8rGcnBwEBgY6HNdoNPDz83MoU9U5bvyM6srYj1dl3rx58Pb2lrfQ0ND6XiIREdEdRaVhGKpNk3pEaubMmSgoKJC3c+fOubpKREREDUqtvd7LIhiGquTUMGQ0GgEAFy9edNh/8eJF+ZjRaERubq7DcbPZjCtXrjiUqeocN35GdWXsx6ui1+vh5eXlsCnVuXPn8PTTTyMkJAQ6nQ6tWrXCpEmTcPnyZVdXjYiIbiO1Q8sQB1BXxalhKDw8HEajESkpKfI+k8mEXbt2ISYmBgAQExOD/Px8ZGRkyGW2bNkCq9WK6OhouUxaWhrKy68/ApicnIyIiAj4+vrKZW78HHsZ++c0ZadPn0bPnj1x4sQJrFmzBidPnsSyZcuQkpKCmJgYXLlyxdVVJCKi20Sj0cE+dbC1nC1DVal3GCosLERmZiYyMzMB2AZNZ2Zm4uzZs5AkCZMnT8abb76J//73v/j5558xevRohISEID4+HgDQsWNHDB48GOPGjcPu3buxfft2TJw4ESNGjEBISAgA4PHHH4dOp0NiYiIOHz6ML7/8EosXL8bUqVPlekyaNAmbNm3CokWLcOzYMcyaNQt79+7FxIkTb/2uVEEIgWtlZpdsQoh61XXChAnQ6XT44Ycf0K9fP4SFhWHIkCHYvHkzfv31V7z88ssAgNatW+ONN97AyJEj4eHhgRYtWlSaMiE/Px9jx45FQEAAvLy88Mc//hEHDhyQj8+aNQt33303/vWvf6F169bw9vbGiBEjcPXq1Vu/6UREdMvUkhoWte13Uc55hqpS7xmo9+7di/vvv19+bQ8oCQkJWLlyJV566SUUFRVh/PjxyM/Px3333YdNmzbBYDDI71m1ahUmTpyIAQMGQKVSYfjw4Xj//ffl497e3vjhhx8wYcIE9OjRA82bN8drr73mMBfRvffei9WrV+OVV17B3/72N7Rv3x7r16/HXXfddVM3ojbF5RZ0eu37Bjl3bY7MiYO7rm5/qitXruD777/H3Llz4ebm5nDMaDRi1KhR+PLLL/Hhhx8CABYuXIi//e1vmD17Nr7//ntMmjQJHTp0wMCBAwEAjz76KNzc3PDdd9/B29sbH3/8MQYMGIDjx4/Dz88PAHDq1CmsX78eSUlJyMvLw2OPPYb58+dj7ty5TrwLRER0M9QqNcpUgNYCCLYMVaneYah///41tlRIkoQ5c+Zgzpw51Zbx8/PD6tWra/ycLl264Mcff6yxzKOPPopHH3205go3MSdOnIAQAh07dqzyeMeOHZGXl4dLly4BAHr37o0ZM2YAADp06IDt27fj3XffxcCBA/HTTz9h9+7dyM3NhV5vm7Tr73//O9avX49///vfcji1Wq1YuXIlPD09AQBPPvkkUlJSGIaIiBoBjaRBSUU/EFuGqsa1yerITavGkTlxLvvs+qpr19r/jrGKiYnBe++9BwA4cOAACgsL4e/v71CmuLgYp06dkl+3bt1aDkIAEBwcXGmQPBERuYZaUsNSsQyk4NpkVWIYqiNJkurcVeVK7dq1gyRJOHr0KB5++OFKx48ePQpfX18EBATUeq7CwkIEBwcjNTW10jEfHx/5d+0NE3oBtntltVpBRESup1apYZFbhthNVpXG/+1O9eLv74+BAwfiww8/xJQpUxzGDeXk5GDVqlUYPXq0vFr8zp07Hd6/c+dOuYute/fuyMnJgUajQevWrW/bNRARkfNoJA2s9sel2E1WpSY16WJTsWTJEpSWliIuLg5paWk4d+4cNm3ahIEDB6JFixYOY3m2b9+OBQsW4Pjx41i6dCnWrVuHSZMmAbAtkxITE4P4+Hj88MMPOHPmDHbs2IGXX34Ze/fuddXlERFRPTi0DLGbrEoMQwrUvn177N27F23atMFjjz2Gtm3bYvz48bj//vuRnp4uPwUGAC+++CL27t2Lbt264c0338Q777yDuDjb2ChJkrBx40b07dsXTz31FDp06IARI0bgl19+qbQUChERNU4qSSWHITAMVUkS9Z3ERkFMJhO8vb1RUFBQaTbqkpISZGdnIzw83GFaACVp3bo1Jk+ejMmTJ9/Wz20K95aIqLH4vfh3ZA7ogxZXgKIxg9BzxmJXV+mW1fT9fTPYMkRERKRgaunGAdRcjqMqDENEREQKplap5QHUVgu7yarCp8masDNnzri6CkRE1MA0kkZuGWIYqhpbhoiIiBTM8Wkys2sr00gxDBERESmYWrreTSYsHDNUFYYhIiIiBbtxALXVYnFtZRophiEiIiIFkyQJ1opVBwTHDFWJYYiIiEjhLPb1vq1sGaoKwxAREZHCCblliGGoKgxDTdDKlSsdVp2vizFjxiA+Pr5B6kNERA1LXqiVYahKDEMKU11oSU1NhSRJyM/Px1/+8hccP3789leOiIhcwlrRTSYsfLS+Kpx0sQlyc3ODm5ubq6tBRES3iX0ANccMVY0tQ3UlBFBW5JrNyWvpVtVN9uabbyIwMBCenp4YO3YsZsyYgbvvvrvSe//+978jODgY/v7+mDBhAsrL+WQCEVFjJ1T2MGR1bUUaKbYM1VX5NeCtENd89t9+A3QeDXb6VatWYe7cufjwww/Ru3dvfPHFF1i0aBHCw8Mdym3duhXBwcHYunUrTp48ib/85S+4++67MW7cuAarGxER3Torw1CNGIYUKCkpCc2aNXPYZ6lh0NwHH3yAxMREPPXUUwCA1157DT/88AMKCwsdyvn6+mLJkiVQq9WIjIzE0KFDkZKSwjBERNTIWdUVT5MxDFWJYaiutO62FhpXfXY93H///fjoo48c9u3atQtPPPFEleWzsrLw17/+1WFfr169sGXLFod9UVFRUKvV8uvg4GD8/PPP9aobERHdfuwmqxnDUF1JUoN2VTmTh4cH2rVr57Dv/Pnzt3xerVbr8FqSJFj5/1hERI2eUNnX4+C/2VXhAGpCREQE9uzZ47Dvf18TEdGdy95NBsEwVBW2DBGef/55jBs3Dj179sS9996LL7/8EgcPHkSbNm1cXTUiInIGezeZhWGoKgxDhFGjRuH06dP4v//7P5SUlOCxxx7DmDFjsHv3bldXjYiInMDeTSY5eaoWpZCEaLp3xmQywdvbGwUFBfDy8nI4VlJSguzsbISHh8NgMLiohq4zcOBAGI1G/Otf/3L6uZv6vSUiut2WjrsHf/yxALmdNOj31Z3/4EtN3983gy1DhGvXrmHZsmWIi4uDWq3GmjVrsHnzZiQnJ7u6akRE5Axq+wDqJtv+USOGIYIkSdi4cSPmzp2LkpISRERE4D//+Q9iY2NdXTUiInICYQ9DHEBdJYYhgpubGzZv3uzqahARUQOxhyGJWahKfLSeiIhI4a63DLGbrCpOD0OtW7eGJEmVtgkTJgAA+vfvX+nYs88+63COs2fPYujQoXB3d0dgYCCmTZsGs9nsUCY1NRXdu3eHXq9Hu3btsHLlSmdfChERkTJUrB4gccxQlZzeTbZnzx6HdbAOHTqEgQMH4tFHH5X3jRs3DnPmzJFfu7tfX27CYrFg6NChMBqN2LFjBy5cuIDRo0dDq9XirbfeAgBkZ2dj6NChePbZZ7Fq1SqkpKRg7NixCA4ORlxcnLMviYiI6M6mrvi6v4luMiEEfi8sw6lLhbYttwi/XC5CidkCqxWwCAFrRcgyaNUwaFUVP22/TxsUCW93bS2f4lpOD0MBAQEOr+fPn4+2bduiX79+8j53d3cYjcYq3//DDz/gyJEj2Lx5M4KCgnD33XfjjTfewPTp0zFr1izodDosW7YM4eHhWLRoEQCgY8eO+Omnn/Duu+8yDBEREf0PqaJlSC0sOPf+EFgtZlisFlitVpSoPFCs9kSx2hMlak+YVF44Z/HHyXI/ZBX74Pw1FUrKb36w0aQBHZx1GQ2mQQdQl5WV4fPPP8fUqVMhSZK8f9WqVfj8889hNBoxbNgwvPrqq3LrUHp6Ojp37oygoCC5fFxcHJ577jkcPnwY3bp1Q3p6eqUnneLi4jB58uQa61NaWorS0lL5tclkcsJVEhERNW6STm/7aQVCr+yo13vzVM1wVe8GrQrQqQCtCtCoAEmlhpBUEJIGQlJDSGpYIUEAsAgJVkiwCsDT+gcAgc6/KCdq0DC0fv165OfnY8yYMfK+xx9/HK1atUJISAgOHjyI6dOnIysrC1999RUAICcnxyEIAZBf5+Tk1FjGZDKhuLgYbm5uVdZn3rx5mD17trMuj4iI6I6gr2hwKFD54fPgsdBrNdDrNDBo1dBZiqAvL4C+/Cr0ZhPczXnwKctBs+IL0Jab4CsVwheFsKWciq0+1M6+Gudr0DD0z3/+E0OGDEFISIi8b/z48fLvnTt3RnBwMAYMGIBTp06hbdu2DVkdzJw5E1OnTpVfm0wmhIaGNuhn3m5jxoxBfn4+1q9f7+qqEBFRIyFpbGN2vD19MPiZ6XV/Y4kJKDgHlF0DJBUgSdd/CitgtQJWs20TFtvTasIKoOKnAGDwbpBrcqYGC0O//PILNm/eLLf4VCc6OhoAcPLkSbRt2xZGo7HSmlgXL14EAHmckdFolPfdWMbLy6vaViEA0Ov10Ov19b4WIiKiO5qm4mkySz2bdQxegCGqASrUuDTYPEMrVqxAYGAghg4dWmO5zMxMAEBwcDAAICYmBj///DNyc3PlMsnJyfDy8kKnTp3kMikpKQ7nSU5ORkxMjBOvQHm2bduGXr16Qa/XIzg4GDNmzJCnLEhKSoKPj4/8JGBmZiYkScKMGTPk948dOxZPPPGES+pOREQ3T2V/moyr1lepQVqGrFYrVqxYgYSEBGg01z/i1KlTWL16NR544AH4+/vj4MGDmDJlCvr27YsuXboAAAYNGoROnTrhySefxIIFC5CTk4NXXnkFEyZMkFt1nn32WSxZsgQvvfQSnn76aWzZsgVr167Fhg0bGuJyANgeLSw2FzfY+WvipnFzGIB+M3799Vc88MADGDNmDD777DMcO3YM48aNg8FgwKxZs9CnTx9cvXoV+/fvR8+ePbFt2zY0b94cqamp8jm2bduG6dPr0bxKRESNg/27uL4tQ01Eg4ShzZs34+zZs3j66acd9ut0OmzevBnvvfceioqKEBoaiuHDh+OVV16Ry6jVaiQlJeG5555DTEwMPDw8kJCQ4DAvUXh4ODZs2IApU6Zg8eLFaNmyJf7xj3806GP1xeZiRK+ObrDz12TX47vgrnWvvWANPvzwQ4SGhmLJkiWQJAmRkZH47bffMH36dLz22mvw9vbG3XffjdTUVPTs2ROpqamYMmUKZs+ejcLCQhQUFODkyZMOUyQQEdGdQZK7ydgyVJUGCUODBg2CqGLK79DQUGzbtq3W97dq1QobN26ssUz//v2xf//+m65jU3P06FHExMQ4tDD17t0bhYWFOH/+PMLCwtCvXz+kpqbixRdfxI8//oh58+Zh7dq1+Omnn3DlyhWEhISgffv2LrwKIiK6GZKaLUM14UKtdeSmccOux3e57LNvh/79+2P58uU4cOAAtFotIiMj0b9/f6SmpiIvL4+tQkREdyh7GGLLUNUYhupIkqRb7qpypY4dO+I///kPhBBy69D27dvh6emJli1bAoA8bujdd9+Vg0///v0xf/585OXl4cUXX3RZ/YmI6OZJWoahmnDVegUqKChAZmamwzZ+/HicO3cOzz//PI4dO4ZvvvkGr7/+OqZOnQqVyvY/A19fX3Tp0gWrVq1C//79AQB9+/bFvn37cPz4cbYMERHdoVTqirXBrAxDVWHLkAKlpqaiW7duDvsSExOxceNGTJs2DV27doWfnx8SExMdBq8DQL9+/ZCZmSmHIT8/P3Tq1AkXL15ERETE7boEIiJyIpXcMsRV66siiapGOjcRJpMJ3t7eKCgogJeXl8OxkpISZGdnIzw8HAaDwUU1VCbeWyKi22vNt/Nw97TPAACSXl8xU7QAJAm68HAYOnWCISrK9jMyAir3xj0spKbv75vBliEiIiKFMxv9YXIDvIoBccOC5QBQmpWF0qwsFHz9NQBA0ungNexB+I1OgCGi8a847wwMQ0RERAonebjjrxPUeMi3P2ZEz4SkkgBJgigvR+mJEyg5fBglh4+g+MhhWC79joL/fIWC/3wF95h74Dd6NJr17g1hNkOUlUGUl0OYzdD4+0PS6Vx9aU7BMERERKRwapUaZVoJBf566Fq2cDimCwuD54ABACpWW9i/H1c+/QxXk5NxLX0nrqXvrOakamhbtoC+dTh04eHQtW4FTWAQNAEB0AQGQuPvB0lzZ8SMO6OWREREdNPUkm0GaouoedJFSZLg3r073Lt3R/mvv+LKqtXIX7cO1qtXbywEqNWA2YzyX86i/JezQFUTKqtUUPv7ofWaNdBVTOHSWDEMERERKZxGZfu6t1jrPgO1tkULBL00DYGTJ8F67RokrdbWLVbR2mPOvYSy7GyUncm2/Tx7DuZLl2zb778DFgssl36H2tu7Qa7JmRiGiIiIFM7eMmQW5nq/V9LpoK5ibJA2KBDaoEB43FN53U5hscCSlwdzbi5UzZrVv8K3GcMQERGRwqkk2+S69WkZuhWSWg1N8+bQNG9+Wz7vVnEGaiIiIoWTu8lqGTPUVDEMERERKZzcTWatfzdZU8Aw1ERJkoT169e7uhpERHQbqFV1e5qsqWIYUqicnBw8//zzaNOmDfR6PUJDQzFs2DCkpKS4umpERHSbaaT6P03WlHAAtQKdOXMGvXv3ho+PDxYuXIjOnTujvLwc33//PSZMmIBjx465uopERHQbsWWoZmwZUqC//vWvkCQJu3fvxvDhw9GhQwdERUVh6tSp2Lmz6plEf/75Z/zxj3+Em5sb/P39MX78eBQWFsrHU1NT0atXL3h4eMDHxwe9e/fGL7/8Ih//5ptv0L17dxgMBrRp0wazZ8+G2cy+aSKixuBWHq1vCtgyVEdCCIjiYpd8tuTmBkmS6lT2ypUr2LRpE+bOnQsPD49Kx318fCrtKyoqQlxcHGJiYrBnzx7k5uZi7NixmDhxIlauXAmz2Yz4+HiMGzcOa9asQVlZGXbv3i3X6ccff8To0aPx/vvvo0+fPjh16hTGjx8PAHj99ddv/sKJiMgpbmbSxaaEYaiORHExsrr3cMlnR+zLgOTuXqeyJ0+ehBACkZGRdT7/6tWrUVJSgs8++0wOUEuWLMGwYcPw9ttvQ6vVoqCgAA8++CDatm0LAOjYsaP8/tmzZ2PGjBlISEgAALRp0wZvvPEGXnrpJYYhIqJGoK7LcTRVDEMKI4So93uOHj2Krl27OrQk9e7dG1arFVlZWejbty/GjBmDuLg4DBw4ELGxsXjssccQHBwMADhw4AC2b9+OuXPnyu+3WCwoKSnBtWvX4F7HIEdERA1DHjPElqEqMQzVkeTmhoh9GS777Lpq3749JEly+iDpFStW4IUXXsCmTZvw5Zdf4pVXXkFycjLuueceFBYWYvbs2XjkkUcqvc9gMDi1HkREVH/y02Q3tAxZhRV5JXn4vfh3h+1q2VVo1VpoVVroVDpo1VqoJJVtuAhs/8Ft/90qrPK5LMKCa+XXUFRehMLyQvn39+5/D+7axv0fxQxDdSRJUp27qlzJz88PcXFxWLp0KV544YVK44by8/MrjRvq2LEjVq5ciaKiIrn89u3boVKpEBERIZfr1q0bunXrhpkzZyImJgarV6/GPffcg+7duyMrKwvt2rVr8OsjIqL6s7cMXS6+jDGbxiCnKAe513JRbi1v8M8uLC9kGKLbb+nSpejduzd69eqFOXPmoEuXLjCbzUhOTsZHH32Eo0ePOpQfNWoUXn/9dSQkJGDWrFm4dOkSnn/+eTz55JMICgpCdnY2PvnkE/zpT39CSEgIsrKycOLECYwePRoA8Nprr+HBBx9EWFgY/vznP0OlUuHAgQM4dOgQ3nzzTVfcAiIiuoGXzgsAUGYtQ8bF670cEiT4GnzR3K25vHnqPGG2mmG2mlFmKUOZtUwegiFJEuz/B8m25pkECSpJBZWkgofWA+4ad3hoPeStmZYLtZILtGnTBvv27cPcuXPx4osv4sKFCwgICECPHj3w0UcfVSrv7u6O77//HpMmTcIf/vAHuLu7Y/jw4XjnnXfk48eOHcOnn36Ky5cvIzg4GBMmTMAzzzwDAIiLi0NSUhLmzJkjD7iOjIzE2LFjb+t1ExFR1UKahWBhv4XIKcyB0cOIII8gGN2NaO7eHFqV1tXVczlJ3MyIW4UwmUzw9vZGQUEBvLy8HI6VlJQgOzsb4eHhHPfiZLy3RER0K2r6/r4ZnHSRiIiImjSGISIiImrSGIaIiIioSWMYIiIioiaNYYiIiIiaNIahWjThh+0aDO8pERE1Jk4PQ7NmzbJNynTDduOioSUlJZgwYQL8/f3RrFkzDB8+HBcvXnQ4x9mzZzF06FC4u7sjMDAQ06ZNg9lsdiiTmpqK7t27Q6/Xo127dli5cqVTr0Or1UKSJFy6dAnFxcUoKSnh5oStuLgYly5dgiRJ0Go5twUREbleg0y6GBUVhc2bN1//EM31j5kyZQo2bNiAdevWwdvbGxMnTsQjjzyC7du3A7At8Dl06FAYjUbs2LEDFy5cwOjRo6HVavHWW28BALKzszF06FA8++yzWLVqFVJSUjB27FgEBwcjLi7OKdegVqvRsmVLnD9/HmfOnHHKOclGkiS0bNkSarXa1VUhIiJy/qSLs2bNwvr165GZmVnpWEFBAQICArB69Wr8+c9/BgAcO3YMHTt2RHp6Ou655x589913ePDBB/Hbb78hKCgIALBs2TJMnz4dly5dgk6nw/Tp07FhwwYcOnRIPveIESOQn5+PTZs21bmudZm0yWKxoLy84dduaUq0Wi2DEBER3TRnT7rYIC1DJ06cQEhICAwGA2JiYjBv3jyEhYUhIyMD5eXliI2NlctGRkYiLCxMDkPp6eno3LmzHIQA23IPzz33HA4fPoxu3bohPT3d4Rz2MpMnT66xXqWlpSgtLZVfm0ymWq9FrVbzi5uIiEjBnD5mKDo6GitXrsSmTZvw0UcfITs7G3369MHVq1eRk5MDnU5XadX0oKAg5OTkAABycnIcgpD9uP1YTWVMJhOKi4urrdu8efPg7e0tb6Ghobd6uURERHSHc3rL0JAhQ+Tfu3TpgujoaLRq1Qpr166Fm5ubsz+uXmbOnImpU6fKr00mEwMRERFRE9fgj9b7+PigQ4cOOHnyJIxGI8rKypCfn+9Q5uLFizAajQAAo9FY6eky++vaynh5edUYuPR6Pby8vBw2IiIiatoaZMzQjQoLC3Hq1Ck8+eST6NGjB7RaLVJSUjB8+HAAQFZWFs6ePYuYmBgAQExMDObOnYvc3FwEBgYCAJKTk+Hl5YVOnTrJZTZu3OjwOcnJyfI56so+drwuY4eIiIiocbB/bzvtGTDhZC+++KJITU0V2dnZYvv27SI2NlY0b95c5ObmCiGEePbZZ0VYWJjYsmWL2Lt3r4iJiRExMTHy+81ms7jrrrvEoEGDRGZmpti0aZMICAgQM2fOlMucPn1auLu7i2nTpomjR4+KpUuXCrVaLTZt2lSvup47d04A4MaNGzdu3Ljdgdu5c+eckl2c3jJ0/vx5jBw5EpcvX0ZAQADuu+8+7Ny5EwEBAQCAd999FyqVCsOHD0dpaSni4uLw4Ycfyu9Xq9VISkrCc889h5iYGHh4eCAhIQFz5syRy4SHh2PDhg2YMmUKFi9ejJYtW+If//hHvecYCgkJwblz5+Dp6QlJkpxzA3B9LNK5c+fYFXcb8b67Bu+7a/C+uwbvu2v8730XQuDq1asICQlxyvmdPs8QOX/+A6ob3nfX4H13Dd531+B9d42Gvu9cm4yIiIiaNIYhIiIiatIYhhqAXq/H66+/Dr1e7+qqNCm8767B++4avO+uwfvuGg193zlmiIiIiJo0tgwRERFRk8YwRERERE0awxARERE1aQxDRERE1KQxDBEREVGTxjDUAJYuXYrWrVvDYDAgOjoau3fvdnWVFGPevHn4wx/+AE9PTwQGBiI+Ph5ZWVkOZUpKSjBhwgT4+/ujWbNmGD58OC5evOiiGivT/PnzIUkSJk+eLO/jfW8Yv/76K5544gn4+/vDzc0NnTt3xt69e+XjQgi89tprCA4OhpubG2JjY3HixAkX1vjOZ7FY8OqrryI8PBxubm5o27Yt3njjDYdFQXnfb11aWhqGDRuGkJAQSJKE9evXOxyvyz2+cuUKRo0aBS8vL/j4+CAxMRGFhYX1rgvDkJN9+eWXmDp1Kl5//XXs27cPXbt2RVxcHHJzc11dNUXYtm0bJkyYgJ07dyI5ORnl5eUYNGgQioqK5DJTpkzBt99+i3Xr1mHbtm347bff8Mgjj7iw1sqyZ88efPzxx+jSpYvDft5358vLy0Pv3r2h1Wrx3Xff4ciRI1i0aBF8fX3lMgsWLMD777+PZcuWYdeuXfDw8EBcXBxKSkpcWPM729tvv42PPvoIS5YswdGjR/H2229jwYIF+OCDD+QyvO+3rqioCF27dsXSpUurPF6Xezxq1CgcPnwYycnJSEpKQlpaGsaPH1//yjhluVeS9erVS0yYMEF+bbFYREhIiJg3b54La6Vcubm5AoDYtm2bEEKI/Px8odVqxbp16+QyR48eFQBEenq6q6qpGFevXhXt27cXycnJol+/fmLSpElCCN73hjJ9+nRx3333VXvcarUKo9EoFi5cKO/Lz88Xer1erFmz5nZUUZGGDh0qnn76aYd9jzzyiBg1apQQgve9IQAQX3/9tfy6Lvf4yJEjAoDYs2ePXOa7774TkiSJX3/9tV6fz5YhJyorK0NGRgZiY2PlfSqVCrGxsUhPT3dhzZSroKAAAODn5wcAyMjIQHl5ucPfIDIyEmFhYfwbOMGECRMwdOhQh/sL8L43lP/+97/o2bMnHn30UQQGBqJbt274f//v/8nHs7OzkZOT43Dfvb29ER0dzft+C+69916kpKTg+PHjAIADBw7gp59+wpAhQwDwvt8OdbnH6enp8PHxQc+ePeUysbGxUKlU2LVrV70+T+OcahMA/P7777BYLAgKCnLYHxQUhGPHjrmoVspltVoxefJk9O7dG3fddRcAICcnBzqdDj4+Pg5lg4KCkJOT44JaKscXX3yBffv2Yc+ePZWO8b43jNOnT+Ojjz7C1KlT8be//Q179uzBCy+8AJ1Oh4SEBPneVvVvDu/7zZsxYwZMJhMiIyOhVqthsVgwd+5cjBo1CgB432+DutzjnJwcBAYGOhzXaDTw8/Or99+BYYjuWBMmTMChQ4fw008/uboqinfu3DlMmjQJycnJMBgMrq5Ok2G1WtGzZ0+89dZbAIBu3brh0KFDWLZsGRISElxcO+Vau3YtVq1ahdWrVyMqKgqZmZmYPHkyQkJCeN8Vit1kTtS8eXOo1epKT9BcvHgRRqPRRbVSpokTJyIpKQlbt25Fy5Yt5f1GoxFlZWXIz893KM+/wa3JyMhAbm4uunfvDo1GA41Gg23btuH999+HRqNBUFAQ73sDCA4ORqdOnRz2dezYEWfPngUA+d7y3xznmjZtGmbMmIERI0agc+fOePLJJzFlyhTMmzcPAO/77VCXe2w0Gis9nGQ2m3HlypV6/x0YhpxIp9OhR48eSElJkfdZrVakpKQgJibGhTVTDiEEJk6ciK+//hpbtmxBeHi4w/EePXpAq9U6/A2ysrJw9uxZ/g1uwYABA/Dzzz8jMzNT3nr27IlRo0bJv/O+O1/v3r0rTR1x/PhxtGrVCgAQHh4Oo9HocN9NJhN27drF+34Lrl27BpXK8etRrVbDarUC4H2/Hepyj2NiYpCfn4+MjAy5zJYtW2C1WhEdHV2/D7yl4d9UyRdffCH0er1YuXKlOHLkiBg/frzw8fEROTk5rq6aIjz33HPC29tbpKamigsXLsjbtWvX5DLPPvusCAsLE1u2bBF79+4VMTExIiYmxoW1VqYbnyYTgve9IezevVtoNBoxd+5cceLECbFq1Srh7u4uPv/8c7nM/PnzhY+Pj/jmm2/EwYMHxUMPPSTCw8NFcXGxC2t+Z0tISBAtWrQQSUlJIjs7W3z11VeiefPm4qWXXpLL8L7fuqtXr4r9+/eL/fv3CwDinXfeEfv37xe//PKLEKJu93jw4MGiW7duYteuXeKnn34S7du3FyNHjqx3XRiGGsAHH3wgwsLChE6nE7169RI7d+50dZUUA0CV24oVK+QyxcXF4q9//avw9fUV7u7u4uGHHxYXLlxwXaUV6n/DEO97w/j222/FXXfdJfR6vYiMjBSffPKJw3Gr1SpeffVVERQUJPR6vRgwYIDIyspyUW2VwWQyiUmTJomwsDBhMBhEmzZtxMsvvyxKS0vlMrzvt27r1q1V/nuekJAghKjbPb58+bIYOXKkaNasmfDy8hJPPfWUuHr1ar3rIglxw5SaRERERE0MxwwRERFRk8YwRERERE0awxARERE1aQxDRERE1KQxDBEREVGTxjBERERETRrDEBERETVpDENERETUpDEMERERUZPGMERERERNGsMQERERNWn/HxhXrtzw/bI2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_companies(company, companyPath, filtered_companies_model):\n",
        "    \"\"\" Function to predict all good companies. Calling predict_one_company.\n",
        "    Return: A list of predicted prices from different company.\"\"\"\n",
        "    predictions = []\n",
        "    for i in range(0, len(company)):\n",
        "        predictions.append(predict_one_company(company[i], companyPath[i], filtered_companies_model[i]))\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "EHYb8xpvH7rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3: When to buy/hold/sell"
      ],
      "metadata": {
        "id": "nxifmVvINeX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_making(predictions):\n",
        "    \"\"\"Output the list of companies to keep and to sell\"\"\"\n",
        "    portfolio = []\n",
        "    for company in predictions:\n",
        "        company_name = company[0]\n",
        "        company_indicators = company[2]\n",
        "        company_rsi = company_indicators[\"rsi\"]\n",
        "        company_rsi = company_rsi.iloc[-prediction_day:]\n",
        "        # buy = np.argmin(company_rsi_interested)\n",
        "        # sell = np.argmax(company_rsi_interested)\n",
        "        # buy = buy if company_rsi_interested.iloc[buy] < 30 else None\n",
        "        # sell = sell if company_rsi_interested.iloc[sell] > 70 else None\n",
        "        buy = []\n",
        "        sell = []\n",
        "        hold = []\n",
        "        index=1\n",
        "        for i in company_rsi:\n",
        "          if i<10:\n",
        "            buy.append(index)\n",
        "          elif i>80:\n",
        "            sell.append(index)\n",
        "          else:\n",
        "            hold.append(index)\n",
        "          index+=1\n",
        "        if len(buy)==0:\n",
        "          buy=None\n",
        "        if len(sell)==0:\n",
        "          sell=None\n",
        "        if len(hold)==0:\n",
        "          hold=None\n",
        "        portfolio.append([company_name, buy, hold, sell])\n",
        "    return portfolio"
      ],
      "metadata": {
        "id": "5D893SPuIpYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict all company & indicators\n",
        "predictions = predict_companies(goodCom, goodComPath, filter_compiled_model)"
      ],
      "metadata": {
        "id": "zw2rVQJRIum9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa387b3-abed-4a46-8143-860641bd9bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio management\n",
        "portfolio = decision_making(predictions)\n",
        "print(\"Company name\", \"Buy date\", \"Hold date\", \"Sell date\")\n",
        "for company in portfolio:\n",
        "    print(company)"
      ],
      "metadata": {
        "id": "f564Wmw-JPdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c7ceb3-b525-4dd0-84c5-82ffce4b63aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company name Buy date Hold date Sell date\n",
            "['BAB', [1, 2, 3, 4, 5, 6, 7], None, None]\n",
            "['TPB', [1, 2, 3, 4, 5, 6, 7], None, None]\n",
            "['PGB', [1, 2, 3, 4, 5, 6, 7], None, None]\n",
            "['SGB', [1, 2, 3, 4, 5, 6], [7], None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4: Which companies to hold"
      ],
      "metadata": {
        "id": "TvBmc3btjqUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/thinh-vu/vnstock.git@main\n"
      ],
      "metadata": {
        "id": "uqG8RRiSIptp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a873530d-45b5-4513-9bb1-c7c1245e73a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/thinh-vu/vnstock.git@main\n",
            "  Cloning https://github.com/thinh-vu/vnstock.git (to revision main) to /tmp/pip-req-build-8jeznup4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/thinh-vu/vnstock.git /tmp/pip-req-build-8jeznup4\n",
            "  Resolved https://github.com/thinh-vu/vnstock.git to commit f09b4ee9c64649be5e5d78806fb419fefe99854e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: vnstock\n",
            "  Building wheel for vnstock (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vnstock: filename=vnstock-0.1.2-py3-none-any.whl size=17826 sha256=1d70e2bafeb58eed60e409b9b23e6b4ab54f35c70df69318929b5f49f5aa003a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6u_nf7bv/wheels/af/d1/dd/4a6968f5e0bb65a0f13b9340b9c6d9e185115f3514f05240ca\n",
            "Successfully built vnstock\n",
            "Installing collected packages: vnstock\n",
            "Successfully installed vnstock-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vnstock import *"
      ],
      "metadata": {
        "id": "M1O7wZeOWVGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_analysis = pd.DataFrame()\n",
        "for i in goodCom:\n",
        "  temp = general_rating(i)\n",
        "  stock_analysis = pd.concat([temp, stock_analysis])"
      ],
      "metadata": {
        "id": "igWHXznpV7bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_analysis"
      ],
      "metadata": {
        "id": "m_Zv_GNwXP_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f057676-8745-4598-da7d-872522636ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stockRating  valuation  financialHealth  businessModel  businessOperation  \\\n",
              "0          3.3        2.0              2.8            3.2                2.3   \n",
              "0          3.4        1.8              2.8            3.0                2.5   \n",
              "0          4.3        2.9              4.0            3.3                4.5   \n",
              "0          3.7        3.2              4.1            3.0                1.8   \n",
              "\n",
              "   rsRating  taScore ticker  highestPrice  lowestPrice  priceChange3m  \\\n",
              "0       1.8      1.0    SGB       14349.0      11828.0          0.046   \n",
              "0       3.4      2.0    PGB       33922.0      13508.0          0.648   \n",
              "0       3.2      1.5    TPB       29739.6      17438.2          0.129   \n",
              "0       1.7      1.0    BAB       17777.3      12400.0         -0.029   \n",
              "\n",
              "   priceChange1y  beta   alpha  \n",
              "0         -0.080  0.23  0.0000  \n",
              "0          0.173  1.22  0.0000  \n",
              "0         -0.170  1.01 -0.0009  \n",
              "0         -0.223  0.79 -0.0006  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e3aa954-af6b-4402-80cf-31c9154df1c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stockRating</th>\n",
              "      <th>valuation</th>\n",
              "      <th>financialHealth</th>\n",
              "      <th>businessModel</th>\n",
              "      <th>businessOperation</th>\n",
              "      <th>rsRating</th>\n",
              "      <th>taScore</th>\n",
              "      <th>ticker</th>\n",
              "      <th>highestPrice</th>\n",
              "      <th>lowestPrice</th>\n",
              "      <th>priceChange3m</th>\n",
              "      <th>priceChange1y</th>\n",
              "      <th>beta</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SGB</td>\n",
              "      <td>14349.0</td>\n",
              "      <td>11828.0</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.080</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.4</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>PGB</td>\n",
              "      <td>33922.0</td>\n",
              "      <td>13508.0</td>\n",
              "      <td>0.648</td>\n",
              "      <td>0.173</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>TPB</td>\n",
              "      <td>29739.6</td>\n",
              "      <td>17438.2</td>\n",
              "      <td>0.129</td>\n",
              "      <td>-0.170</td>\n",
              "      <td>1.01</td>\n",
              "      <td>-0.0009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>BAB</td>\n",
              "      <td>17777.3</td>\n",
              "      <td>12400.0</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-0.223</td>\n",
              "      <td>0.79</td>\n",
              "      <td>-0.0006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e3aa954-af6b-4402-80cf-31c9154df1c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e3aa954-af6b-4402-80cf-31c9154df1c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e3aa954-af6b-4402-80cf-31c9154df1c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the number of uptrends and downtrends each company have. If more downtrends, the company is not good for investment and vice versa\n",
        "uptrend = []\n",
        "downtrend = []\n",
        "for company in predictions:\n",
        "  interestRange = company[1].iloc[-prediction_day:]\n",
        "  numUp=0\n",
        "  numDown=0\n",
        "  prevPivot = (interestRange[\"Open\"].iloc[0]+interestRange[\"High\"].iloc[0]+interestRange[\"Low\"].iloc[0]+interestRange[\"Close\"].iloc[0])/4\n",
        "  for i in range(1, len(interestRange)):\n",
        "    pivot = (interestRange[\"Open\"].iloc[i]+interestRange[\"High\"].iloc[i]+interestRange[\"Low\"].iloc[i]+interestRange[\"Close\"].iloc[i])/4\n",
        "    if pivot<prevPivot:\n",
        "      numDown +=1\n",
        "    else:\n",
        "      numUp+=1\n",
        "  if numDown>numUp:\n",
        "    downtrend.append(company[0])\n",
        "  else:\n",
        "    uptrend.append(company[0])\n"
      ],
      "metadata": {
        "id": "tJM1KCzM19hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the stock rating and business operation rating by TCBS. Sort it in descending orders, and pick up the best company.\n",
        "stock_analysis.sort_values([\"stockRating\", \"businessOperation\"], ascending=False, ignore_index=True, inplace=True)\n",
        "focused_stock_analysis = stock_analysis[[\"ticker\", \"stockRating\", \"businessOperation\"]]\n",
        "focused_stock_analysis.head()"
      ],
      "metadata": {
        "id": "6Q7RxcyKiMMI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "c13945a6-5784-41e8-b17f-a1f44818d7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ticker  stockRating  businessOperation\n",
              "0    TPB          4.3                4.5\n",
              "1    BAB          3.7                1.8\n",
              "2    PGB          3.4                2.5\n",
              "3    SGB          3.3                2.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f80391c1-aa7f-42c5-9b5c-8d7a2572f17e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>stockRating</th>\n",
              "      <th>businessOperation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TPB</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BAB</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PGB</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGB</td>\n",
              "      <td>3.3</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f80391c1-aa7f-42c5-9b5c-8d7a2572f17e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f80391c1-aa7f-42c5-9b5c-8d7a2572f17e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f80391c1-aa7f-42c5-9b5c-8d7a2572f17e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(downtrend)\n",
        "print(uptrend)"
      ],
      "metadata": {
        "id": "yNXXBaTx5GRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70134359-d996-4d88-b363-af76d1e47d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BAB', 'TPB', 'PGB', 'SGB']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goodCompany = []\n",
        "badCompany = []\n",
        "for i in focused_stock_analysis.head(5)[\"ticker\"]:\n",
        "  if not (i in downtrend):\n",
        "    goodCompany.append(i)\n",
        "  else:\n",
        "    badCompany.append(i)\n",
        "print(\"Good companies which have good stock ratings, business operation ratings, and more uptrends\", goodCompany)\n",
        "print(\"Bad companies with low stock ratings, business operation ratings, and more downtrends\", badCompany)"
      ],
      "metadata": {
        "id": "YxPW24n3Du8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f864b3-73e8-4517-d8a4-51e1af64a3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good companies which have good stock ratings, business operation ratings, and more uptrends []\n",
            "Bad companies with low stock ratings, business operation ratings, and more downtrends ['TPB', 'BAB', 'PGB', 'SGB']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}